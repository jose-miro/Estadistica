[
["index.html", "Mera estadística Capítulo 1 Introducción", " Mera estadística Jose Miró Julià 2/18/2020 Capítulo 1 Introducción Este libro contiene los conocimientos básicos necesarios para la asignatura Matemáticas III - Estadística del grado de Ingeniería Electrónica Industrial y Automática de la U. de les Illes Balears. No es un libro de texto: no hay ejercicios ni muchos ejemplos. Es más bien un libro para acompañar lo que se explica en clase y los ejercicios que van apareciendo en el Aula Digital de la asignatura. Este libro es dinámico: va a ir cambiando a medida qeu vea cosas a añadir o mejorar. Conviene ir siempre al sitio web para tener la información actualizada. "],
["qué-es-y-no-es-la-estadística.html", "Capítulo 2 ¿Qué es (y no es) la estadística? 2.1 El proceso estadístico 2.2 ¿Es la estadística parte de las matemáticas?", " Capítulo 2 ¿Qué es (y no es) la estadística? Faltan 17 segundos para que acabe el partido de baloncesto entre el Celta de Boston y el Real Sacramento. El Celta gana de dos puntos y va a sacar de banda. El Real Sacramento ha pedido tiempo muerto. Está claro que van a hacer una falta personal y esperar que el jugador del Celta falle al menos uno de los tiros. Ambos entrenadores están montando su estrategia en torno a esto: el del Celta, pensando en qué jugdores debe poner en cancha; el del Real Sacramento pensando a qué jugador conviene hacer la falta. A efectos de este escrito, supongamos que no se han enfrentado nunca y no saben nada de partido anteriores. Entonces, la única evidencia que tienen, y en lo que basarán sus decisiones, es en el porcentaje de tiros libres encestados en este partido. Hay dos jugadores del Celta con un porcentaje del 100%. Uno es L’Bron Jaume pero que sólo ha tirado uno y la ha encestado. El otro es Llorenç Ocell, que lleva 8 de 8. Claramente a Ocell no hay que tocarle, pero a Jaume… no está tan claro. Hay dos con un 0%. Uno es Sión Guillérmez, que ha fallado el único que ha tirado. El otro es Trae Joven, que lleva una serie de 0 de 5. Joven es el candidato número uno a recibir la falta, que es por lo que lo van a sentar. En cambio es difícil valorar la probabilidad de que Guillérmez falle sus tiros. Hay dos que han encestado un 50%, Santi Mayordomo y Cristóbal Pablo. Pero Santi ha metido 1 de 2 mientras que Cristóbal ha metido 7 de 14. Es el mismo porcentaje, pero la intuición nos dice que mejor hacer falta a Cris que a Santi. Finalmente tenemos a Kevin Amor, que ha metido 7 de 9, para un porentaje de 78% y Juan Pared que ha metido 5 de 7, un 71%. Aunque es cierto que Amor tiene un porcentaje un 7% mayor que Pared, otra vez la intuición nos dice que no hay mucha diferencia entre ambos y que incluso puede ser que Pared sea mejor tirador que Amor. “¿A quién hacer falta?” se pregunta el entrenador del Real. “¿Cuál dejo en el banquillo?” se pregunta el del Celta. Intuitivamente nos podemos hacer una idea de quién es peligroso tirando tiros libres y quién no. No nos parece que 1 de 1 y 8 de 8 sean lo mismo aunque nos dé el mismo porcentaje. Ni es lo mismo 0 de 1 que 0 de 5. Pero sólo son intuiciones. La estadística es la rama del conocimiento que gestiona y cuantifica la incertidumbre. Es la que nos permite dar un fundamento riguroso a estas intuiciones que tenemos y nos permite diferenciar un 1 de 2 y un 7 de 14, aunque ambos sean el 50%. Una cuestion importante que se ve en este ejemplo es que la estadística no es necesaria para valorar el pasado: para saber el porcentaje de tiros libres de los tiros ya lanzados sólo necesitamos la aritmética. La estadística se necesita cuando hemos de valorar lo desconocido, generalmente, el futuro. Pues también podemos usar la estadística para valorar hechos desconocidos en el pasado: ¿A qué velocidad iba el coche cuando chocó? A menudo se usa mal el término “estadística”: es un error habitual en retransmisiones deportivas decir cosas como “La estadística dice que mide 1,84 m”. Eso no es una estadística, eso es un dato. Tambien es un dato que “Ha dado 13 pases de los cuales han llegado a su destino 8”. La estadística se nutre de estos datos, pero lo que es propiamente estadística son las inferencias a las que podemos llegar a partir de esos datos. En nuestro ejemplo, los entrenadores quieren evaluar cuál es la probabilidad para cada jugador del Celta de que enceste los dos siguientes tiros libres. En un caso real partirían de muchos datos (porcentaje de tiros libres, porcentaje de tiros libres en el último cuarto, minutos jugados —un jugador cansado suele acertar menos—, etc) para realizar cálculos complejos y tener una tabla, normalmente antes de que empiece el partido, con la lista de jugadores a los que hacer falta y a los que no (o los jugadores que deben estar en el campo y los que no). Después añaden su intuición —quizá este jugador está muy fallón hoy, quizá este otro parece nervioso— para tomar sus decisiones. Porque ese es el uso principal de la estadística: ayudarnos en la toma de decisiones. 2.1 El proceso estadístico Veamos de una manera simplificada y esquemática cuál es el proceso que se sigue para realizar un estudio estadístico. El primer paso es determinar cuál es nuestra población de interés. Aunque se le llame población, no son necesariamente personas. Pueden serlo, pero también pueden ser objetos, por ejemplo los ordenadores fabricados por una fábrica, o pueden ser entes, por ejemplo días en los que puede llover o no, o tiradas de dado (no el dado en sí, sino el resultado obtenido tras tirarlo). Esta población puede ser finita o potencialmente infinita: todos los españoles con facultad de votar en unas elecciones determinadas es una población finita, mientras que todas las tiradas posibles de una determinada moneda es una población potencialmente infinita. De esta población quiero saber alguna característica: la altura media de los jóvenes españoles actuales, el porcentaje de caras del lanzamiento de una moneda, el porcentaje de días de lluvia en una ciudad, el consumo medio de un modelo de coche. Por algún motivo me es imposible medir la característica en todos los miembros de la población. Puede ser una cuestión de coste: es teóricamente posible, pero de un coste inasumible, medir la altura de todos los jóvenes españoles actuales o medir el consumo de todos los coches de un modelo. Otras veces es literalmente imposible: no puedo saber si va a llover o no mañana, dentro de una semana o dentro de un més, como tampoco puedo saber el resultado de los lanzamientos futuros de una moneda. Lo que hacemos es coger una muestra representativa de la población y medir la característica en esa muestra. La estadística nos va a permitir decir algo de la característica en la población total, incluyendo aquellos que no hemos medido, a partir de lo que hemos medido en nuestra muestra. Naturalmente, no vamos a tener certeza total de lo que pasa en toda la población, pero la estadística nos permitirá acotar nuestra incertidumbre. En muy pocos casos coger una muestra es fácil. Sí lo es en lanzamientos de monedas y casos así, pero poco más. En general, coger una muestra representativa es muy difícil. Es donde se va la mayor parte del coste de las encuestas o del control de calidad. No vamos a hablar más de ello en esta introducción, pero la mayor parte de los errores de los procesos estadísticos vienen de escoger muestras no representativas, llamadas sesgadas, que no representan a la población. Población y muestra en nuestro ejemplo. En nuestro ejemplo la población no son los jugadores del Celta, sino los tiros libres de cada jugador. Una manera de ver que los jugadores no son la población, es que no hay incertidumbre alguna: son los que están allí. En cambio sí que hay incertidumbre en su capacidad de meter los próximos tiros libres. La población, para cada jugador, son todos los tiros libres que va a tirar en partido oficial. La muestra son todos los tiros libres que ha tirado en este partido hasta el momento. ¿Es una muestra representativa? Hay razonamientos tanto a favor como en contra. Una vez tenemos la muestra y hemos medido la característica que nos interesa en todos los elementos de la muestra el siguiente paso es obtener una visión global de todos estos datos individuales. Esta parte de la estadística se le conoce como estadística descriptiva. Podemos obtener algunos valores importantes, como la media y la mediana, pero sobre todo es útil usar buenas gráficas. Fijémonos en los dos histogramas de la figura siguiente. Estos dos histogramas representan el peso de dos poblaciones de animales. La media en ambos casos es la misma, 4.97 gr, pero vemos que las naturalezas de las dos poblaciones son claramente diferentes. El de la derecha es una población homogénea, mientras que en el de la izquierda vemos que probablemente haya dos subpoblaciones con pesos diferentes, uno más ligero centrado alrededor de los 3 gramos y otro más pesado centrado alrededor de los 7. Un estadístico sabe que hablar de una media en el caso de la derecha tiene sentido; en el caso de la izquierda, no tanto. El conocido chiste “Un estadístico es el que, si tienes tu cabeza en un horno y los pies en el congelador, te dice que de media estás bien” es completamente erróneo. El estadístico es precisamente el que te dice que en este caso no tiene mucho sentido calcular una media. Una vez tenemos una idea global de nuestros datos, podemos pasar a deducir conocimiento a partir de nuestros datos. Esta parte de la estadística se le conoce como estadística inferencial. Según el tipo de datos se le hacen unas pruebas estadísticas u otras. Estas pruebas nos van a permitir determinar si hay una correlación entre una variable y otra (¿Se fallan más tiros libres cuántos más minutos hayas jugado? ¿El porcentaje de tiros libre es el mismo en todos los cuartos?) o si se puede diferenciar entre dos casos (¿Es el porcentaje de acierto de Kevin Amor mayor que el de Juan Pared? —nos referimos a la población entera, todos los tiros libres de la temporada: en la muestra sí sabemos qué porcentaje es mayor—. Los razonamientos que salen de las pruebas estadísticas son particulares a la estadística y cuesta entenderlos y acostumbrarse a ellos. Nos gustaría un claro sí/no, pero la estadística no elimina la incertidumbre, sólo la gestiona y cuantifica. Lo más que vamos a obtener son afirmaciones del estilo “La evidencia que tenemos da soporte a la afirmación de que el porcentaje de tiro de Amor es mayor que el de Pared”. Simplemente da soporte, no asegura. Y para saber cuánto soporte da usamos unas probabilidades aún más particulares a la estadística y más difíciles de entender. Otra cuestión importante a tener en cuenta es que de la estadística, por su naturaleza, nunca, nunca, nunca se puede deducir causalidad. Por ejemplo, un estudio estadístico mostró que hay una clara correlación entre los libros que se tiene en una casa y la nota de selectividad de los habitantes de esa casa. Pero es obvio que no son los libros los que causan la mejora de la nota, pues si así fuera, bastaría con comprar unas cuantas cajas de libros el día anterior al examen (y devolverlos el día después) para mejorar la nota de selectividad. Absurdo. Pero el procedimiento para determinar la correlación entre libros y nota de selectividad es exactamente el mismo que para determinar si un medicamento causa la cura de una enfermedad. La estadística puede indicar que hay una correlación, incluso cuantificarla de alguna manera, pero si la eliminación de la enfermedad es causada por el medicamento se debe determinar por métodos médicos: metabólicos, bioquímicos, patológicos… Las pruebas estadísticas no pueden determinar si hay causa o no. Este es un peligro contra el que hay que estar alerta siempre. Si nos dicen que las personas con ojos azules son más altas que los de ojos marrones no pensamos que el color de los ojos cause alguna diferencia de altura, pero si nos dicen que las personas que siguen una dieta mediterránea son más delgadas que los que siguen otras dietas, inmediatamente pensamos que quizá convenga cambiar nuestra dieta. No estoy diciendo que la dieta no influye en nuestro peso —evidentemente sí lo hace— y tampoco estoy diciendo que la dieta mediterránea no cause una disminución de peso —quizá sí lo haga—. Lo que estoy diciendo es que el razonamiento estadístico no permite llegar a esa conclusión. 2.2 ¿Es la estadística parte de las matemáticas? Normalmente se suele considerar que la estadística es parte de las matemáticas, aunque hay voces ––entre las que me incluyo–– que lo discuten. Un razonamiento que se suele dar es que la estadística usa fuertemente de las matemáticas. Pero la física también usa fuertemente de las matemáticas y en el S. XVI el término “matemáticas” era un sinónimo de “astronomía”, pero ahora nadie opina que la física es parte de las matemáticas. Exploremos la diferencia entre física y matemáticas para ver cómo la estadística no es matemáticas. El proceso matemático parte de axiomas y llega a teoremas. La física, en cambio, parte de observaciones y llega a las leyes físicas que describen con precisión el mundo material. La física utiliza ecuaciones diferenciales y matrices y tensores, elementos matemáticos, pero su proceso de creación de conocimiento es completamente diferente al de las matemáticas. La estadística parte de datos y llega a conclusiones probabilísticas. La parte fundamental, y la más difícil, es la recogida de los datos, el muestreo, que es la parte más alejada a las matemáticas de todo el proceso. El segundo paso, la estadistica descriptiva, depende mucho de la percepción que se tiene ante gráficas y eso es más cercano a la psicología que a las matemáticas. La práctica estadística usa fuertemente de las matemáticas, sobre todo en la parte inferencial, pero no es matemáticas. Quizá la confusión viene de que sí que hay una parte de las matemáticas que recibe el nombre de estadística, en donde, partiendo de axiomas se llegan a los teoremas que usamos en la práctica estadística. Son dos campos que reciben el mismo nombre, pero no se refieren a lo mismo. La estadística es un campo de conocimiento propio, con sus procedimientos y sus razonamientos, que usa de las matemáticas. Pero el procedimiento estadístico no es el procedimiento matemático y el razonamiento estadístico no es el razonamiento matemático. La estadística es una campo propio. "],
["estadística-descriptiva-de-datos-numéricos-univariantes.html", "Capítulo 3 Estadística descriptiva de datos numéricos univariantes 3.1 Tipos de datos 3.2 Medidas de centralidad y dispersión 3.3 Gráficas para datos cuantitativos 3.4 Análisis de los datos", " Capítulo 3 Estadística descriptiva de datos numéricos univariantes Lo primero que hay que hacer cuando se quiere hacer un análisis estadístico sobre un conjunto de datos es entenderlos. Para ello hay que hacer algunos cálculos básicos y mirar algunas gráficas. A esto se llama estadística descriptiva. Cuanto mejor se entiendan los datos, mejor se podrá decidir qué técnicas y pruebas estadísticas hay que usar y cuánto nos podemos fiar de los resultados. Veamos las bases de la estadística descriptiva de una variable numérica. 3.1 Tipos de datos Una variable puede ser de dos tipos. Si la variable se tiene que representar mediante un número y puede operarse, tenemos una variable cuantitativa o numérica. Si en cambio se representa mediante un concepto o término y no puede operarse con ella, es de tipo cualitativo o factor. Ejemplos típicos de variables numéricas son el peso, la altura, la temperatura, la resistencia… Ejemplos típicos de los factores son el color de ojos o de pelo, el sexo o estados varios (casado, soltero, viudo, divorciado; funcionando, parado, estropeado). Las variables cuantitativas pueden ser continuas o discretas. En una variable discreta sól se pueden tomar ciertos valores y no los intermedios. Por ejemplo el número de hermanos es discreto, pues puede ser 0, 1, 2… pero no puede tomar ningñun valor entre 1 y 2: no puede ser 1,7. La temperatura o el peso son continuas, pues pueden tomar cualquier valor. Uno puede medir 173 cm o 174 cm o cualquier valor entre medias. Es cierto que normalmente no usamos estos valores intermedios, no decimos que una persona mide 173,2 cm, pero eso no es una característica de la variable, sino de la precisión que hemos elegido para nuestra variable. Es una decisión que podemos cambiar cuando queramos. Como hemos dicho, una variable cualitativa o factor representa conceptos o términos. Los diferentes valores que puede tomar un factor se llaman los niveles del factor. Por ejemplo la variable color de ojos puede tomar los niveles “azul”, “verde”, “marrón” y “negro”. A veces es una decisión subjetiva cuáles son los niveles que puede tomar un factor: alguno puede opinar que existen los ojos grises, y otros pueden opinar que no. A veces una variable cualitativa puede representarse mediante un número, pero no es un número, pues no se puede operar con él. Por ejemplo tenemos los meses o años: 2 (febrero) + 3 (marzo) no es 5 (mayo). El año 1914 más el 1930 no es el año 3844. Por lo tnato el mes o el año, aunque lo representemos mediante nñumeros, no son variables cuantitativas, sino cualitativas. A veces nos conviene pasar una varaible cuantitativa a cualitativa. Esto lo hacemos agrupando los valores numéricos en intervalos. Por ejemplo si agrupamos los niveles de renta en “Menos de 15 000”, “Entre 15 000 y 30 000”, “Entre 30 000 y 60 000” y “Más de 60 000” hemos convertido de forma objetiva los números de la variable numérica, en términos que podríamos llamar “Muy bajo”, “Bajo”, “Medio” y “Alto”. En lo que resta de este capítulo vamos a trabajar con variables numéricas. En un capítulo posterior miraremos la estadística descriptiva de las variables cualitativas. 3.2 Medidas de centralidad y dispersión La media es la medida más conocida que nos da una idea de valor “central”, valor que representa al “centro” de los datos. Todos sabemos que es la suma de todos los datos dividido por el número de datos. Si los datos son poco problemáticos (ya definiremos más adelante que significa esto), la media es una buena medida del centro de los datos. Otra medida, menos conocida, es la mediana. Es, de entre los valores de los datos, aquel que hace que la mitad sean menores que él y la mitad sean mayores. Lo podemos calcular ordenando los datos y cogiendo el del medio. Si tenemos 7 datos, 4, 7, 13, 8, 10, 13 y 3, los ordenamos y cogemos el cuarto. Así tenemos 3 por debajo y 3 por encima: 3, 4, 7, 8, 10, 13, 13. En este caso la mediana es 8. ¿pero qué pasa si tenemos 8 datos? Ningún dato deja tantos por encima como por debajo. En ese caso se define la mediana como la media aritmética de los dos del medio. Si a los datos anteriores añadimos un 16, tenemos: 3, 4, 7, 8, 10, 13, 13, 16. La mediana sería en este caso 9, la media de 8 y 10. Una extensión de la mediana son los cuartiles. El primer quartil (o Q1) es un valor que es mayor que el 25% de los datos. El segundo quartil sería la mediana, y el tercer quartil (o Q3) es un valor que es mayor que el 75% de los datos. A diferencia de la mediana, no hay una definición clara de qué hacer si no coincide con un dato. No es tampoco demasiado importante. En nuestro ejemplo (con 8 datos) diremos que el Q1 es cualquier valor entre 4 y 7, y que el Q3 vale 13. La mediana es mucho más robusta que la media. Un solo valor muy gande o pequeño hace que la media cambie mucho. Esto no pasa con la mediana. Supongamos que partimos estamos mirando el número medio de seguidores de Twitter de la población. Cogemos una muestra de 9 twiteros y supongamos que nos salen que tienen 28, 31, 75, 90, 105, 201, 250, 400 y 586 seguidores. Esto nos da una media de 172,9 seguidores y una mediana de 105 seguidores. Algo diferente pero podemos decir que ambos valores son representativos del conjunto. Pero cogemos al décimo seguidor al azar y sale que es Donald Trump (@realDonaldTrump) que tiene (en el momento de escribir este documento) más de 25 millones de seguidores. Pongamos que tiene 25 millones y medio. La mediana pasa a ser 153, que podemos seguir considerando representativa de la mayoría de la población. En cambio la media pasa a valer más de dos millones y medio y ya no representa a nadie. A este valor tan alejado de todos se le llama un valor atípico (outlier en inglés). Como ya vemos en este ejemplo influyen mucho en el estudio de los datos. La media o la mediana no nos dice todo sobre los datos. Por ejemplo, las muestras (5, 7, 9) y (2, 7, 12) tienen la misma media, pero la segunda muestra está mucho más dispersa que la primera. Para medir esta dispersión usamos la desviación típica. No daremos aquí la definición (la podéis encontrar en Wikipedia, si queréis) pero sí la idea general. La desviación típica nos da una idea de cuánto están alejados los datos de la media de la muestra. Si es grande, es que están muy alejados; si es pequeña, es que están casi todos concentrados alrededor de la media. La desviación típica (generalmente representada por \\(\\sigma\\)) nos sirve de unidad. En muchas distribuciones más o menos dos tercios de los datos están a menos de una desviación típica (o \\(\\sigma\\)) por encima o por debajo de la media (los datos están dentro de [media \\(- \\sigma\\), media \\(+ \\sigma\\)]; el 95% de los datos están a menos de dos desviaciones típicas (o \\(2 \\sigma\\)) por encima o por debajo de la media (dentro de [media \\(- 2\\sigma\\), media \\(+ 2\\sigma\\)]); y el 99% de los datos está a menos de \\(3 \\sigma\\) por encima o por debajo de la media (dentro de [media \\(- 3\\sigma\\), media \\(+ 3\\sigma\\)]). Si nos dicen que el peso de un ganso concreto es 300 g por encima de la media no sabemos si es mucho o poco. Pero si nos dicen que está a \\(0.3\\sigma\\) por encima sabemos que es prácticamente un ganso medio. En cambio, si nos dicen que está a \\(1.8\\sigma\\) de la media, sabemos que es un ganso muy grande. Para calcular estas medidas en R tenemos varias funciones. Sea datos el vector con nuestros datos. La función mean(datos) nos calcula la media. La función median(datos) nos calcula la mediana. La función summary(datos) nos hace un resumen de los datos, dándonos la media, la mediana, los cuartiles y los valores máximos y mínimos. La función sd(datos) nos calcula la desviación típica. Veamos un ejemplo. datos = c(1.0, 3.1, 2.3, 4.2, 0.2, 1.5, 2.0) mean(datos) ## [1] 2.042857 median(datos) ## [1] 2 summary(datos) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.200 1.250 2.000 2.043 2.700 4.200 sd(datos) ## [1] 1.330234 Estas medidas de centralidad y dispersión nos dan una cierta idea de cómo pueden ser los datos. Pero para entenderlo bien, necesitamos verlos de forma gráfica. 3.3 Gráficas para datos cuantitativos Las gráficas son una parte fundamental de la estadística descriptiva. Los números están bien, pero una gráfica es más informativa. Vamos a ver las cuatro gráficas fundamentales para variables numéricas: diagramas de puntos, histogramas, diagramas de tallo y hojas y diagramas de cajas. Diagrama de puntos. Un diagrama de puntos representa todos los puntos de nuestros datos. Como sólo hay una variable, es un gráfico unidimensional, fácil de crear e interpretar. En R se obtiene esta gráfica con la función stripchart(). Podemos ver un ejemplo del peso de 57 personas en la figura siguiente. Cada cuadradito representa un dato. Podemos ver si están más juntos o dispersos o si se “apelotonan” alrededor de un punto o varios. En la figura se ve que están bastante dispersos y parece que se apelotonan un poco alrededor del 50. Lo mejor del diagrama de puntos es que puedes ver cada dato. Naturalmente esto sólo es posible si tenemos una cantidad pequeña o modarada de datos. Si tenemos miles, es obvio que no veremos nada. Histogramas. Un histograma es una gráfica bidimensional para representar nuestra variable numérica. En el eje X tenemos el valor de los datos, mientras que en el eje vertical tenemos la frecuencia, es decir, cuántos datos tenemos en cada intervalo. En la figura siguiente vemos un histograma, con los mismos datos del peso de 57 personas. Vemos que para crear el histograma se divide los posibles valores de la variable en intervalos. En este caso son intervalos de 5 kg: de 40 Kg a 45 Kg, de 45 Kg a 50 Kg, etc. Podemos leer del histograma que entre 40 Kg y 45 Kg hay dos personas, mientras que entre 65 Kg y 70 Kg hay 5. Se confirma que hay un montículo alrededor del 50. R crea histogramas con la función hist(). Un histograma es muy útil y se usa mucho. Lo malo es que necesita muchos datos. Fijaos que hay varios intervalos con 5 o menos personas. Una sola persona que pese unos cientos de gramos más o menos y que por eso pase de un intervalo al contiguo hace que el aspecto del histograma cambie mucho. Y lo mismo pasa por cómo se escogen los intervalos: si en vez de (40, 45); (45,50); (50,55) etc. hubiéramos cogido (41,46); (46,51); etc. podría dar lugar a un histograma muy diferente. Cuantos menos datos tenemos, menos fiable es el histograma. Y por debajo de unos 30 datos, se recomienda ni siquiera hacerlo. Diagrama de tallo y hojas. Un diagrama de tallo y hojas es una especie de histograma hecho a mano. Escogemos de cada dato las dos cifras más significativas, la de la izquierda es el tallo y la de la derecha es la hoja. Por ejemplo si tenemos 532, 574, 533, 591, 603, 617 y 648, la cifra de la izquierda es el tallo (5 en los primeros, 6 en los últimos) y el siguiente (redondeado) serían las hojas (3, 7, 7, 9, 0, 2 y 5). Ahora el diagrama sería: 5|3779 6|025 Como en el histograma, vemos que en el intervalo 500 a 600 tenemos 4 datos y en el de 600 a 700 tenemos 3. Lo que permite este diagrama, que no permite el histograma, es ver el valor de cada elemento. Esto nos permite detectar cosas interesantes. Supongamos el siguiente diagrama: 3|2256788999 4|1389 5|000112356 Parece a primera vista que hay muchos “3” y “5” y pocos “4”. Pero podemos ver que hay varios “3|9” y “5|0” lo que nos hace concluir que hay un número similar de “3”, “4” y “5” y que la diferencia aparente es pura casualidad. Esto no se puede apreciar en un histograma. La instrucción de R para crear un diagrama de tallo y hojas es stem(): Peso = c(42, 45, 45, 45, 45, 45, 46, 47, 47, 47, 48, 49, 49, 49, 49, 50, 50, 50, 52, 53, 54, 54, 55, 55, 55, 55, 56, 56, 57, 57, 58 , 60, 62, 62, 62, 63, 63, 64, 64, 65, 66, 66, 67, 69 , 70, 72, 74 , 75, 76, 77, 77, 78, 80, 81, 81, 81, 82) stem(Peso) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 4 | 2 ## 4 | 55555677789999 ## 5 | 0002344 ## 5 | 555566778 ## 6 | 02223344 ## 6 | 56679 ## 7 | 024 ## 7 | 56778 ## 8 | 01112 Fijaos que la salida empieza con la frase “The decimal point is 1 digit(s) to the right of the |”. Con sólo “4|2” no sabemos si representa 4,2 o 0,00042 o 4200. Esta frase nos indica que es “42” Diagrama de cajas. El diagrama de cajas (o de caja y bigotes) parte de los cuartiles y la mediana. Para construirlo debemos primero calcular la mediana, Q1 y Q3. Después calculamos el rango intercuartílico que es la resta Q3 – Q1. La caja la delimitan Q1 y Q3, con una raya que indica Q2. A veces se añade un punto o un diamante que representa la media. Los bigotes llegan hasta el dato más alejado a la caja pero que esté a menos que 1,5 veces el rango intercuartílico. Los datos que están más allá de los bigotes se representan como círculos y los podemos considerar datos atípicos potenciales. En la figura siguiente vemos un diagrama de cajas creado con la función boxplot() de R. Un diagrama de cajas nos permite ver bien la asimetría, tanto de la parte central como de los extremos, y si hay algún valor atípico. 3.4 Análisis de los datos Cómo hemos dicho, miramos los datos para entenderlos mejor. ¿Pero entender el qué? Empecemos por estudiar tres características esenciales: la modalidad, la simetría y la presencia de valores atípicos. 3.4.1 Modalidad Si miramos un histograma, la modalidad es el número de picos que tenemos. Por ejemplo la figura siguiente nos muestra dos poblaciones unimodales. Es cierto que vemos fluctutaciones pequeñas, pero eso son artefactos típicos de los histogramas y realmente, en ambos casos, sólo hay un pico, es decir, un modo. En cambio en la figura siguiente vemos un histograma claramente bimodal. Esta gráfica es de longitud de una muestra de hormigas y vemos que en nuestra muestra hay dos poblaciones, ya sea dos tipos de hormiga diferentes o dos castas de hormigas, obreras y soldados, de un mismo tipo. La modalidad se puede ver con el histograma, el de tallo y hojas e incluso con el de puntos (donde cada modo se muestra como una aglomeración de puntos). Un diagrama de cajas no muestra esta característica. Hay que ir con cuidado de no confundir pequeñas fluctuaciones, como los de las gráficas unimodales de arriba, con los modos. Que una variable sea unimodal significa que tenemos una población homogénea, con más o menos dispersión. Si además es simétrica, es muy fácil describir los datos: basta dar la media y la desviación típica. Si la variable es bimodal, como la figura anterior, suele querer decir que tenemos dos poblaciones. No tiene mucho sentido dar un sólo conjunto de datos para ambas: supongamos que tenemos dos especies de hormigas muy distintas. Dar la “media de la longitud de las hormigas” es absurdo. En este caso es conveniente dividir las dos poblaciones (esto lo tiene que hacer un experto en hormigas o en la población bajo estudio) y estudiar cada uno por separado. Pero esto no siempre es posible: por ejemplo la talla y peso de la población de personas es bimodal ya que los hombres y las mujeres tiene alturas y pesos diferentes, pero si estamos diseñando los asientos de un tren o avión, no podemos tener asientos para hombres y asientos para mujeres y tendremos que considerar la población en conjunto. 3.4.2 Simetría Ninguna variable real es exactamente simétrica, por lo tanto una leve asimetría es de esperar. Lo que da características propias a una variable es que sea moderada o fuertemente asimétrica, como es el caso de la figura siguiente. En este caso la media es poco representativa de la población: sólo una fracción pequeña está cerca del valor medio. Normalmente la mediana (y los cuartiles) dan una información más reveladora. Otra cosa a tener en cuenta es que la desviación típica nos da poca información en una variable muy asimétrica ya que el “montículo” con más población quizá noesté dentro del rango media ± desviación. Todas las gráficas nos permiten ver la asimetría: el histograma, el diagrama de puntos, el de tronco y hojas, pero el que lo muestra más claramente es el de cajas, en donde se ve si hay asimetría tanto en donde se encuentra la parte “central” de la población (dentro de la caja) como la más periférica (los bigotes). La figura siguiente nos muestra un diagrama de cajas de una variable claramente asimétrica y con valores atípicos 3.4.3 Valores atípicos Al mirar unos datos a menudo puedes ver una gran mayoría que muestran unas características comunes, pero con uno o unos pocos que se alejan del grupo. Estos son los llamados valores atípicos (o outliers). Estos valores tiene una gran influencia en el cálculo de la media (en cambio no en el de la mediana), o a la hora de estimar la tendencia. Las loterías usan de estos valores extremos: un único gran premio hace que la media de lo que se puede obtener sea razonable (alrededor del 75% de lo apostado), mientras que lo más probable sea que no ganes nada. Por eso hay que estudiar estos valores atípicos con detenimiento. A menudo son errores (hemos tecleado 190.5 en vez de 109.5, o tenemos medidas erróneas debido a un fallo de la batería). En este caso la solución es sencilla: se eliminan estos valores. En cambio otras veces son valores reales. En este caso se deben identificar y ya es cuestión del especialista (con nuestra ayuda) decidir qué hacer con ellos. Hay dos gráficas donde los valores atípicos se ven muy bien: el diagrama de cajas y el diagrama de puntos. Se ven peor en histogramas y diagramas de tallo y hojas. 3.4.4 Problematicidad El objetivo de la estadística es sacar pronósticos e inferencias a partir de los datos que nuestra muestra. Si los datos son muy “regulares” podemos tener una buena confianza en nuestros pronósticos e inferencias, pero si son muy irreguares, dudamos mucho más de nuestras deducciones. A veces se dice que tenemos “buenos datos” o “malos datos”, pero esto es erróneo: los datos son los que son, no son ni buenos ni malos. Aquí vamos a utilizar el término “problemático” para describir los datos. Si los datos son poco problemáticos, podemos tener bastante confianza en nuestras deducciones. Si son muy problemáticos, muy poca. Otra manera de verlo es que si tenemos datos poco problemáticos y tomamos otra muestra, seguramente haremos las mismas deducciones con la segunda muestra que con la primera. Si son algo problemáticos, la segunda muestra puede ser diferente a la primera. Si son muy problemáticos, una segunda muestra puede parecerse muy poco a la primera, y sacaríamos conclusiones muy diferentes. Aqui es donde entra enormemente la experiencia del estadístico, pero para empezar, con el estudio de la modalidad, asimetría y la presencia o no de valores atípicos, podemos sopesar si nuestros datos son o no problemáticos. Para ellos tenemos que mirar las medidas de centralidad y dispersión y todas las gráficas posibles. Si tenemos suerte los datos seran unimodales, simétricos y sin valores atípicos. Son datos nada problemáticos. El caso ideal es ver algo parecido a una campana de Gauss. En este caso una muestra pequeña nos bastará y las deducciones que hagamos serán bastante fiables. Si tenemos peor suerte los datos serán bimodales, o asimétricos o tendrán algún valor atípico. En este caso nuestros datos son algo problemáticos. Necesitamos una muestra mucho mayor para tener unos resultados algo fiables. El pero caso es si es multimodal, fuertemente asimétrico y con valores muy atípicos. Incluso con muestras muy grandes no nos podremos fiar gran cosa de nuestros resultados. En estos casos extremos, generalmente no podemos hacer deducción alguna a partir de los datos, aunque casi siempre lo intentaremos. Es esencial recordar que hay muchísima incertidumbre y cualquier deducción que hagamos puede estar muy alejado de la realidad. "],
["estadística-descriptiva-de-datos-cualitativos-univariantes.html", "Capítulo 4 Estadística descriptiva de datos cualitativos univariantes 4.1 Tablas de contingencia 4.2 Gráficas para datos cualitativos 4.3 Conclusión", " Capítulo 4 Estadística descriptiva de datos cualitativos univariantes En el capítulo anterior discutimos la estadística descriptiva de los datos que están formados por una variable numérica. En este vamos a extender la discusión al caso de una variable cualitativa. Como veremos, hay menos cálculos y gráficas a considerar, aunque esto no hace que el análisis sea más fácil. 4.1 Tablas de contingencia Una variable cualitativa es aquella cuyos valores son conceptos o términos, sobre los que no se puede operar. El ejemplo típico es el color de los ojos o el sexo. Recordemos que aunque algunas variables cualitativas pueden representarse mediante un número (por ejemplo el mes o el año), pero no puede operarse sobre ese número: 2 (febrero) + 3 (marzo) no es 5 (mayo) o el año 1914 más el 1930 no hacen el año 3844. A los posibles valores que puede recibir un factor se les llama niveles. El sexo sólo puede tener dos niveles, que podemos llamar “hombre” y “mujer” o “masculino” y “femenino”, mientras que podemos crear una variable cualitativa con el estado civil con 4 niveles: “soltero”, “casado”, “divorciado” y “viudo”. A menudo es una decisión del que toma los datos el establecer cuántos niveles. Por ejemplo, en el caso del estado civil podríamos añadir el estado de “pareja de hecho” o dividir los casados en “casado civil” y “casado por la iglesia”. Todo depende de qué es lo que queremos estudiar. Es muy importante, antes de empezar a tomar los datos, el determinar qué niveles puede tener nuestra variable y qué nombre tendrán. Muchas, muchas, horas se han perdido porque alguno de los tomadores de datos no ha distinguido entre “azul” y “gris” mientras otros sí lo han hecho. O porque uno ha llamado “marrón” a lo que otro ha llamado “castaño”. Igual atención se ha de prestar a exactamente cómo se va a escribir cada nivel. R, y muchos programas, distingue entre mayúsculas y minúsculas, o la existencia o no de acentos. Para R son distintos “marron”, “marrón”, “Marron” y “Marrón”. Dado que por su propia naturaleza no puede operarse con los valores de las variables, no podemos calcular ni medias ni medianas ni desviaciones típicas. Lo único que podemos hacer es contar: cuántas personas de nuestra muestra tienen ojos azules, o son hombres, o cuántas veces se estropeó una máquina en abril. En general, podemos contar cuántos individuos de la muestra tienen un valor concreto. Los resultados se escriben en una tabla que recibe el nombre de tabla de contingencia. El paquete MASS de R contiene muchos conjuntos de datos. El conjunto survey es una encuesta hecha a estudiantes de estadística de la U. de Adelaida en Australia. Uno de los datos que contiene es si los estudiantes fuman o no. Hay 4 posible niveles: “Heavy”, “Regul”, “Occas” y “Never” que representan a los fumadores fuertes, regulares, ocasionales y no fumadores respectivamente. Podemos contar cuántos hay en cada nivel y escribirlo como una tabla. Esto es la tabla de contingencia: library(MASS) table(survey$Smoke) ## ## Heavy Never Occas Regul ## 11 189 19 17 No hay que contarlo a mano, naturalmente. La función table() de R se ocupa de hacerlo por nosotros. Para obtener la tabla mostrada he ejecutado la instrucción table(survey$Smoke). Es muy probable que además del número de individuos en cada categoría nos interese el porcentaje. Basta con contar el número total de individuos (236) y dividir. O utilizar la función prop.table() de R. Esta función actúa sobre una tabla y no sobre los datos “crudos”. prop.table(table(survey$Smoke)) ## ## Heavy Never Occas Regul ## 0.04661017 0.80084746 0.08050847 0.07203390 Y esto es todo lo que podemos hacer numéricamente sobre una variable de tipo factor. 4.2 Gráficas para datos cualitativos Sólo hay dos gráficas habituales para una variable numérica: el diagrama de barras y el diagrama de tarta (o quesitos). Empecemos por esta segunda. Diagrama de tarta. El diagrama de tarta no debe usarse. Coge un papel y lápiz y dibuja dos barras, una el doble de alta que la otra. Si el papel es cuadriculado es una tarea trivial. E incluso si es un papel blanco, no es difícil dibujar sin regla las dos barras con una precisión muy aceptable. Ahora dibuja un círculo y divídelo en dos porciones, una con el doble de superficie que la otra. Sin un transportador, un compás o alguna otra herramienta de dibujo y cierto conocimiento de dibujo técnico es casi imposible hacerlo con un mínimo de precisión. Y si no somos capaces de dibujar algo tan simple, tampoco somos capaces de leerlo. Fijaos que esto lo “resuelven” en muchas publicaciones poniendo el número al lado de cada porción. Y entonces la gente lee el número en vez de mirar la gráfica. Es decir, que la gráfica no sirve para nada. El diagrama de tarta no debe usarse. Para más información de por qué no debe usarse, mirad la ayuda de R de la función pie(). Diagrama de barras. Un diagrama de barras es la representación simple de la tabla de contingencia: hay una barra por nivel y la altura de la barra es proporcional al valor en la tabla. Bajo cada barra está el nombre del nivel. La figura siguiente muestra el diagrama de barras de nuestra tabla de contingencia. Vemos en la figura que medimos el número de ocurrencias de cada nivel. Naturalmente también podríamos medir el porcentaje si lo quisiéramos. Lo único que cambiaría son los números que aparecen en el eje vertical. Una cosa a tener en cuenta a la hora de hacer un diagrama de barras es el orden de los niveles. En este ejemplo, hay un cierto orden implícito: fumar mucho es más que fumar regularmente que es más que fumar ocasionalmente que es más que fumar poco. Pero si estamos considerando enfermedades, por ejemplo, no hay ningún orden lógico entre la alergia y el dolor de espalda. R, y muchos otros programas, lo que hacen es ordenarlo en orden alfabético, que es un orden muy malo, como vemos en la figura de debajo: el lector tiene dificultades en interpretar lo que ve. Es mucho mejor de mayor a menor o de menor a mayor, como se muestra en las figuras siguientes. 4.2.1 Gráficos 3D Los gráficos 3D no deben hacerse nunca. Son todo apariencia: más bonitas pero mucho más difíciles de leer. Mirad la figura de debajo. Son los mismos datos que las de la figura anterior. ¿Cuánta gente hay con dolor de espalda? Intentad establecer el valor en ambas gráficas. ¿En cual es más fácil hacerlo? Y naturalmente, nunca, nunca hay que crear un diagrama de tarta en 3D. 4.3 Conclusión Por su propia naturaleza, son pocas las operaciones que podemos hacer sobre variables cualitativas. Numéricamente podemos contar cuántos individuos hay en cada nivel, y a lo más calcular el porcentaje. Tampoco hay muchos gráficos posibles: el único útil es el diagrama de barras. "],
["estadística-descriptiva-de-datos-bivariantes.html", "Capítulo 5 Estadística descriptiva de datos bivariantes 5.1 Dos variables numéricas 5.2 Una variable numérica y una cualitativa 5.3 Dos variables cualitativas 5.4 Resumen", " Capítulo 5 Estadística descriptiva de datos bivariantes Una vez visto cómo escribir datos de una variable, veamos cómo describir datos de dos variables. Cómo tenemos dos tipos de variables, numéricos y cualitativos, tenemos tres casos: dos variables numéricas, una numérica y una cualitativa, y dos variables cualitativas. Cada una tiene sus métodos y sus gráficas. 5.1 Dos variables numéricas En este caso, y en todos, primero hay que estudiar cada variable por separado utilizando las técnicas ya explicadas. Si alguna de las dos (o las dos) son muy problemáticas, tenemos que ir con precaución y saber que las inferencias que podamos hacer pueden no ser fiables. Hay que estudiarlas por separado pues se ve mucho mejor la modalidad, simetría e incluso los valores atípicos por separado que todo junto. 5.1.1 Gráfica de nube de puntos La gráfica más habitual a la hora de representar dos variables numéricas es la nube de puntos (en inglés scatterplot). Hay que decidir qué variable va en el eje horizontal, cuál va en la vertical, escoger bien la escala y dibujarlo. Veamos un ejemplo. Tenemos una resistencia, le aplicamos voltajes de 3 en 3 voltios y medimos la intensidad que pasa por el circuito. Los resultados que obtenemos los introducimos en R. Hemos aplicado el voltaje y hemos medido la intensidad. En este caso se debe poner el voltaje (el estímulo) en el eje X y la intensidad (la respuesta) en el eje Y. La instrucción para dibujarlo es plot(): V = c(3, 6, 9, 12, 15, 18, 21, 24, 27, 30) I = c(0.021, 0.049, 0.093, 0.111, 0.159, 0.183, 0.204, 0.219, 0.270, 0.301) plot(V,I) Una primera cosa que vemos es que los puntos se ajustan muy bien a una curva, en este caso una recta. Decimos que las dos variables están fuertemente correlacionadas. La figura siguiente muestra un gráfico en donde no se ajustan tan bien y están débilmente correlacionadas. Y ahora mostramos una nube de puntos en el que no vemos curva alguna. Las variables probablemente no estén correlacionadas. 5.1.2 Rectas de regresión Un cálculo que se puede hacer para tener una idea más clara de lo que significan los datos es calcular y dibujar la recta de regresión, esto es, la recta que mejor se ajusta a los puntos. Hacerlo a mano es lento, pero en un ordenador es inmediato. La instrucción de R para hacerlo es lm(y~x). La forma de escribir la función parece un poco rara. Se entiende mejor si se lee el símbolo “~” como “en función de”. Así la funcion sería la que calcula la recta de regresión de \\(y\\) en función de \\(x\\). En el caso de la resistencia la instrucción sería recta = lm(I~ V). Hemos asignado el resultado a la variable recta lo que nos será un poco más cómodo más adelante. A través de summary() obtenemos la información más importante: recta = lm(I~V) summary(recta) ## ## Call: ## lm(formula = I ~ V) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0177576 -0.0043182 0.0002424 0.0060455 0.0131515 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.0056667 0.0063554 -0.892 0.399 ## V 0.0101010 0.0003414 29.585 1.85e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.009303 on 8 degrees of freedom ## Multiple R-squared: 0.9909, Adjusted R-squared: 0.9898 ## F-statistic: 875.3 on 1 and 8 DF, p-value: 1.847e-09 De todo esto, en estos momentos sólo interesa lo que hay bajo Estimate y tras Adjusted R-squared. Lo que hay bajo Estimate nos da la recta. Tenemos que \\(I = -0.005 + 0.010\\cdot V\\). Tras Adjusted R-squared tenemos el coeficiente de correlación. Es un número que siempre va a estar entre \\(0\\) y \\(1\\). Como está muy cerca de 1, tenemos una muy fuerte correlación. Si estuviera cerca de 0 apenas habría correlación. Podemos añadir la recta a la gráfica con la función abline(). Con las instrucciones plot(V,I) abline(recta, col = &quot;red&quot;) añadimos la recta a la gráfica en color rojo. Haciendo un lm() en los otros dos casos vemos que el coeficiente de correlación es mucho menor: 0,64 en el caso de la correlación débil y 0,07 en el caso de la correlación apenas existente. 5.2 Una variable numérica y una cualitativa Como muchos nórdicos son altos y con ojos azules, nos preguntamos si hay alguna correlación entre la altura de una persona y su color de ojos. Escogemos una buena muestra y tomamos los datos: el color de ojos y la altura de cada individuo. Obtenemos un data frame más o menos como el siguiente: ColorOjos Altura Azul 177 Marron 187 Azul 155 Marron 173 Marron 177 Verde 186 ... ... Como se ha dicho en el apartado anterior, lo primero que se debe hacer es un estudio de cada variable por separado. Es decir, una tabla de contingencia y un diagrama de barras del color de ojos y medidas de centralidad y dispersión y un diagrama de caja, histograma, etc. de las alturas. Una vez hecho esto, podemos empezar el estudio conjunto. Esencialmente el estudio conjunto es hacer un estudio de la variable numérica para cada nivel del factor. En este caso, coger las alturas de los individuos de cada color de ojos, y estudiar la altura para cada caso. Esto implica hacer, por ejemplo, cuatro histogramas, uno para cada color de ojos. Cuatro histogramas separados son difíciles de comparar y por lo tanto poco útiles. Hay dos diagramas, el de puntos y el de cajas que se prestan a verlos en conjunto y éstos son los que más se usan. Además R facilita su creación. El diagrama de puntos se crea con la instrucción stripchart() y el operador ~: stripchart(OA$Altura~ OA$ColorOjos), es decir, un diagrama de puntos para las alturas en función del color de ojos. Siempre ha de ser la variable numérica en función de la variable cualitativa. Podemos ver el resultado en la figura siguiente. El de cajas se crea de forma muy similar, con la instrucción boxplot(OA$Altura~ OA$ColorOjos): variable numérica en función de la variable cualitativa. Podemos ver el resultado en la figura siguiente. En el diagrama de puntos vemos gráficamente ya lo sabíamos por la tabla de contingencia del color de ojos que habíamos hecho: que hay pocos datos de gente con ojos verdes y ojos negros y por lo tanto el que el diagrama de cajas salga algo distinto, no significa mucho. Y el “valor atípico” de los ojos verdes, tampoco. Y entre los ojos azules y marrones, no parece que haya mucha diferencia. Las inferencias estadísticas nos darán más información, pero si hay una diferencia, parece que es pequeña. 5.3 Dos variables cualitativas Ya vimos que con las variables cualitativas lo único que podíamos hacer era contar. Y con dos variables cualitativas pasa lo mismo, sólo que ahora podemos contar cuántos hay en cada intersección de niveles. Esto quiere decir que la tabla de contingencia ya no es unidimensional, sino bidimensional. Para explicarlo usemos un ejemplo típico: el color de ojos y de pelo. Usemos datos de 476 personas. Los datos está en un data frame de dos columnas: Pelo Ojos 1 Castaño Negro 2 Castaño Verde 3 Negro Marron 4 Castaño Negro 5 Negro Marron ... Vemos que el primer individuo tiene pelo castaño y ojos negros, el segundo tiene pelo castaño y ojos verdes, etc. Los posibles niveles del color de pelo son “Rubio”, “Pelirrojo”, “Castaño” y “Negro”, y de los ojos son “Azul”, “Verde”, “Marron” y “Negro”. Si hacemos una tabla de contingencia por cada variable tenemos: Rubio Pelirrojo Castaño Negro 76 22 311 67 Azul Verde Marrón Negro 64 87 304 21 Hagamos ahora la tabla de las dos variables. No nos importa en este momento qué variable formará las filas y cuál por columnas. En R el primer parámetro de la función table() serán las filas y la segunda serán las columnas. Por lo tanto, si escribimos table(Pelo, Ojos) nos da la tabla: Azul Verde Marrón Negro Total Rubio 31 25 16 4 76 Pelirrojo 0 9 11 2 22 Castaño 28 48 225 10 311 Negro 5 5 52 5 67 Total 64 87 304 21 476 Si hubiéramos ejecutado table(Ojos, Pelo) nos daría la tabla traspuesta: con el color de pelo en las columnas y el de ojos en las filas. Esta tabla de contingencia nos da cuántos individuos hay en cada intersección de niveles: cuántos rubios con ojos azules, pelirrojos con ojos verdes, etc. Pero nos puede interesar tener las proporciones o los porcentajes. La cuestión es que hay varias maneras de hacerlo. Una es que cada celda sea el porcentaje del total. Por ejemplo, los rubios con ojos azules son 31 de 476, por lo tanto un 6,5% del total. Pero otra posibilidad que a menudo nos interesa es el porcentaje de cada nivel de una de las variables. En este caso, de las 64 personas con ojos azules, 31 son rubias, es decir el 48,4% de las personas de ojos azules son rubias; y de los 76 rubios, 31 tienen los ojos azules, es decir, el 40,8% de los rubios tienen los ojos azules. Estas tres tablas de contingencias de proporciones se suelen identificar como “el total suma 1”, “las columnas suman 1” y “las filas suman 1”. En R las tres se consiguen con la instrucción prop.table(), que recordemos se aplica a la tabla y no al data frame. Desgraciadamente la función no tiene una sintaxis muy intuitiva. El código de R para conseguirlas y las tablas resultantes son: # Leemos los datos PO = read.table(&quot;datos/PeloOjos.csv&quot;, sep = &quot;;&quot;,header = TRUE) # Creamos una variable con la tabla POT = table(PO) # Total suma 1 prop.table(POT) ## Ojos ## Pelo Azul Marron Negro Verde ## Castanyo 0.058823529 0.472689076 0.021008403 0.100840336 ## Negro 0.010504202 0.109243697 0.010504202 0.010504202 ## Pelirrojo 0.000000000 0.023109244 0.004201681 0.018907563 ## Rubio 0.065126050 0.033613445 0.008403361 0.052521008 # Filas suman 1 prop.table(POT,1) ## Ojos ## Pelo Azul Marron Negro Verde ## Castanyo 0.09003215 0.72347267 0.03215434 0.15434084 ## Negro 0.07462687 0.77611940 0.07462687 0.07462687 ## Pelirrojo 0.00000000 0.50000000 0.09090909 0.40909091 ## Rubio 0.40789474 0.21052632 0.05263158 0.32894737 # Columnas suman 1 prop.table(POT,2) ## Ojos ## Pelo Azul Marron Negro Verde ## Castanyo 0.43750000 0.74013158 0.47619048 0.55172414 ## Negro 0.07812500 0.17105263 0.23809524 0.05747126 ## Pelirrojo 0.00000000 0.03618421 0.09523810 0.10344828 ## Rubio 0.48437500 0.05263158 0.19047619 0.28735632 Nótese que en la primera (“el total suma 1”) el total de fila nos dice la proporción de rubios, pelirrojos, etc, y los totales de columna nos muestra las proporciones de ojos azules, verdes, etc. Al igual que en el caso de una única variable cualitativa, el único diagrama adecuado es el diagrama de barras. Pero es un diagrama un poco más complejo ya que tenemos que representar las dos variables. Lo que se hace es agrupar por una variable y en cada agrupación representar los valores de la otra. La primera decisión es decidir por qué variable queremos agrupar. Digamos que queremos agrupar por color de ojos. Ahora tenemos dos formas de agrupar: apilar los valores o ponerlos uno al lado de otro. La figura siguiente muestra las dos posibilidades. Vemos que es necesario añadir una leyenda para conocer los niveles en cada agrupación. El diagrama apilado tiene más sentido cuando las proporciones de cada grupo suman 1, como vemos: R agrupa por columnas, por lo tanto si queremos agrupar por color de pelo, que son las filas en nuestro ejemplo, como ya hemos dicho, tenemos que recrear las tablas de contingencia cambiando el orden de las dos variables en la función table(). Otra posibilidad es trasponer la tabla de contingencia con la función t(). Vemos el resultado en la figura siguiente. Aunque no se vea directamente, las frecuencias de cada agrupación suman 1. 5.4 Resumen Si tenemos dos variables tenemos tres posibles casos, que sean ambas numéricas, que una sea numérica y la otra un factor o que sean ambas factores. Sea cuál sea el caso, primero debemos estudiar cada variable por separado. Una vez hecho esto Si las dos variables son numéricas la gráfica adecuada es la nube de puntos. Si los puntos siguen una recta o curva, diremos que están fuertemente correlacionadas. Si lo siguen aproximadamente, están débilmente correlacionadas. Si no vemos curva alguna, no están correlacionadas. Si siguen una recta, entonces la función de R lm() nos dará la recta que más se acerca a los puntos y el coeficiente de correlación. Si una variable es numérica y la otra un factor, entonces debemos estudiar los valores de las variables numéricas para cada nivel del factor. Las gráficas más adecuadas para esto son el diagrama de puntos y el de cajas, ya que nos permite verlo fácilmente de forma global. Si ambas variables son cualitativas, entonces hay que crear las tablas de contingencia. Si son de proporciones, hay tres tablas posibles: que el total sume 1, que las columnas sumen 1 y que las filas sumen 1. La única gráfica adecuada es el diagrama de barras agrupado según los niveles de una de las dos variables, la que más nos convenga. Podemos agrupar las barras apilándolas en una sola o poniéndolas una al lado de otra. "],
["uso-de-r-para-estadística-descriptiva-tutorial.html", "Capítulo 6 Uso de R para estadística descriptiva. Tutorial 6.1 Data frames 6.2 El caso de una variable cuantitativa 6.3 El caso de una variable cualitativa 6.4 El caso de dos variables cuantitativas 6.5 El caso de dos variables, una cuantitativa y una cualitativa 6.6 El caso de dos variables cualitativas 6.7 Resumen final", " Capítulo 6 Uso de R para estadística descriptiva. Tutorial 6.1 Data frames El data frame es la estructura de datos más utilizada en R. Es la tabla de datos de un experimento. Cada fila es un individuo y cada columna son las características medidas de ese individuo. Por ejemplo un individuo podría ser un alumno y las características la edad, el sexo, el número de créditos matriculados y el curso. O el individuo podría ser una máquina de una fábrica y las características, la marca, el modelo, la fecha de compra, fecha de la última reparación, etc. De esta estructura se deduce que cada columna es de un tipo (numérico, carácter, etc) mientras que diferentes columnas son de diferentes tipos. Por ejemplo tenemos un data frame llamado Alumnos, con columnas para Sexo, Edad, Créditos matriculados y Curso: Sexo = c(&quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;) Edad = c(19, 19, 20, 18, 21, 19) Creditos = c(60, 54, 60, 69, 66, 48) Curso = c(2, 2, 3, 2, 3, 3 ) Alumnos = data.frame(Sexo,Edad, Creditos, Curso) Alumnos ## Sexo Edad Creditos Curso ## 1 M 19 60 2 ## 2 M 19 54 2 ## 3 F 20 60 3 ## 4 M 18 69 2 ## 5 F 21 66 3 ## 6 M 19 48 3 Es importante recordar que esta debe ser la estructura. Cuando se opera sobre un data frame R espera que sea así: no se puede intercambiar filas por columnas. Se puede calcular la media de una columna (media de edad, por ejemplo) pero no de una fila, ya que sumar créditos y edad no tiene sentido. Podemos por ejemplo hacer un summary() de todo el data frame para obtener las información fundamental de los datos y R nos lo hace columna a columna: summary(Alumnos) ## Sexo Edad Creditos Curso ## F:2 Min. :18.00 Min. :48.0 Min. :2.0 ## M:4 1st Qu.:19.00 1st Qu.:55.5 1st Qu.:2.0 ## Median :19.00 Median :60.0 Median :2.5 ## Mean :19.33 Mean :59.5 Mean :2.5 ## 3rd Qu.:19.75 3rd Qu.:64.5 3rd Qu.:3.0 ## Max. :21.00 Max. :69.0 Max. :3.0 Aunque se puede hacer, R no está diseñado para crear y editar data frames. Es mucho mejor crearlos en una hoja de cálculo, exportarlos en formato CSV y después leerlos desde R. En la próxima sección enseñaremos cómo se lee un data frame. 6.2 El caso de una variable cuantitativa Empecemos por leer los datos. Tenemos en la carpeta de datos el fichero “Salud.csv”, un data frame con datos de 57 personas: la altura, el peso, el sexo y si padecen alguna enfermedad. La leemos con la instrucción read.table() y miramos las primeras líneas con head() Salud = read.table(&quot;datos/Salud.csv&quot;,sep = &quot;;&quot;, header = T, row.names = 1,dec = &quot;,&quot;) head(Salud) ## Talla Peso Sexo Enfermedades ## ID001 175 63.7 Hombre Ninguna ## ID002 160 60.0 Hombre Colesterol ## ID003 160 45.4 Mujer Espalda ## ID004 167 54.7 Mujer Alergia ## ID005 170 62.2 Hombre Colesterol ## ID006 182 81.4 Hombre Colesterol Los parámetros de read.table() son: - el nombre del fichero, - el carácter que se usa en el fichero para separar celdas: en nuestro caso “;” (esto depende de cada hoja de cálculo. Hasta que no estés seguro de cuál usa tu hoja de cálculo, inspecciona el fichero antes de leerlo) - si la primera fila es una cabecera o no (en este caso lo es) - si hay una columna con el nombre de los individuos (en este caso es la primera) y - cuál es el separador decimal (en este caso es la coma, es decir usamos “5,34” y no “5.34”). Empecemos por estudiar las características del data frame Salud y de paso vamos conociendo las instrucciones que R tiene para ello. Para acceder a una columna entera del data frame usamos el nombre del data frame, seguido del símbolo $ seguido del nombre de la columna. En nuestro ejemplo, Salud$Enfermedades es la columna de enfermedades o Salud$Peso es la de peso. Veamos el tipo de datos del data frame y de cada columna: class(Salud) ## [1] &quot;data.frame&quot; class(Salud$Talla) ## [1] &quot;integer&quot; class(Salud$Peso) ## [1] &quot;numeric&quot; class(Salud$Sexo) ## [1] &quot;factor&quot; class(Salud$Enfermedades) ## [1] &quot;factor&quot; Veamos los tipos de enfermedad recogidos en la tabla levels(Salud$Enfermedades) ## [1] &quot;Alergia&quot; &quot;Colesterol&quot; &quot;Espalda&quot; &quot;Ninguna&quot; &quot;Respiratorio&quot; Extraigamos las columnas Talla y Peso y pongámosla en variables. En cuanto tengamos un poco más de dominio de R no haremos esto, pero para un principiante es más sencillo. Lo haremos de dos formas diferentes para aprender las posibilidades de R: Talla = Salud$Talla Peso = Salud[,&quot;Peso&quot;] Talla ## [1] 175 160 160 167 170 182 180 180 172 166 165 173 180 165 176 168 179 175 175 ## [20] 160 160 182 177 180 174 181 168 160 173 170 160 188 170 177 165 178 164 163 ## [39] 172 181 164 165 168 161 159 165 162 163 160 170 163 160 157 169 180 180 181 Peso ## [1] 63.7 60.0 45.4 54.7 62.2 81.4 69.6 69.1 62.1 53.6 49.4 57.0 71.7 50.2 66.2 ## [16] 61.5 74.2 63.5 62.6 48.0 45.4 74.5 77.0 81.4 56.9 81.7 56.4 46.7 54.9 54.7 ## [31] 45.4 67.3 54.9 64.7 53.9 76.2 52.9 46.7 58.2 76.6 48.7 48.8 51.6 44.9 48.8 ## [46] 49.5 47.3 50.1 45.3 65.9 62.6 45.8 42.0 56.2 81.3 77.9 79.7 El primer caso es adecuado si se quiere la columna entera, el segundo es el que se debe usar si que quiere una parte de la columna. Si no se pone nada, se refiere a todas. Por lo tanto en este caso Salud[,&quot;Peso&quot;] significa “En data frame Salud, todas las filas, columna”Peso&quot;”. Por ejemplo, si queremos separar los pesos de los hombres y las mujeres en dos vectores debemos hacer: TallaH = Salud[Salud$Sexo == &quot;Hombre&quot;, &quot;Talla&quot;] TallaM= Salud[Salud$Sexo == &quot;Mujer&quot;, &quot;Talla&quot;] PesoH = Salud[Salud$Sexo == &quot;Hombre&quot;, &quot;Peso&quot;] PesoM= Salud[Salud$Sexo == &quot;Mujer&quot;, &quot;Peso&quot;] En este caso Salud[Salud$Sexo == &quot;Mujer&quot;, &quot;Peso&quot;] significa “en data frame Salud, filas en las que Salud$Sexo sea igual a”Mujer“, columna”Peso&quot;”. Describamos, es decir, obtengamos una visión global de las variables numéricas. Empecemos por la media y la desviación típica: mean(Talla) ## [1] 170.1404 sd(Talla) ## [1] 8.003211 mean(Peso) ## [1] 59.62982 sd(Peso) ## [1] 11.7349 R nos permite obtener los datos principales de una variable mediante la instrucción summary(): summary(Talla) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 157.0 163.0 170.0 170.1 177.0 188.0 summary(Peso) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 42.00 49.40 56.90 59.63 67.30 81.70 Ahora “veamos” los datos. Empecemos por el diagrama de tallo y hojas: stem(Talla) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 15 | 79 ## 16 | 000000001233344 ## 16 | 55555678889 ## 17 | 000022334 ## 17 | 55567789 ## 18 | 00000011122 ## 18 | 8 stem(Peso) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 4 | 2 ## 4 | 55555677789999 ## 5 | 0002344 ## 5 | 555566778 ## 6 | 02223344 ## 6 | 56679 ## 7 | 024 ## 7 | 56778 ## 8 | 01112 Este diagrama era popular antes de la disponibilidad de ordenadores. Claramente es para hacer a mano, pero sigue siendo útil, sobre todo si se tienen pocos datos. Otro diagrama muy usado es el de caja, que obtenemos con la instrucción boxplot() boxplot(Talla) boxplot(Peso) El tercer diagrama que veremos es el de puntos. A menudo se le llama dotplot pero en R la instrucción se llama stripchart(): stripchart(Talla) stripchart(Peso) Y el último que veremos es el conocido histograma: hist(Talla) hist(Peso) En el paquete UsingR se incluye una instrucción que permite dibujar simultáneamente el histograma y el diagrama de cajas. Para ello primero hemos de cargar el paquete. library(UsingR) ## Loading required package: HistData ## Loading required package: Hmisc ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## Loading required package: ggplot2 ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units ## ## Attaching package: &#39;UsingR&#39; ## The following object is masked from &#39;package:survival&#39;: ## ## cancer Nos indica otros paquetes que también carga y nos da algunos avisos a los que no hacemos caso. Y ahora podemos usar la instrucción simple.hist.and.boxplot() simple.hist.and.boxplot(Talla) simple.hist.and.boxplot(Peso) Es importante notar que ambos diagramas no están a la misma escala. Con esto acabamos con las instrucciones para describir una variable cuantitativa. 6.3 El caso de una variable cualitativa Veamos ahora las instrucciones que tiene R para el caso de una variable cualitativa (o factor). Ya hemos visto que la instrucción levels() nos permite inspeccionar los posibles valores de un factor. Empecemos por extraer las columnas como antes Sexo = Salud$Sexo Enfermedades = Salud$Enfermedades Es fácil darse cuenta que no hay medias de nada, por lo tanto no podemos calcular medias ni medianas ni nada de todo eso. Lo único que podemos hacer numéricamente es contar cuantos elementos hay en cada categoría. Para ello R nos proporciona la instrucción table() table(Sexo) ## Sexo ## Hombre Mujer ## 26 31 table(Enfermedades) ## Enfermedades ## Alergia Colesterol Espalda Ninguna Respiratorio ## 8 16 11 10 12 En el caso del sexo, como sólo hay dos, no es muy interesante. El de las enfermedades lo es algo más. Vemos que en los datos contenidos en Salud hay 8 personas con alergia, 16 con colesterol, etc. Para verlo de forma gráfica hagamos un diagrama de barras con la instrucción barplot(). Nuestro primera impulso es escribir barplot(Enfermedades). Pero si lo hacemos, recibiremos un mensaje de error: Error in barplot.default(Enfermedades) : &#39;height&#39; must be a vector or a matrix Al principio, como todos los lenguajes, R es muy misterioso con sus mensajes de error. Con el tiempo se van entendiendo. Este nos dice que necesita un valor para poder dibujar la barra y no lo encuentra. Esto es porque hemos pasado el vector de enfermedades y no el conteo de cuántos hay en cada uno. Hagámoslo bien: barplot(table(Enfermedades)) Tenemos nuestro diagrama de barras. Pero los diagramas se ven mejor si los datos están ordenados de más frecuente a menos frecuente (o al revés, de menos a más). Hagamos esto paso a paso. Primero recojamos la tabla en una variable: TabEnf = table(Enfermedades) Lo ordenamos de mayor a menor con la instrucción sort() TabEnf = sort(TabEnf, decreasing = T) Y ahora podemos dibujar el diagrama de barras: barplot(TabEnf) Y con esto hemos visto cómo describir una estadística de una variable y las instrucciones que R nos proporciona par ello. En la próxima sección veremos como describir estadísticas de dos variables 6.4 El caso de dos variables cuantitativas Siempre que tengamos dos variables hemos de empezar por estudiar cada una por separado usando las técnicas descritas hasta ahora. Después podemos estudiarlas en conjunto. Veamos como. Si las dos variables son numéricas lo que corresponde es una nube de puntos Esto se consigue con la instrucción plot() plot(Talla, Peso) La primera variable es la “x” y la segunda la “y”. Vemos que hay una clara correlación: a tallas mayores corresponden pesos mayores. Casi podemos adivinar una recta. Esta recta es la llamada recta de regresión Para obtener la recta y alguna idea numérica de la correlación usamos la instrucción lm(). Esta es una instrucción que hace muchas, muchas cosas. Ya la iremos conociendo mejor. No os asuste la gran cantidad de información que da. La aplicamos TallaPeso = lm(Peso~Talla) summary(TallaPeso) ## ## Call: ## lm(formula = Peso ~ Talla) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.7775 -3.3811 -0.8744 2.7544 13.6833 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -163.74509 14.99511 -10.92 2.17e-15 *** ## Talla 1.31289 0.08804 14.91 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.273 on 55 degrees of freedom ## Multiple R-squared: 0.8017, Adjusted R-squared: 0.7981 ## F-statistic: 222.4 on 1 and 55 DF, p-value: &lt; 2.2e-16 La manera de pasar los parámetros extraña un poco. Es más facil de recordar si sabes que ~ se lee “en función de”. Por lo tanto Peso~Talla es “Peso en función de la talla”. De todo esto ahora nos interesan dos cosas Talla 1.31289 y Multiple R-squared: 0.8017. El primer dato es la pendiente de la recta de regresión y nos indica que por cada cm que crece la persona pesa 1.3 Kg más y que la Talla explica el 80% de la variabilidad observada en el peso: estos datos muestran que se pesa más porque se es más alto (80%) y otras cosas (20%). Podemos dibujar la recta sobre nuestros puntos. Lo haremos en rojo: plot(Talla, Peso) abline(TallaPeso, col = &quot;red&quot;) 6.5 El caso de dos variables, una cuantitativa y una cualitativa Una vez visto el caso de dos variables cuantitativas, pasemos al caso de que una variable sea cuantitativa y otra cualitativa. En este caso lo que hay que hacer es separar la variable cuantitativa en conjuntos, uno por categoría de la variable cualitativa y comparar los resultados y gráficas. Se puede hacer “a mano”. Hemos separado antes las tallas de hombres y mujeres y ahora podemos comparar los resultados numéricos. summary(TallaH) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 160.0 172.8 177.5 175.8 180.0 182.0 summary(TallaM) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 157.0 160.0 165.0 165.4 168.5 188.0 Vemos que la talla media y mediana es superior en los hombres. Curiosamente la mujer más alta es más alta que el hombre más alto. Podemos también crear gráficas, por ejemplo los histogramas: hist(TallaH) hist(TallaM) No es lo mejor, puesto que es difícil comparar los histogramas. Es más simple si podemos tener ambas gráficas una al lado de otra. Aunque se puede hacer “a mano“, lo más fácil es dejar que R se encargue. Para eso tenemos el operador ~ (que recordemos se lee “en función de”). Los diagramas de caja de la talla en función del sexo las podemos dibujar con este operador: boxplot(Talla~Sexo) Intentemos entender qué hace R: mira en ”Sexo“ los diferentes sexos posibles, separa las tallas y dibuja. Vemos en la gráfica que los hombres son más altos, con la excepción del ”outlier“ de 188 cm visto antes en las mujeres. Podemos hacer lo mismo para ver el peso en funcion de las enfermedades: boxplot(Peso~Enfermedades) Por algún motivo parece que los que padecen alergia pesan algo menos que los demás. Podemos también dibujar stripcharts con el mismo método: stripchart(Talla~Enfermedades) Y con esto acabamos la descripción del caso de una variable cuantitativa y una cualitativa. Finalmente nos queda analizar el caso de dos variables cualitativas. 6.6 El caso de dos variables cualitativas En el caso de una variable cualitativa creábamos tablas unidimensionales y dibujábamos diagramas de barras. En el caso de dos variables creamos tablas bidimensionales. llamadas tablas de contingencia. Para ahorrarnos escribir código, meteremos la tabla en una variable tse = table(Sexo, Enfermedades) tse ## Enfermedades ## Sexo Alergia Colesterol Espalda Ninguna Respiratorio ## Hombre 1 11 4 7 3 ## Mujer 7 5 7 3 9 Notamos que hay muchas más mujeres con alergias que hombres. Esto quizá explique la diferencia de peso visto antes. Esta tabla de contingencia muestra frecuencias absolutas: por ejemplo vemos que hay en Salud 11 personas con dolor de espaldas: 7 hombres y 4 mujeres. Nos podría interesar más tener los porcentajes. Aunque es fácil hacerlo a mano, R tiene la función prop.table() para esto. La primera cuestión es qué tipo de porcentajes queremos (o tres posibles ”cienes“). El primero es quizá el que primero se nos podría ocurrir:”cien“ es el número total de individuos en Salud prop.table(tse) ## Enfermedades ## Sexo Alergia Colesterol Espalda Ninguna Respiratorio ## Hombre 0.01754386 0.19298246 0.07017544 0.12280702 0.05263158 ## Mujer 0.12280702 0.08771930 0.12280702 0.05263158 0.15789474 Notad que se aplica prop.table() sobre la tabla, no los datos originales. En este caso el resultado de cada celda es el porcentaje sobre el total: Los hombres sin ninguna enfermedad representan el 12.3% del total. A veces nos interesa calcular procentajes dentro de cada variable. Por ejemplo si queremos que ”cien“ sea el número total de hombres o de mujeres, segun tenga sentido la instrucción es: prop.table(tse,1) ## Enfermedades ## Sexo Alergia Colesterol Espalda Ninguna Respiratorio ## Hombre 0.03846154 0.42307692 0.15384615 0.26923077 0.11538462 ## Mujer 0.22580645 0.16129032 0.22580645 0.09677419 0.29032258 La notación de añadir un 1 (o un 2 como veremos pronto) es poco intuitiva pero es la que hay. De estos datos vemos que el 22.6% de las mujeres sufren de alergia el 16,1% de colesterosl, el 22,6% sufren de la espalda, el 29% tienen problemas respiratorios y el 9,7% gozan de buena salud. las filas suman siempre 1. Si queremos calcular porcentajes según la otra variable, es decir, siqueremos que ”cien“ sea el número de individuos en cad a categoría de enfermedad la instrucción es: prop.table(tse,2) ## Enfermedades ## Sexo Alergia Colesterol Espalda Ninguna Respiratorio ## Hombre 0.1250000 0.6875000 0.3636364 0.7000000 0.2500000 ## Mujer 0.8750000 0.3125000 0.6363636 0.3000000 0.7500000 En este caso vemos que entre los que sufren de alergia el 12.5% son hombres y el 87.5% son mujeres. Ambas columnas suman 1. Pasemos a la gráfica. Podemos aplicar la función barplot() directamente sobre el resultado de prop.table(): barplot(prop.table(tse,2)) En este diagrama el gris claro representa a las mujeres y el gris oscuro a los hombres. Veamos otra manera de ver gráficamente la diferencia de enfermedades entre mujeres y hombres: tes = table(Enfermedades, Sexo) tes ## Sexo ## Enfermedades Hombre Mujer ## Alergia 1 7 ## Colesterol 11 5 ## Espalda 4 7 ## Ninguna 7 3 ## Respiratorio 3 9 barplot(prop.table(tes,2), beside = T) El parámetro beside = T nos permite agrupar las barras una al lado de otra. Hemos creado una nueva variable por un detalle técnico: R siempre agrupa los barplots por columnas, por lo tanto hemos tenido que crear la tabla de forma adecuada. El parámetro beside = T nos agrupa las barras. Notad que cada conjunto de barras suma 1. Vemos claramente en el diagrama que en los hombres el colesterol predomina, mientras que entre las mujeres no hay una enfermedad predominante. Hubiéramos podido aplicar la instrucción barplot() directamente sobre la variable, sin pasarlo por prop.table() y a veces es lo que conviene. Probadlo y veréis la diferencia e iréis aprendiendo cuándo usar una y cuándo la otra. 6.7 Resumen final Hemos visto como describir de forma numérica y gráfica una variable numerica, una variable cualitativa y conjuntos de dos variables ya sea cuantitativa-cuantitativa, cuantitativa-cualitativa o cualitativa-cualitativa. En el caso de una variable cuantitativa teníamos summary() apra obtener un conjunto de información (mínimo, máximo, media, mediana y dos cuartiles). Hemos visto como dibujar un diagrama de tallo y hojas, de cajas, de puntos y un histograma. Si la vartiable es cualitativa hemnos de contar con table() el número de individuos en cada categoría. Esto lo podemos mostrar gráficamente con un diagrama de barras. Si tenemos dos variables primero las hemos de estudiar por separado. Después las podemos estudiar en conjunto. Si las dos variables son cuantitativas lo dibujamos mediante una nube de puntos. La compleja función lm() nos permite dibujar la recta de regresión y obtener alguna información numérica de esta recta y de la correlación. En el caso de una variable cuantitativa y una cualitativa hemos de hacer un estudio cuantitativo, con los números y diagramas, para los individuos en cada categoría y compararlos. El operador ~ nos puede resultar útil. Y en el último caso, dos variables cualitativas, hemos de crear las tablas de contingencia. Hemos de decidir qué tipo de porcentaje queremos. Finalmente podemos dibujar diagrams de barras de agrupaciones de barras. "],
["probabilidad.html", "Capítulo 7 Probabilidad 7.1 Ideas básicas 7.2 Operaciones con probabilidades 7.3 Probabilidad condicionada 7.4 Regla de Bayes 7.5 Resumen", " Capítulo 7 Probabilidad La probabilidad es el lenguaje de la incertidumbre. Y dado que la estadística vive en la incertidumbre, es el lenguaje de la estadística. En estadística no tenemos certezas, sólo tenemos probabilidades: los resultados de la estadística son todos de la forma «La probabilidad de que esta estrategia de inversión te dé ganacias es del 65%» o «La probabilidad de que la media de la población esté dentro del intervalo de confianza es del 95%». No sólo para entender los resultados de la estadística, sino para entender qué es lo que hace es imprescindible poder entender el lenguaje de la probabilidad. Vamos a ello. 7.1 Ideas básicas En nuestros estudios estadísticos hemos tomado datos del color de ojos y pelo de 476 personas y del grupo sanguíneo y factor Rh de 173 472 personas. Las tablas de contingencia son: Color Pelo \\ Ojos Azul Verde Marron Negro Total Rubio 31 25 16 4 76 Pelirrojo 0 9 11 2 22 Castaño 28 48 225 10 311 Negro 5 5 52 5 67 Total 64 87 304 21 476 Factor \\ Grupo A B AB 0 Total Rh+ 58 990 13 885 4338 62 461 139 674 Rh- 13 882 3470 1041 15 675 34 068 Total 72 872 17 355 5379 78 136 173 742 Consideramos estas tablas como nuestra evidencia \\(E\\) de la proporción de gente con cierto color de pelo y de ojos y con cierto grupos sanguíneo y factor Rh. Es decir, vamos a suponer que toda nuestra población de interés sigue los números que muestra esta tabla. Entonces, si escogemos al azar una persona, la probabilidad de que sea rubia es P(Rubia\\(|E\\)) = 76/476 = 0,160. Esto se lee como «Probabilidad de que una persona escogida al azar sea rubia dada la evidencia que tenemos es 0,160». Es fundamental notar que esta probabilidad depende de la evidencia de partida. Otra persona, con otros datos y otra tabla de contingencia, obtendría probabilidades diferentes. Si son buenas muestras de la misma población, generalmente no diferirán en mucho. La probabilidad de ser de tipo sanguíneo A es P(A\\(|E\\)) = 72 872/173 742 = 0,419. En palabras: la probabilidad de que una persona escogida al azar sea de tipo A dada la evidencia que tenemos es de 0,419. Más ejemplos. La probabilidad de ser una persona pelirroja de ojos marrones dada la evidencia que tenemos es de 0,023 (P(Pelirroja y Marron\\(|E\\)) = 11/476 = 0,023). O la probabilidad de ser de grupo AB+ dada la evidencia que tenemos es 0,025 (P(AB y Rh+\\(|E\\)) = 4338/173 742 = 0,023). Para ser más ágil se suele eliminar el «dada la evidencia que tenemos» y el «\\(|E\\)» de las expresiones. Y a partir de ahora apenas lo usaremos. Pero es fundamental recordar que está. Y por lo tanto debemos exponerla como parte de nuestro razonamiento. Diferentes estudios de lo mismo, por ejemplo diferentes encuestas electorales, dan resultados diferentes porque parten de evidencia diferente. Si volvemos a repetir el estudio, obtendremos resultados diferentes. Esperamos que si lo hacemos todo bien la diferencia será pequeña (podemos hacerlo todo bien ambas veces y obtener diferencias grandes. Eso pasa), pero la habrá. Esta visión que hemos descrito y que suele ser la que casi todo el mundo intuye, es la llamada visión frecuentista. Se suele resumir con el lema «casos favorables dividido por caso posibles». Pero no todas las probabilidades son frecuentistas. Hay muchas que no pueden serlo. Un caso habitual es cuando hablamos de la probabilidad de que la Real Sociedad gane el próximo partido ante el Athletic de Bilbao. Si siguiéramos la visión frecuentista habría que hacer jugar ambos equipos en las mismas condiciones (alineación, campo, condiciones meteorológicas, árbitro…), digamos 30 veces y dividir el número de victorias entre 30. Esto es imposible. Por lo tanto cogemos otra evidencia («La Real ha ganado sus últimos 3 partidos», «El portero del Athletic está lesionado», «El campo está seco», etc.) y razonar a partir de esta evidencia para obtener una probabilidad. Diferentes aficionados escogen evidencia diferente y le dan peso diferente a cada dato y obtienen probabilidades diferentes. Es importante notar que la probabilidad no es subjetiva. Lo que es subjetivo es la evidencia que se escoge. Pero incluso usamos visiones no frecuentistas en probabilidades tan repetitivas como los dados y monedas. Si decimos que la probabilidad de sacar cara al lanzar una moneda es 1/2 no es por un análisis frecuentista: no tiramos la moneda al aire 1000 veces antes de deducir la probabilidad. Suponemos que la moneda no está trucada y que hay la misma probabilidad de sacar cara que de sacar cruz. Lo mismo con el lanzamiento de un dado. Suponemos que el dado no está cargado y que todas las posibilidades son equiprobables. En el caso de dados y monedas la práctica muestra que este razonamiento funciona bien. Pero no lo hace siempre. Por ejemplo falla con las cartas. Suponemos que la probabilidad de sacar un 7 de diamantes es 1/52, pero eso sólo pasa si las cartas están bien barajadas. Un famoso estudio de Persi Diaconis, que fue mago antes que matemático, demostró que es necesario barajar las cartas 7 veces para poder suponer que todas las cartas tienen la misma probabilidad de salir. Y los tahures lo sabían y podían estimar con bastante precisión la probabilidad de que saliera un 7 de diamantes en función de dónde estaba el 7 de diamantes en la partida anterior, las cartas que acababan de salir y las veces que se había barajado. No todo es saber leer las caras de los contrarios. 7.2 Operaciones con probabilidades Una vez tenemos unas probabilidades básicas, directamente a partir de nuestra evidencia, podemos calcular las probabilidades de casos más complejos. Veamos las operaciones más habituales. 7.2.1 Probabilidad de una cosa u otra Tenemos dos sucesos y queremos calcular la probabilidad de que pasen uno o el otro o ambos. Debemos considerar dos casos. El primero es que los dos sucesos sean incompatibles, es decir, que no puedan darse simultáneamente. El segundo es que no lo sean y sí que puedan darse ambos. Si vamos al típico ejemplo de un dado, dos suceos incompatibles son «sacar un 3» y «sacar un 5». Obviamente, con un solo dado, no podemos sacar un 3 y un 5 a la vez. En ese caso la probabilidad de que suceda uno u otro suceso es la suma de las probabilidades. Matemáticamente: \\[P(A\\mbox{ o }B) = P(A) + P(B).\\] Estrictamente es \\(P(A\\mbox{ o }B|E) = P(A|E) + P(B|E)\\) pero como dijimos, damos la evidencia por entendida y no la ponemos enlas fórmulas. Si los sucesos no son incompatibles esta expresión es incorrecta. Supongamas que los sucesos son «ser rubios» y «tener ojos azules». Ya hemos calculado que la probabilidad de ser rubio es \\(P(\\mbox{Rubio}) = 0,160\\). De forma similar, la probabilidad de tener ojoz azules es \\(P(\\mbox{Azules}) = 64/476 = 0,134\\). Si los sumamos tendríamos una probabilidad (incorrecta) de \\(0,294\\). Pero si lo calculamos directamente de la tabla, sumando las 7 celdas de la primera fila y la primera columna (que son los casos que nos interesan) tenemos una probabilidad (correcta) de: \\((31+25+16+4+0+28+5)/476 = 0,229\\). El error viene que en la forma incorrecta hemos contado dos veces a los rubios de ojos azules: en los rubios y en los ojos azules. Por lo tanto lo que tenemos que hacer es restarlos: restar aquellos que son simultáneamente rubios y de ojos azules. Esto nos da la expresión par el caso de que no sean incompatibles: \\[P(A\\mbox{ o }B) = P(A) + P(B) - P(A \\mbox{ y } B).\\] Algunos habréis notado que esta segunda expresión engloba también el primer caso: si los sucesos son incompatibles \\(P(A \\mbox{ y } B) = 0\\). 7.2.2 Probabilidad de una cosa y otra La segunda probabilidad que nos puede interesar calcular es la de que se den simultáneamente dos sucesos, \\(P(A \\mbox{ y } B)\\). Empecemos por suponer que los sucesos son independientes: que el que uno suceda o no no tiene nada que ver con que lo haga el otro. Si tiramos dos dados, uno azul y uno rojo, lo que haga el dado azul no va a influir en el rojo. En este caso la probabilidad de que sucedan ambas cosas es el producto de las probabilidades. La probabilidad de que el dado azul saque un 5 y el rojo un 2 es \\[P(\\mbox{azul} = 5\\mbox{ y rojo} = 2) = P(\\mbox{azul} = 5) \\cdot P(\\mbox{rojo} = 2) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36}.\\] Esto no es lo mismo que tener dos dados blancos indistinguibles, tirarlos y sacar un 2 y un 5. En este caso tenemos dos posibilidades que nos interesan: que el primer dado tenga un 5 y el otro un 2 o que el primer dado tenga un 2 y el otro un 5. La probabilidad es 1/18. ¿Y qué pasa si los sucesos no son independientes? En este caso no tenemos ninguna expresión general de la probabilidad de \\(P(A \\mbox{ y } B)\\). Por ejemplo, la probabilidad de \\(P(\\mbox{Rubio}) = 0,160\\), la de \\(P(\\mbox{Azules}) = 0,134\\). Pero la probabilidad de \\(P(\\mbox{Rubio y azules}) = 31/476 = 0,065\\), que es mucho mayor al producto de probabilidades, que es \\(0,160 \\cdot 0,134 = 0,021\\), mientras que la probabilidad de ser pelirrojo con ojos marrones es mucho menor que el producto de las probabilidades. La pregunta ahora es, ¿cómo sabemos si dos sucesos son independientes o no? A veces nos lo dicta la lógica: dos dados no interfieren entre sí, o la fase de la luna no interfiere con la probabilidad de que un gato sea negro. El resto de las veces no lo sabemos. Realmente lo hemos hecho al revés: se define que dos sucesos son independientes si la probabilidad de que se den los dos simultáneamente es igual al producto de las probabilidades. Acabamos de ver que el color de ojos y de pelo no son independientes. Pueden comprobar que en cambio el tipo sanguíneo y factor Rh sí que lo son. Para ello hay que calcular \\(P(A+), P(A-), P(B+),\\) etc y ver que en todos los caso es igual al producto de probabilidades. Veamos un caso. \\(P(A+) = 58.990/173.742 = 0,339\\) lo que es casi idéntico a \\(P(A) \\cdot P(+) = 0,337\\) (no nos olvidemos que son muestras, pequeñas diferencias son perfectamente normales). Y lo mismo pasa con todas las demás probabilidades. 7.2.3 Probabilidad del suceso contrario La probabilidad de que pase algo es 1: si tiramos un dado no sabemos qué número saldrá, pero sí sabemos que saldrá uno entre 1 y 6. Si consideramos _todas_ las salidas posibles, la probabilidad de que pase alguna de ellas ha de ser 1. Matemáticamente, si \\(A_{1}, A_{2}\\dots A_{n}\\) son todos los sucesos posibles, \\[\\sum P(A_{i}) = 1.\\] Este resultado es muy útil para detectar errores. Por ejemplo, si sumamos \\(P(\\mbox{Ganar}) + P(\\mbox{Perder})\\) y no nos sale 1 nos daremos cuesta que se nos ha olvidado el caso del empate. Siempre que trabajemos con probabilidades nos evitaremos errores, y a la larga ahorraremos tiempo, si hacemos la simple comprobación de que la suma de probabilidades debe dar 1. Y e resultado también es útil para simplificar enormemente los cálculos de algunas probabilidades. Supongamos que hay \\(N\\) plazas de aparcamiento, y que para cada plaza la probabilidad de que esté libre es \\(L\\). ¿Cuál es la probabilidad de que alguna de las \\(N\\) esté libre? Una plaza de aparcamiento o está libre o está ocupada. Si la probabilidad de que esté libre es \\(L\\), la de que esté ocupada, su suceso contrario, es \\((1-L)\\). Si alguna está libre puede ser que lo esté sólo 1, que lo estén 2, lo estén 3, …, hasta que lo estén todas. Son sucesos incompatibles, por lo tanto podemos calcular cada probabilidad por separado y sumarlas. Aseguro que calcular la probabilidad de que \\(N-3\\) de las \\(N\\) plazas estén libres no es tarea fácil. Por suerte hay una manera mucho más simple. El que esté alguna libre es el suceso contario a que estén todas ocupadas. Si suponemos que la probabilidad de que una esté ocupada es independiente a la probabilidad de que lo esté cualquier otra, lo que parece razonable si \\(N\\) no es muy grande, entonces la probabilidad es el producto de las probabilidades: \\[\\begin{eqnarray*} P(\\mbox{Todas ocupadas}) &amp; = &amp; P(\\mbox{pl. 1 ocupada})\\cdot P(\\mbox{pl. 2 ocupada})\\cdots P(\\mbox{pl. }N\\mbox{ ocupada)}\\\\ &amp; = &amp; (1-L) \\cdot (1-L)\\cdots (1-L)\\\\ &amp; = &amp; (1-L)^{N} \\end{eqnarray*}\\] Y nos queda: \\[P(\\mbox{Alguna libre}) = 1 - P(\\mbox{Todas ocupadas}) = 1 - (1-L)^{N}\\] Si tenemos que calcular la probabilidad de que algo pase y no sabemos hacerlo fácilmente, siempre conviene preguntarse si es más fácil calcular la probabilidad de que no pase. 7.3 Probabilidad condicionada Hemos visto la probabilidad de «ser rubio o tener los ojos azules» y la de «ser rubio y tener los ojos azules». Nos falta otra: la prababilidad de que «un rubio tenga los ojos azules». Hay quien confunde «ser rubio con ojos azules» con «siendo rubio, tener los ojos azules». En el primer caso la población bajo consideración (los «casos posibles») es todo el mundo, mientras que en el segundo son sólo los rubios. Otra manera de describirlo. En el primer caso escogemos una persona al azar y miramos su color de ojos y pelo; en el segundo escogemos una persona rubia al azar y miramos su color de ojos. No es un concepto extraño. Es calcular la probabilidad de ganar el partido si jugamos en casa, que claramente es diferente de la probabilidad de ganar si jugamos fuera, o la probabilidad de ganar sin tener en cuenta dónde jugamos. A esta probabilidad se le llama probabilidad condicionada y se representa por \\(P(A|B)\\). Como hemos visto esto se puede describir en palabras como «la probabilidad de que un B (rubio) tenga A (ojos azules)», «la probabilidad de A (tener ojos azules) dado que pasa B (ser rubio)», «la probabilidad de A (tener ojos azules) si B (se es rubio)». También podemos decir que es «la probabilidad de A condicionado a que pase B». Si tenemos una tabla como las del apartado 1, podemos calcular estas probabilidades sacando los datos directamente de la tabla. La probabilidad de tener los ojos azules si se es rubio es 31/64: de 64 personas rubias, 31 tienen los ojos azules. Por lo tanto \\(P(\\mbox{azules}|\\mbox{rubio}) = 0,484\\). De este cálculo es fácil deducir una expresión general: \\[P(A|B) = \\frac{P(A\\mbox{ y } B)}{P(B)}.\\] Efectivamente: \\(P(A\\mbox{ y } B) = 31/476\\) y \\(P(B) = 64/476\\), por lo que \\[P(A|B) = \\frac{P(A\\mbox{ y } B)}{P(B)} = \\frac{31/476}{64/476} = \\frac{31}{64}.\\] Esta expresión es válida tanto si \\(A\\) y \\(B\\) son independientes como si no. Si son independientes tenemos una cosa interesante: \\[P(A|B) = \\frac{P(A\\mbox{ y } B)}{P(B)} = \\frac{P(A)\\cdot P(B)}{P(B)} = P(A)\\] % Esta expresión nos confima que si son independientes \\(B\\) no influye en \\(A\\): a \\(A\\) le da igual si \\(B\\) pasa o no pasa. Su probabilidad es siempre \\(P(A)\\). Una última cosa. No es lo mismo \\(P(A|B)\\) que \\(P(B|A)\\). Si cogemos un hombre, la posibilidad de medir más de 2,00 m no es muy alta. Digamos que es 0.05 (un 5%). En cambio, si cogemos una persona que mide más de 2,00 m, la probabilidad de que sea un hombre es muy alta. Probablemente más de 0.99. Desgraciadamente, a menudo en la vida nos dan la probabilidad condicionada que nos interesa menos. Digamos que nos hacemos una prueba médica para saebr si tenemos una enfermedad grave (algún tipo de cáncer o el virus VIH). Y sale positivo. Naturalmente nos preocupamos. Y más cuando el médico nos dice «la probabilidad de dar positivo si se está enfermo es del 90%». Eso es \\(P(\\mbox{Positivo}|\\mbox{Enfermo})\\). Esa no es la probabilidad que nos interesa. La que nos interesa es la probabilidad de que estemos enfermos dado que hemos dado positivo, \\(P(\\mbox{Enfermo}|\\mbox{Positivo})\\). En la siguiente sección veremos cómo calcular esto. 7.4 Regla de Bayes Eres una persona sana, sin síntomas de ninguna enfermedad y sin antecedentes de cáncer de pecho (mujeres) o de próstata (hombres) en tu familia. Pero dentro del programa de detección precoz viene incluido gratuitamente una mamografía (mujeres) para detectar el cáncer de pecho o una prueba de PSA (hombres) para detectar el de próstata. Y te haces la prueba. Y sale positivo. ¿Debes preocuparte? Los números que voy a usar aquí son aproximadamente reales para ambos tipos de cáncer. Cambian con el tiempo y la prueba, pero en estos momentos y con las pruebas que tenemos los datos son los que se citan aquí. Siendo una persona sin antecedentes familiares, la probabilidad de tener cáncer de pecho o próstata es de 0,5% (según datos de la Asociación Española contra el Cáncer). La mamografía o el PSA, cuando hecha sobre una persona enferma, dan positivo el 90% de las veces, y negativo el 10% restante. Si la persona no está enferma, el test da positivo el 9% de las veces, y negativo el 91% de las veces. Con estos datos podemos calcular la probabilidad que nos interesa: la probabilidad de que estemos enfermos dado que hemos dado positivo, \\(P(\\mbox{Enfermo}|\\mbox{Positivo})\\). Supongamos que tenemos 10 000 personas sin síntomas. Sabemos que 50 tienen cáncer y 9950, no. Pasamos la prueba a todas ellas. De las 50 que tienen cáncer, 45 (El 90%) dan positivo y 5 dan negativo. De las 9950 sanas, 895 (el 9%) dan positivo y el resto dan negativo. Ponemos esto en un cuadro: Sanas Enfermas Total Test Positivo 895 45 940 Test Negativo 9055 5 9060 Total 9950 50 10000 Ahora podemos responder a la pregunta que nos interesa: ¿Cuál es la probabilidad que, habiendo dado positivo, esté enfermo? De los 940 que han dado positivo, 45 están enfermos. Por lo tanto es 45/940 = 0,048, un 5%. Esto no quiere decir que las pruebas son inútiles. Si se está en un grupo de riesgo, por ejemplo porque haya antecedentes familiares, la probabilidad de tener cáncer ya no es el 0,5%, sino que es mucho mayor. Imagina que es un 20% y repite los cálculos. En este caso sí hay motivo de preocupación y tiene sentido hacerse pruebas de detección precoz. Lo que hemos hecho es aplicar de una forma calculística el teorema de Bayes. Este teorema nos permite relacionar \\(P(A|B)\\) con \\(P(B|A)\\). En formato de ecuación se expresa como: \\[ P(A|B) = \\frac{P(B|A)\\, P(A)}{P(B)}\\] En nuestro ejemplo: \\[ P(\\mbox{Enfermo}|\\mbox{Positivo}) = \\frac{P(\\mbox{Positivo}|\\mbox{Enfermo})\\, P(\\mbox{Enfermo})}{P(\\mbox{Positivo})}\\] Sabemos que \\(P(\\mbox{Positivo}|\\mbox{Enfermo}) = 0,9\\) y que \\(P(\\mbox{Enfermo}) = 0,05\\). De la tabla podemos obtener que \\(P(\\mbox{Positivo}) = 0,094\\), y entonces \\[ P(\\mbox{Enfermo}|\\mbox{Positivo}) = \\frac{0,9 \\cdot 0,005}{0,094} = 0,048\\] 7.5 Resumen La probabilidad es el lenguaje de la estadística y debemos saberlo conversar. La visión frecuentista parte de la idea de «casos favorables dividido entre casos posibles» y es la más intuitiva. Pero cuando no hay casos que contar, debemos usar otra visión. A partir de las probabilidades iniciales, podemos calcular la probabilidad de que suceda un evento u otro, \\(P(A\\mbox{ o }B)\\), sucedan dos simultáneamente, \\(P(A\\mbox{ y }B)\\), o suceda una condicionado a otra, \\(P(A|B)\\). Si los sucesos son incompatibles \\(P(A\\mbox{ o }B) = P(A) + P(B)\\); si no \\(P(A\\mbox{ o }B) = P(A) + P(B) - P(A\\mbox{ y }B)\\). Si son independientes \\(P(A\\mbox{ y }B) = P(A)\\cdot P(B)\\) y \\(P(A|B) = P(A)\\). Si no lo son, no tenemos una manera directa de calcular \\(P(A\\mbox{ y }B)\\). Tanto si son independientes como si no, \\(P(A|B) = P(A\\mbox{ y }B)/P(B)\\). La regla de Bayes nos da una manera de calcular \\(P(A|B)\\) a partir de \\(P(B|A)\\). Las probabilidades condicionadas son más comunes, y en general más fáciles de calcular, que las probabilidades absolutas (sin condicionar). Es por eso que es importante saber usarlas y conocer cómo operar con ellas. "],
["variables-aleatorias.html", "Capítulo 8 Variables aleatorias 8.1 ¿Qué es una variable aleatoria? 8.2 Cálculo de probabilidades", " Capítulo 8 Variables aleatorias Tienes dos dados en la mano y los vas a tirar. ¿Qué va a salir? Sólo sabes que será un número entre 2 (si sacas dos 1) y 12 (si sacas dos 6). El valor que vas a sacar a los dados cuando los tires, cada vez que los tires, es un valor que no conoces de antemano. En probabilidad y estadística a lo deconocdo se le suele llamar aleatorio y una variable que va a tomar un valor a priori desconocido se le llama variable aleatoria. En este documento vamos a estudiar las características que tienen estas variables aleatorias y cómo podemos cuantificar la incertidumbre que tenemos con ellas. 8.1 ¿Qué es una variable aleatoria? 8.1.1 Variables discretas Empecemos con los dados azul y rojo. Lo que queremos es de alguna manera cuantificar la incertidumbre de los dos dados. En este caso simple lo que podemos hacer es indicar en una tabla la probabilidad de sacar cada valor para cada dado: Azul Rojo Valor: 1 2 3 1 2 3 Probabilidad: 1/3 1/3 1/3 1/6 1/3 1/2 A esta función, que para cada valor de una variable indica la probabilidad que aparezca, se llama una función de masa. En nuestro ejemplo hemos indicado las funciones de masa de forma tabular, pero también lo podríamos haber hecho como una expresión algebraica. Para ello necesitamos un poco de notación. En el caso de funciones discretas, llamaremos \\(k\\) al valor que puede tomar la variable aleatoria. Tambien aparecerá el símbolo \\(n\\) que suele indicar el número de valores diferentes o al valor máximo que puede tomar la variable (suele quedar claro por el contexto). En este caso de los dados azul y rojo, \\(k\\) puede valer 1, 2 o 3 y \\(n\\) es 3. Las funciones de masa las podemos describir como: \\[a(k) = \\frac{1}{n} \\qquad r(k) = \\frac{k}{2n}\\] Puedes comprobar que esto se corresponde con los valores de la tabla. Podemos definir formalmente la función de masa: la función de masa \\(f(k)\\) de una variable aleatoria \\(X\\) es la probabilidad de que \\(X\\) tome el valor \\(k\\): \\[f(k) = \\mbox{P}(X = k)\\] Veamos otro caso discreto, este infinito. Lanzamos un dado al aire hasta que nos salga cruz. Nos interesa saber cuántas caras han salido hasta llegar a esta primera cruz. Podemos tener 0 caras si la primera vez que lanzamos sacamos una cruz. La probabilidad de esto es \\(1/2\\). Para tener 1 cara debe salirnos primero una cara y después una cruz. Suponiendo razonablemente que las tiradas son independientes, la probabilidad de esto es \\(1/2\\cdot 1/2 = 1/4\\). Para sacar exactamente 2 caras, debemos sacar cara la primera vez, cara la segunda vez, y cruz la tercera. La probabilidad de esto es \\(1/2\\cdot 1/2 \\cdot 1/2= 1/8\\). No es difícil darse cuenta que la función de masa \\(f(k)\\) es \\[f(k) = P(\\mbox{núm. caras} = k) = \\frac{1}{2^{k+1}}\\] Aunque es extremadamente improbable tener más de una docena de caras seguidas, \\(k\\) puede potencialmente extenderse hasta el infinito. Esto nos impide describir esta función como una tabla y debemos hacerlo con una expresión. La función de masa es una manera de describir la distribución de una variable aleatoria. Hay otra, menos intuitiva, pero más útil, sobre todo antes de la disponibilidad de los ordenadores, que es la llamada función acumulativa de distribución. La palabra clave es acumulativa. Si la función de masa \\(f(k)\\) es la probabilidad de que la variable aleatoria \\(X\\) valga \\(k\\), la acumulativa \\(F(k)\\) es la probabilidad acumulada hasta \\(k\\). Es decir, la probabilidad de que valga \\(k\\) o menos: \\[F(k) = P(X = 1) + P(X = 2) + \\cdots + P(X = k) = \\mbox{P}(X \\leq k)\\] Es decir que \\(F(1) = f(1)\\), \\(F(2) = f(1) + f(2)\\), etc. (hemos supuesto que \\(k\\) empezaba por 1. No tiene por qué ser así). Esta función, un tanto extraña, facilitaba el cálculo de probabilidades, como ilustraremos en el apartado correspondiente. Con la llegada de los ordenadores la diferencia es mucho menor, pero estas funciones siguen apareciendo en escritos y cálculos y por lo tanto sigue siendo necesario saber cómo son. Para nuestro ejemplo de los dados azul y rojo obtenemos: Azul Rojo Valor: 1 2 3 1 2 3 f(k) (masa): 1/3 1/3 1/3 1/6 1/3 1/2 F(k) (distribución): 1/3 2/3 1 1/6 1/1 1 8.1.2 Variables continuas Cuando la variable es continua, la definición de función de masa ya no sirve. No sirve porque la probabilidad de que la variable aleatoria coja un valor concreto es siempre 0. ¿Cuál es la probabilidad de que una persona mida exactamente \\(55 \\pi\\) cm? Esto es 172,787594743… cm. Habrá mucha gente que mida alrededor de 173 cm, ¿pero 172,787594743… sin desviarse nada de los infinitos decimales? Imposible. Pues lo mismo con 175 cm, es decir 175,000000…cm. La probabilidad es 0. Por lo tanto no podemos tener una función de masa como en el caso discreto. Lo que tenemos es una función que hace un papel similar y que se llama función de densidad. En la figura siguiente tenemos la función de densidad de la distribución normal, la conocida campana de Gauss. Vemos que para \\(x = 0\\) la densidad vale alrededor de 0,4 y que para \\(x = 1,7\\) vale aproximadamente 0,1. Notad que para las variables continuas usamos \\(x\\) para los valores de la variable. Esto no quiere decir que la probabilidad de que la variable aleatoria \\(X\\) valga 0 es 0,4. Ya hemos dicho que es 0. Lo que sí quiere decir que es unas 4 veces más probable que la variable valga algo que esté _alrededor} del 0 que algo que esté alrededor del 1,7. La función se llama de densidad debido a esto: la probabilidad es más “densa” alrededor del 0 que alrededor del \\(2\\) y del \\(-2\\), y es casi 0 alrededor del \\(4\\) y del \\(-4\\). La definición formal es la siguiente. Sea \\(dP[ x &lt; X &lt; x + dx]\\) la probabilidad diferencial de que la variable aleatoria \\(X\\) se encuentre entre los valores \\(x\\) y \\(x + dx,\\) entonces la función \\(f(x)\\) es la que cumple que: \\[f(x)\\, dx = dP[ x &lt; X &lt; x + dx]\\] Es decir, \\(f(x)\\, dx\\) es la probabilidad diferencial de que la variable aleatoria \\(X\\) se encuentre entre los valores \\(x\\) y \\(x + dx\\). Al igual que en el caso discreto, tenemos la función acumulativa de distribución, que se define de la misma manera: como la probabilidad acumulada de que valga \\(x\\) o menos: \\[F(x) = P[X \\leq x]\\] Dada la definición de función de densidad, podemos calcular esta probabilidad como una integral: \\[F(x) = P[X \\leq x] = \\int_{-\\infty}^{x}dP[ t &lt; X &lt; t + dt] = \\int_{-\\infty}^{x} f(t)dt\\] donde usamos \\(t\\) en la función para no confundirlo con la \\(x\\) del límite superior. Otra vez, tenemos una función menos intuitiva, pero que nos será útil para calcular probabilidades. 8.1.3 Propiedades de estas funciones La valores de la función de masa son probabilidades, por lo tanto tienen las características de una probabilidad. Han de ser valores entre 0 y 1 y la suma de todos los valores ha de ser 1. La función de densidad no es una probabilidad, por lo que puede tomar valores mayores que 1. Lo que no puede ser nunca es negativa: una densidad negativa implicaría que por esa zona tenemos probabilidades negativas. La función de distribución, tanto en el caso discreto como en el continuo, es una acumulación de probabilidades. Por lo tanto para \\(X = -\\infty\\) (o para el menor valor de \\(X\\) posible) la función de distribución vale 0 (\\(F(-\\infty) = 0\\)). Para \\(X = \\infty\\) (o para el mayor valor de \\(X\\) posible) hemos acumulado toda la probabilidad, y por lo tanto tiene que valer 1 (\\(F(\\infty) = 1\\)). Además esta función de distribución ha de ser creciente ya que acumulamos probabilidades, que siempre son positivas. En la figura siguiente tenemos dos funciones acumulativas de distribución: a la izquierda la función discreta del número de caras seguidas al tirar un dado antes de sacar la primera cruz, y a la derecha, la de la función normal. En la discreta tenemos saltos de probabilidad en los valores 0, 1, 2, etc. debido a que en esos puntos (y sólo en esos puntos) tenemos cambios en el valor de la probabilidad. 8.2 Cálculo de probabilidades 8.2.1 Calculando a mano Veamos cómo utilizar las funciones de masa, de densidad y de distribución para calcular probabilidades. Empecemos por el caso de variables discretas. Usaremos como distribución para los ejemplos la del número de caras seguidas antes de la primera cruz. Ya vimos que la función de densidad es \\(f(k) = 1/2^{k+1}\\). Se puede deducir que la función de distribución es \\(F(k) = 1 - (1/2^{k+1})\\). Caso 1: \\(P[X = k]\\). Esta es fácil. Es la probabilidad que la variable tome un valor concreto. Eso es, por definición, la función de masa: \\[P[X = k] = f(k)\\] La probabilidad de obtener 3 caras es \\[P[\\mbox{Caras} = 3] = f(3) = \\frac{1}{2^{3+1}} = \\frac{1}{16}\\] Caso 2: \\(P[X \\leq k]\\). Otra que no es difícil. Esto es, por definición, la función acumulativa de distribución: \\[P[X \\leq k] = F(k)\\] La probabilidad de obtener 2 o menos caras es \\[P[\\mbox{Caras} \\leq 2] = F(2) = 1 - \\frac{1}{2^{2+1}} = \\frac{7}{8}\\] Ahora bien, si tenemos la función de masa, pero no la de distribución, lo podemos calcular también: \\[P[X \\leq k] = f(0) + f(1) + \\cdots + f(k)\\] (hemos supuesto que \\(k\\) empieza en 0. Si empieza en otro valor, pues empezamos por ese). En nuestro ejemplo: \\[P[\\mbox{Caras} \\leq 2] = f(0) + f(1) + f(2) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} = \\frac{7}{8}\\] Caso 2(b): ¿Y si es menor estricto \\(P[X &lt; k]\\)? La función de distribución está definida para menor o igual. Si es menor estricto, un pequeño truco: \\[P[X &lt; k] = P[X \\leq k-1] = F(k-1)\\] Atención con los menores estrictos, que son causa de muchos errores. Conviene aprender el truco, pues se usa mucho. Caso 3: \\(P[X &gt; k]\\). Aplicamos la probabilidad del caso contrario: \\[P[X &gt; k] = 1 - P[X \\leq k] = 1 - F(k)\\] La probabilidad de obtener 3 o más caras es \\[P[\\mbox{Caras} &gt; 3] = 1 - F(3) = 1 - \\left(1 - \\frac{1}{2^{3+1}}\\right) = \\frac{1}{16}\\] Si sólo tenemos la función de masa podemos calcular la probabilidad directamente o por el caso contrario. Haremos lo que lleve menos operaciones: \\[P[X &gt; k] = f(k+1) + f(k+2) + \\cdots + f(n) = 1 - (f(k) + f(k-1) + \\cdots + f(0))\\] En nuestro ejemplo sólo podemos hacerlo de la segunda manera: \\[P[\\mbox{Caras} &gt; 3] = 1 - (f(3) + f(2) + f(1) + f(0)) = 1 - \\left(\\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\frac{1}{16}\\right) = \\frac{1}{16}\\] Caso 3(b): ¿Y si es mayor o igual? Ya sabemos qué hacer: \\[P[X \\geq k] = P[X &gt; k-1] = 1 - F(k-1)\\] Caso 4, el caso general: \\(P[k_{1} &lt; X \\leq k_{2}]\\). Suponemos, naturalmente que \\(k_{2} &gt; k_{1}\\). Empecemos en este caso por la función de masa. Es fácil ver que: \\[P[k_{1} &lt; X \\leq k_{2}] = f(k_{1}+1) + f(k_{1} + 2) + \\cdots + f(k_{2}).\\] Para ver cómo calcularlo con funciones acumulativas de distribución vamos a sumar y restar \\(f(0) + f(1) + \\cdots + f(k_{1})\\) (seguimos suponiendo que empezamos en \\(k = 0\\)): \\[P[k_{1} &lt; X \\leq k_{2}] = (f(0) + \\cdots + f(k_{1})) + f(k_{1}+1) + \\cdots + f(k_{2}) -(f(0) + \\cdots + f(k_{1})).\\] Y ahora basta darse cuenta que \\(f(0) + \\cdots + f(k_{2}) = F(k_{2})\\) y que \\(f(0) + \\cdots + f(k_{1}) = F(k_{1})\\). Por lo que queda: \\[P[k_{1} &lt; X \\leq k_{2}] = F(k_{2}) - F(k_{1}).\\] En nuestro ejemplo, la probabilidad de sacar más de 0 pero menos o igual a 4 caras es: \\[P[0 &lt; \\mbox{Caras} \\leq 4] = F(4) - F(0) = \\frac{31}{32} - \\frac{1}{2} = \\frac{15}{32}\\] Si en vez del \\(&lt;\\) tenemos un \\(\\leq\\), o en vez del \\(\\leq\\) tenemos un \\(&lt;\\) aplicamos el truco de siempre. Entonces, por ejemplo, \\[P[k_{1} \\leq X \\leq k_{2}] = P[k_{1}-1 &lt; X \\leq k_{2}] = F(k_{2}) - F(k_{1}-1).\\] Vemos aquí el motivo principal del uso de la función acumulativa de distribución. En vez de tener que sumar 20 o 30 términos, nos basta con restar 2. Pasemos ahora al caso de variables continuas. Hay menos casos debido a que \\(P[X = x] = 0\\). El caso 1 de las discretas ya no interesa. Además no hay que distinguir entre \\(X \\leq x\\) y \\(X&lt;x\\) (o \\(X \\geq x\\) y \\(X&gt;x\\)) ya que la única diferencia entre ambas es \\(P[X = x]\\) que es 0. Como ejemplo usaremos la distribución uniforme entre 0 y 1. Esto quiere decir que cualquier valor real entre 0 y 1 es igualmente probable. La función de densidad es \\(f(x) = 1\\) y la de distribución es \\[F(x) = \\left\\{ \\begin{array}{ll} 0 &amp;\\mbox{ si } x &lt; 0\\\\ x &amp;\\mbox{ si } 0 \\leq x \\leq 1\\\\ 1 &amp;\\mbox{ si } x &gt; 1 \\end{array}\\right. .\\] Caso 1: \\(P[X \\leq x]\\). Esto es por definición la función acumulativa de distribución: \\[P[X \\leq x] = F(x)\\] La probabilidad de obtener un valor menor que 0,2 en la distribución uniforme del ejemplo es \\[P[X \\leq 0,2] = F(0,2) = 0,2\\] Ahora bien, si tenemos la función de masa, pero no la de distribución, lo podemos calcular integrando: \\[F(x) = P[X \\leq x] = \\int_{-\\infty}^{x}f(t)dt\\] En nuestro ejemplo: \\[P[X \\leq 2] = \\int_{0}^{0,2}1\\,dt = \\left. t \\right|_{0}^{0,2} = 0,2 - 0 = 0,2\\] Vemos que en el caso continuo sí que es muy interesante usar la función acumulativa de distribución: nos ahorramos integrar (esta era fácil, pero las hay muy complicadas). Caso 2: \\(P[X &gt; x]\\). Aplicamos la probabilidad del caso contrario: \\[P[X &gt; x] = 1 - P[X \\leq x] = 1 - F(x).\\] En nuestro ejemplo, la probabilidad de que valga más de 0,6 es \\[P[X &gt; 0,6] = 1 - P[X \\leq 0,6] = 1 - 0,6 = 0,4.\\] Y si sólo tenemos la función de densidad, otra vez toca integrar: \\[P[X &gt; x] = \\int_{x}^{\\infty}f(t)dt\\] En nuestro ejemplo \\[P[X &gt; 0,6] = \\int_{0,6}^{1} 1\\,dt = \\left. t \\right|_{0,6}^{1} = 1 - 0,6 = 0,4\\] Caso general: \\(P[x_{1} &lt; X \\leq x_{2}]\\). Podría sumar y restar integrales, de manera similar a como hicimos en el caso discreto, pero voy a usar otro argumento (que también se puede usar en el caso discreto). En vez de restar las integrales sumamos y restamos la probabilidad de \\(P[X \\leq x_{1}]\\): \\[P[x_{1} &lt; X \\leq x_{2}] = P[X \\leq x_{1}] + P[x_{1} &lt; X \\leq x_{2}] - P[X \\leq x_{1}].\\] Ahora bien, \\(P[X \\leq x_{1}]\\) y \\(P[x_{1} &lt; X \\leq x_{2}]\\) son probabilidades incompatibles, por lo tanto \\[P[X \\leq x_{1}] + P[x_{1} &lt; X \\leq x_{2}] = P[X \\leq x_{1} \\mbox{ o } x_{1} &lt; X \\leq x_{2}].\\] Pero \\(P[X \\leq x_{1} \\mbox{ o } x_{1} &lt; X \\leq x_{2}] = P[X \\leq x_{2}]\\). Y nos queda \\[P[x_{1} &lt; X \\leq x_{2}] = P[X \\leq x_{2}] - P[X \\leq x_{1}] = F(x_{2}) - F(x_{1}).\\] En nuestro ejemplo, la probabilidad de que la variable tenga un valor entre 0,15 y 0,72 es \\[P[0,15 &lt; X \\leq 0,72] = F(0,72) - F(0,15) = 0,72 - 0,15 = 0,57.\\] Si no tenemos la función acumulativa de distribución, toca integrar: \\[P[x_{1} &lt; X \\leq x_{2}] = \\int_{x_{1}}^{x_{2}} f(x)\\, dx.\\] Lo dejo como ejercicio para el caso de nuestro ejemplo. Vuelvo a recordar que en el caso continuo no hay diferencia entre menor o igual y menor estricto (o mayor o igual y mayor estricto), por lo que \\[P[x_{1} \\leq X &lt; x_{2}] = F(x_{2}) - F(x_{1}) = \\int_{x_{1}}^{x_{2}} f(x)\\, dx.\\] 8.2.2 Calculando con R R trae muchas distribuciones incorporadas: la normal, la binomial, la de Poisson, la uniforme, etc. Para cada una de estas distribuciones trae 4 funciones de las que en este momento nos interesan 2: la de densidad o masa, y la acumulativa de distribución. La nomenclatura es la siguiente: se antepone una “d” al nombre de la distribución para tener la función de densidad o masa, y una “p” para obtener la acumulativa de distribución. Así, para la distribución normal (que recordemos es continua) la función de densidad sería dnorm() y la de distribución pnorm(). Para la distribución de Poisson, que es discreta, dpois() sería la de masa y ppois() la de distribución. Así, si tenemos una distribución normal, continua, de media 0 y desviación estandar 1 (los valores que R usa por defecto), para calcular la probabilidad \\(P[-1 &lt; X &lt; 0,5]\\) escribimos &gt; pnorm(0.5) - pnorm(-1) [1] 0.5328072 Es decir que la probabilidad de que una variable aleatoria en una distribución normal de media 0 y desviación estandar 1 tome un valor entre \\(-1\\) y \\(0.5\\) es \\(0.533\\). R no integra, por lo que no tenemos otra forma de calcular la probabilidad. Si tenemos una distribución discreta, como la de Poisson, sí que podemos calcular la probabilidad tanto con la función de masa como con la de distribución. No vamos a entrar en detalles aquí con las características de la distribución de Poisson. En este momento hemos de decir que es discreta y que depende de un parámetro llamado \\(\\lambda\\) y al que le vamos a dar el valor de 2. Para calcular que una variable aleatoria que sigue una distribución de Poisson con parámetro \\(\\lambda = 2\\) valga 1 debemos usar la función de masa dpois(): &gt; dpois(1,2) [1] 0.2706706 Luego la probabilidad \\(P[X = 2] = 0.27\\). Si queremos calcular la probabilidad \\(P[1 &lt; X \\leq 6]\\) lo podemos hacer tanto con la de masa como con la acumulativa de distribución: &gt; ppois(6,2)-ppois(1,2) [1] 0.5894603 &gt; dpois(2,2) + dpois(3,2) + dpois(4,2) + dpois(5,2) + dpois(6,2) [1] 0.5894603 En ambos casos da lo mismo (como toca): la probabilidad es de 0,59. 8.2.3 Resumen Una variable aleatoria es una variable de la que desconocemos el valor que va a tomar. Eso sí, cada posible valor lo tomará con una determinada probabilidad. A esta se le llama la distribución de la variable aleatoria. Tenemos dos funciones para describir la distribución: la de masa o densidad y la acumulativa de distribución. La función de masa sólo se usa en variables discretas y es simplemente la probabilidad de que la variable tome el valor \\(k\\): \\(f(k) = P[X = k]\\). En el caso continuo usamos la función de densidad que nos da la densidad de probabilidad: cuanto mayor es el valor de esta función en un punto \\(x\\), más probable es que la variable tome valores alrededor de \\(x\\). Eso sí, la probabilidad de que la variable tome exactamente el valor \\(x\\) es 0. Tanto en el caso discreto como el continuo la función acumulativa de distribución en el punto \\(x\\) se define como la probabilidad acumulada hasta ese punto: \\(F(x) = P[X \\leq x]\\). Podemos usar estas funciones para calcular probabilidades. En el caso discreto, la expresión general es \\[P[k_{1} &lt; X \\leq k_{2}] = F(k_{2}) - F(k_{1}) = f(k_{1}+1) + f(k_{1} + 2) + \\cdots + f(k_{2}).\\] y en el continuo \\[P[x_{1} \\leq X &lt; x_{2}] = F(x_{2}) - F(x_{1}) = \\int_{x_{1}}^{x_{2}} f(x)\\, dx.\\] R trae incorporadas las funciones de masa o densidad y distribución de muchas distribuciones. "],
["esperanzas-y-desviaciones-típicas-de-variables-aleatorias.html", "Capítulo 9 Esperanzas y desviaciones típicas de variables aleatorias 9.1 Desviaciones típicas 9.2 Operaciones con variables aleatorias 9.3 Resumen", " Capítulo 9 Esperanzas y desviaciones típicas de variables aleatorias Cuando cogemos una muestra de una población podemos calcular la media y la desviación típica de la muestra. Esto nos da un idea de su valor central y de la dispersión. Esta es una información que también nos interesa de una distribución. En este documento vamos a ver cómo se calcula la “media” (más conocida como esperanza) y la desviación típica de una distribución, tanto si es discreta como si es continua. Tiramos un dado 6 veces y nos sale 3, 6, 3, 4, 5 y 2. La media de esta muestra es 3,83. Como vimos en el documento de estadística descriptiva de datos numéricos, el valor de la media me da una medida de cuál es el “centro” de los datos, el valor alrededor del cuál se mueven. Esto es un concepto que también me interesa para una distribución. ¿Cuál es el valor “central” de una distribución? Una distribución es un “ideal” de una muestra. Si tuviéramos una muestra “perfecta” tendríamos cada valor en proporción exacta a su probabilidad de salir. Esto en el caso de los dados sería tirar los dados 6 veces y obtener un 1, un 2, un 3, un 4, un 5 y un 6; o tirar los dados 12 veces y obtener dos 1, dos 2, etc. La media de esta “muestra perfecta” es la esperanza o valor esperado de la distribución, o estrictamente hablando, la esperanza de una variable aleatoria distribuida uniformemente con valores de 1 a 6. Realmente es un nombre desafortunado: el valor esperado de tirar un dado es 3,5, que es un valor imposible. Pero bueno, aceptaremos el nombre. Esta idea intuitiva nos da un método para calcular la esperanza: diseñamos una “muestra perfecta” y calculamos su media. Esto tiene dos problemas: es engorroso diseñar esta muestra perfecta, y es imposible si la variable aleatoria puede tomar infinitos valores. Por lo tanto usamos otro método. Antes de tirar el dado tenemos una probabilidad de 1/6 de sacar un 1, una probabilidad de 1/6 de sacar un 2, …, una probabilidad de 1/6 de sacar un 6. La esperanza es la media ponderada de los valores que pueden salir, siendo las probabilidades los pesos con el que multiplicar los valores. Sea \\(D\\) la variable aleatoria de tirar un dado. Su esperanza \\(E[D]\\) es \\[E[D] = \\frac{1}{6}\\, 1 + \\frac{1}{6}\\, 2 + \\frac{1}{6}\\, 3 + \\frac{1}{6}\\, 4 + \\frac{1}{6}\\, 5 + \\frac{1}{6}\\, 6 = \\frac{1 + 2 + 3 +4+5+6}{6} = 3,5\\] Queda claro que en este caso esto corresponde a la media de nuestra “muestra perfecta”. No es difícil ver que esto es así siempre. Y este método me sirve incluso si la variable puede tomar infinitos valores. Recordemos el ejemplo de tirar una moneda hasta que nos saliera una cruz. Llamemos \\(C\\) a la variable aleatoria que es el número de caras que salen hasta que salga la primera cruz. Recordamos que la probabilidad de que \\(C\\) valga \\(k\\) (es decir su función de masa) era \\(f(k) = 1/2^{k+1}\\). Entonces la esperanza es \\[E[C] = 0\\,\\frac{1}{2} + 1\\,\\frac{1}{4} + 2\\,\\frac{1}{8} +\\cdots = \\sum_{k = 0}^{\\infty} k\\,\\frac{1}{2^{k+1}}\\] Por suerte esta serie infinita se sabe sumar. Su valor es \\[E[C] = \\frac{1 - \\frac{1}{2}}{\\frac{1}{2}} = 1.\\] Es decir que si nos ponemos a lanzar moneda hasta sacar una cruz podemos “esperar” ver sólo una cara antes de que llegue la cruz. O lo que es lo mismo, podemos esperar lanzar la moneda 2 veces. Naturalmente, la mitad de las veces nos pararemos a la primera tirada, y hay una probabilidad (infinitesimal) de sacar miles de caras antes de ver la primera cruz. Pero “de media” sacaremos sólo una cara. Podemos generalizar este resultado para calcular la esperanza a partir de la función de masa. Sea una variable discreta \\(X\\) que tiene una función de masa \\(f(k)\\). Vamos a suponer que \\(k\\) varía de 0 a \\(\\infty\\). La esperanza de la variable aleatoria es \\[E[X] = \\sum_{k = 0}^{\\infty} k\\, f(k).\\] En el caso de que la variable aleatoria sea continua, entonces el sumatorio se convierte en una integral: \\[E[X] = \\int_{-\\infty}^{\\infty} x\\, f(x)\\, dx.\\] Veamos una consecuencia, que es importante, de este resultado. Si sacamos una muestra de una distribución cada valor \\(k\\) aparecerá con probabilidad \\(f(k)\\). Si la muestra es grande, se parecerá a la “muestra perfecta” y la media de esa muestra se acercará a la esperanza de la distribución. En estadística esto generalmente se usa al revés: tenemos una distribución de la cuál no sabemos la esperanza, pero si obtenemos una muestra suficientemente grande, la media de la muestra nos dará una buena estima de la esperanza de la distribución. 9.1 Desviaciones típicas De la misma manera que partimos de la idea de media de una muestra y la extendemos a esperanza de una variable aleatoria que sigue una determinada distribución, podemos partir de desviación típica de una muestra y extenderla a la desviación típica de una distribución. Ya en su momento no mostramos la fórmula para el cálculo de la desviación típica de una muestra y tampoco lo vamos a hacer aquí. Si tenemos una variable aleatoria que sigue una distribución discreta y finita, la idea de la “muestra perfecta” nos sigue sirviendo: la desviación de la variable es la de esta muestra. Si es discreta infinita o es continua, hay que aplicar las fórmulas correspondientes, que se pueden encontrar en cualquier libro o página web de estadistica. Otra vez, al igual que en el caso de la esperanza, en estadística se suele usar la desviación típica de una muestra como estimador de la desviación típica de la distribución de donde hemos sacado la muestra. 9.2 Operaciones con variables aleatorias El término «esperanza» y la notación \\(E[X]\\) pertenece al campo de la probabilidad. En estadística se tiene la tendencia a ser más concreto. En vez de pensar en una variable aleatoria en abstracto y su esperanza, se piensa en una población de interés y en su media. Por eso aunque cuando se tratan aspectos teóricos se habla de «esperanza» y se usa el \\(E[X]\\), cuando nos metemos en la práctica se habla de «media poblacional» y se escribe como \\(\\mu\\) (pronunciado «mu»). En estadística las letras griegas son parámetros de la población, mientras que las letras latinas se refieren a las muestras. En el caso de la desviación típica, la desviacion típica poblacional se simboliza con la letra griega sigma: \\(\\sigma\\). Veamos el resultado de la esperanza, o media poblacional, y de la desviación típica, que tenemos si operamos variables aleatorias. Lo primero que hay que tener muy claro es que sumar variables aleatorias no es lo mismo que sumar variables algebraicas. Por ejemplo, todos sabemos que en álgebra \\(x + x= 2x\\). Esto no pasa con variables aleatorias. Supongamos dos juegos distintos. Uno es lanzar un dado dos veces. El otro es lanzar un dado y multiplicar lo que salga por 2. Llamemos \\(D\\) a la variable aleatoria de lanzar un dado. En el primer caso tenemos la variable aleatoria \\(S = D + D\\). En el segundo tenemos la variable aleatoria \\(M = 2D\\). Las variables (y los juegos) no son iguales. Es cierto que \\(S\\) y \\(M\\) van entre 2 y 12, pero por ejemplo la probabilidad de que \\(S\\) valga 3 es \\(P[S = 3] = 2/36\\) mientras que la probabilidad de que \\(M\\) valga 3 es \\(P[M = 3] = 0.\\) Son distribuciones diferentes y por lo tanto son variables aleatorias diferentes. Como vemos en este ejemplo de los dados, es bastante habitual operar con variables aleatorias. Veamos cómo varían las medias poblacionales y las desviaciones típicas ante la suma de variables aleatorias entre sí y con constantes y la multiplicación de variables por constantes. No veremos el caso de multiplicación de variables aleatorias: es mucho más complejo y, por suerte, menos interesante. Empecemos con un ejemplo. La longitud (en minutos) de las llamadas hechas en mi teléfono es una variable aleatoria \\(T\\): no sé de antemano cuánto durarán. Mi operadora me dice que el coste de la llamada es 0,10€ por establecimiento de llamada más 0,03€ por minuto. El coste \\(C\\) de la llamada es otra variable aleatoria (tampoco la conozco de antemano) que es \\(C = 0.03 T + 0,10\\). Yo sé que mis llamadas siguen una cierta distribución (no importa cuál) y tiene una media poblacional (o esperanza) \\(\\mu_{T}\\). Es fácil darse cuenta que la media poblacional del coste de las llamadas es \\(\\mu_{C} = 0.03 \\mu_{T} + 0,10.\\) Esto se puede generalizar —y demostrar rigurosamente— como la primera propiedad de las esperanzas (o medias poblacionales): \\[\\mu_{aX + b} = a \\mu_{X} + b.\\] Es decir que si sumamos una cantidad fija a una variable también hay que sumarla a la media poblacional. Y si multiplicamos una variable por una cantidad fija, también hay que multiplicar la media poblacional por esa cantidad. Consideremos ahora un servidor web. Cuando le llega una petición para ver una página tarda un tiempo \\(P\\) en procesar la petición y un tiempo \\(T\\) en transmitir la página solicitada. Ambos tiempos son desconocidos a priori (es decir aleatorios). Siguen una cierta distribución y tienen unas medias poblacionales \\(\\mu_{P}\\) y \\(\\mu_{T}\\). El tiempo \\(R\\) necesario para responder a la petición es \\(R = P + T\\). Es fácil darse cuenta que la media poblacional de \\(R\\) es \\(\\mu_{R} = \\mu_{P} + \\mu_{T}\\). Esto se puede generalizar —y demostrar rigurosamente— a la segunda propiedad de las esperanzas (o medias poblacionales): \\[\\mu_{aX \\pm bY} = a\\mu_{X} \\pm b \\mu_{Y}.\\] En palabras: la media de una suma (o resta) es la suma (o resta) de las medias. Veamos ahora las propiedades de la distribución típica. Lo haremos gráficamente. En la figura siguiente tenemos dos variables aleatorias. Una es \\(X\\), cuya función de densidad se ha pintado en negro. Otra es \\(Y = X + 5\\), cuya función de densidad se ha pintado en azul. Recordemos que la desviación típica es una medida de cuánto se desvían los valores respecto a la media del conjunto. En el caso de \\(Y\\) todos los valores están desplazados 5 unidades. Y la media también. Por lo tanto el desvío respecto a la media de \\(Y\\) es el mismo que el desvío respecto a la media de \\(X\\). De aquí la primera propiedad de las desviaciones típicas: \\[\\sigma_{X\\pm a} = \\sigma_{X}.\\] En la figura siguiente tenemos las densidades de dos variables, \\(X\\) e \\(Y = -X\\). Una función es la imagen especular de la otra. Están giradas, pero son la misma forma. Por lo tanto las desviaciones respecto a las medias son las mismas, por lo tanto la desviación típica debe ser la misma. Es decir, \\[\\sigma_{-X} = \\sigma_{X}.\\] Consideremos ahora dos variables aleatorias: Una es \\(X\\) y la otra es \\(Y = 2X\\). La probabilidad que \\(X\\) esté entre, digamos \\(-1\\) y \\(-1,1\\) ha de ser igual a la probabilidad que \\(Y\\) esté entre \\(-2\\) y \\(-2,2\\). Esto obliga a la figura a extenderse y achatarse. Mostramos esto en la figura siguiente. Todo está más alejado de la media y por lo tanto la desviación típica ha de crecer. Se puede demostrar que si doblamos el valor de la variable aleatoria, la desviación típica también se dobla. Unimos esto al resultado anterior, que multiplicar por \\(-1\\) no cambia la desviación típica, y tenemos que \\[\\sigma_{aX} = |a| \\sigma_{X}\\] Acabemos con el último resultado que nos interesa: el caso de la suma de dos variables aleatorias independientes, \\(X +Y\\). Si las variables no fuesen independientes, todo lo que sigue no se puede aplicar. En este caso gráficamente no se ve mucho y no mostramos ninguna figura. Queda claro que tenemos dos fuentes de variabilidad y es lógico pensar que la desviación típica será mayor que la de cualquiera de las dos variables. También es fácil darse cuenta que como \\(X - Y = X + (-Y)\\), y \\(\\sigma_{-Y} = \\sigma_{Y}\\), entonces \\(\\sigma_{X-Y} = \\sigma_{X+Y}\\). Se puede demostrar que \\[\\sigma_{X\\pm Y} = \\sqrt{\\sigma_{X}^{2} + \\sigma_{Y}^{2}}.\\] Vuelvo a llamar la atención al hecho de que aunque las variables se resten, las desviaciones típicas se suman. 9.2.1 Un ejemplo Tenemos un bazar de equipos electrónicos. Somos dos socios y lo tenemos montado de esta manera: Alberto compra los equipos y me los vende a un precio un 15% superior. Después yo los vendo a clientes y me quedo con el beneficio. El precio de compra es una variable aleatoria y el de venta también y son independientes porque ambos regateamos fuertemente con los clientes. Entre nosostros no regateamos. El precio de compra medio es de 89,73€ con una desviación típica de 7,35€ y el precio de venta medio es de 114,28€, con una desviación típica de 6,35€. ¿Cuál es mi beneficio medio?¿Qué desviación típica tiene? Llamemos \\(C\\) al precio por el que Alberto compra los equipos, \\(V\\) al precio por el que yo los vendo y \\(B\\) a mi beneficio. Entonces \\[B = V - 1,15 C.\\] El valor esperado del beneficio es \\[\\mu_{B} = \\mu_{V - 1,15 C} = \\mu_{V} - 1,15 \\mu_{C} = 114,28 - 1,15 \\cdot 89,73 = 11,09\\mbox{ \\euro}\\] La desviación típica sería \\[\\sigma_{B} = \\sigma_{V - 1,15 C} = \\sqrt{\\sigma_{V}^{2} + \\sigma_{1,15C}^{2}} = \\sqrt{\\sigma_{V}^{2} + (1,15\\,\\sigma_{C})^{2}} = \\sqrt{7,35^{2} + (1,15 \\cdot 6,35)^{2}} = 10,36\\mbox{ \\euro}\\] La desviación típica es casi tan grande como la media. Esto quiere decir que aunque de media gane, en muchas ventas tendré pérdidas. En vista de esto le propongo a Alberto un cambio en nuestra forma de hacer negocios: Yo le daré 13,50€ por compra, independientemente de cuánto cueste. Esto es un poquito más de lo que él recibe de media, por lo tanto sale ganando. Lo acepta. Con este nuevo arreglo, mi beneficio es: \\[B = V - C - 13,50.\\] y el valor esperado queda: \\[\\mu_{B} = \\mu_{V - C - 13,50} = \\mu_{V} - \\mu_{C} - 13,50 = 114,28 - 89,73 - 13,50 = 11,05\\mbox{ \\euro}.\\] Un poquito menos. Pero la desviacion típica es: \\[\\sigma_{B} = \\sigma_{V - C - 13,50} = \\sqrt{\\sigma_{V}^{2} + \\sigma_{C}^{2}} = \\sqrt{7,35^{2} + 6,35^{2}} = 9,71\\mbox{ \\euro}\\] De media no gano tanto pero la variabilidad ha bajado. Menos sobresaltos al final del día. 9.3 Resumen De la misma manera que una muestra tiene una media y una desviación típica, una distribución también la tiene (o para ser preciso, una variable aleatoria que sigue una distribución). A la “media” de la distribución se le llama _esperanza} (en probabilidad) o _media poblacional} (en estadística). Si la distribución es discreta y finita, la esperanza y la desviacion típica serían aquellas que corresponden a una muestra “perfecta” aquella en la que cada valor de la muestra sale en una proporción que corresponde exactamente a su probabilidad. Si la distribución es discreta infinita o continua, hay fórmulas que permiten calcular estos valores. En particular para la esperanza tenemos: \\[E[X] = \\sum_{k = 0}^{\\infty} k\\, f(k).\\] en el caso discreto y \\[E[X] = \\int_{-\\infty}^{\\infty} x\\, f(x)\\, dx.\\] para el continuo. A menudo tenemos que multiplicar una variable aleatoria por un factor o sumar variables aleatorias. En el caso de sumar o multiplicar constantes por una variables tenemos: \\[\\mu_{aX + b} = a \\mu_{X} + b.\\] Y la suma de variables es: \\[\\mu_{aX \\pm bY} = a\\mu_{X} \\pm b \\mu_{Y}.\\] Para el cálculo de la desviación típica, la suma de una constante a una variable no cambia la desviación típica: \\[\\sigma_{X\\pm a} = \\sigma_{X}.\\] Pero si la multiplicamos, sí: \\[\\sigma_{aX} = |a| \\sigma_{X}\\] Tanto si sumamos como si restamos variables aleatorias, la desviación aumenta: \\[\\sigma_{X\\pm Y} = \\sqrt{\\sigma_{X}^{2} + \\sigma_{Y}^{2}}.\\] "],
["intervalos-de-confianza-una-medida-de-la-incertidumbre.html", "Capítulo 10 Intervalos de confianza: una medida de la incertidumbre 10.1 Incertidumbre en muestras de proporciones 10.2 Incertidumbre en muestras de medias 10.3 Comparación de intervalos de confianza", " Capítulo 10 Intervalos de confianza: una medida de la incertidumbre 10.1 Incertidumbre en muestras de proporciones El muestreo consiste en escoger los datos de algunos individuos de una población, llamada una muestra, para obtener información de toda la población a partir de ella. No es difícil darse cuenta que si tomo dos muestras de la misma población es muy poco probable obtener exactamente los mismos resultados. Incluso si los datos son poco problemáticos, lo hago perfectamente bien y no cometo ningún error, cada vez que tome una muestra obtendré resultados algo diferentes (cuánto más problemáticos sean los datos, más diferentes tenderán a ser). La estadística nos permite cuantificar la incertidumbre asociada a un muestreo bien hecho. Esto se hace a través de los llamados intervalos de confianza. Veamos cómo se calcula el intervalo de confianza de la proporción de individuos con alguna característica. 10.1.1 Una simulación Empecemos por una simulación. Tenemos una población muy numerosa, potencialmente infinita, de la cual hay individuos con una cierta característica. Quizá la población es de caramelos y la característica es tener sabor de fresa; o la población es de personas y la característica es ser hinchas de la UD Porreres; o son tiros libres en baloncesto y la característica es entrar en la canasta. Tomar un individuo de la población y mirar si tiene o no la característica es llamado una prueba de Bernoulli. Si tiene la característica se dice que es un éxito y el no tenerla es un fracaso. Un muestreo de proporciones es una serie de pruebas de Bernoulli y nos interesa obtener la proporción de éxitos. Vamos a hacer una simulación con R. Supongamos que tenemos una población muy grande de la que sabemos, porque así lo programamos, la proporción de individuos que tienen la característica. Representamos esta proporción de la población, deconocida, por la letra griega \\(\\theta\\). Sea \\(\\theta = 0,38\\) esta proporción: exactamente el 38% de nuestra población es hincha de la UD Porreres. Creamos 1000 muestras de 200 pruebas de Bernoulli cada una. Un «0» representa un fracaso y un «1» representa un éxito. Lo metemos en una matriz de 200 filas y 1000 columnas. Cada columna es una muestra. El código de R para hacer esto es el siguiente: # La proporción pr = 0.38 # 1000 muestras de 200 individuos dt = sample(0:1, 200000, replace = T, prob = c(1-pr,pr)) muestreo = matrix(dt, nrow = 200, ncol = 1000) Calculamos la proporción de éxitos de cada prueba. Como astutamente los éxitos son «1» y los fracasos son «0», nos basta sumar las columnas y dividir por el tamaño de la muestra: zetatecho = colSums(muestreo)/200 En estadística se pone un circunflejo (\\(\\hat{}\\)) encima de una variable para indicar que es el valor medido en un muestreo de esa variable. Así, \\(\\theta\\) es la proporción en una población, mientras que \\(\\hat{\\theta}\\), pronunciado zeta-gorro o zeta-techo, es la proporción que hemos medido en una muestra de la población. En nuestra simulación, el resultado del primer muestreo nos ha dado \\(\\hat{\\theta} = 0.355\\), el segundo \\(\\hat{\\theta} = 0.350\\), el tercero \\(\\hat{\\theta} = 0.405\\), etc. (recordemos que esta es una simulación con muestras aleatorias. Si ejecuta el mismo código obtendrá valores diferentes cada vez). Algunas veces obtenemos valores por debajo de \\(\\theta\\), la proporción de toda la población, y otras veces están por encima. Esto lo vemos claramente en el histograma de los 1000 valores de \\(\\hat{\\theta}\\) de las 1000 muestras obtenidas que se muestra a continuación: Estamos interesados en el rango del 90% central de los datos. Es decir eliminamos el 5% más bajo y el 5% más alto y miramos el rango de lo que nos queda. Para ello ordenamos los \\(\\hat{\\theta}\\) y miramos el que está en la posición 50 y 950. Para poder reutilizar el código, usamos unas variables que calculan las posiciones que tenemos que mirar para obtener este rango: # Las ordenamos zetatecho = sort(zetatecho) # El 90% central prob1 = 0.90 zetatecho[((1-prob1)/2)*1000] ## [1] 0.325 zetatecho[((1+prob1)/2)*1000] ## [1] 0.435 En esta simulación en concreto obtenemos que el rango está entre 0,325 y 0,435. Es decir que si escogemos una muestra de las 1000 al azar, tenemos una probabilidad del 90% de que esté entre estos dos valores. Podemos escribirlo como \\[P[0,325 \\leq \\hat{\\theta} \\leq 0,435] = 0.9\\] Como hemos creado este mundo, conocemos \\(\\theta\\). Esto nos permite reescribir la expresión como \\[P[0,325 - 0,38 = 0,055 \\leq \\hat{\\theta} - \\theta \\leq 0,435 - 0,38 = 0,055] = 0.9\\] Y esto nos permite escribir \\[P[ \\hat{\\theta} - 0,055 \\leq \\theta \\leq \\hat{\\theta} + 0,055] = 0.9\\] Es decir, que si cogemos una muestra al azar y medimos la proporción de esta muestra, \\(\\hat{\\theta}\\), tenemos una probabilidad de \\(0.9\\) de que el valor de la población total esté \\(0.055\\) por encima o por debajo de este valor. Podemos repetir esto con cualquier probabilidad que queramos. Por ejemplo 0.8 o 0.95: # El 80% central prob2 = 0.80 zetatecho[((1-prob2)/2)*1000] ## [1] 0.335 zetatecho[((1+prob2)/2)*1000] ## [1] 0.425 # El 95% central prob3 = 0.95 zetatecho[((1-prob3)/2)*1000] ## [1] 0.315 zetatecho[((1+prob3)/2)*1000] ## [1] 0.45 En estos casos obtenemos que hay una probabilidad de 0.8 de que la proporción de la población total \\(\\theta\\) esté en \\([0.335, 0.425]\\) o, lo que es lo mismo, en \\(\\hat{\\theta}\\pm 0,045\\) (en esta simulación concreta. En otras variará un poco). Y una probabilidad de \\(0.95\\) de que esté en \\([0.315, 0.445]\\) o, lo que es lo mismo, en \\(\\hat{\\theta}\\pm 0,065\\). Es importantísimo no olvidar que esto son probabilidades. Hay un buen número de muestras, perfectamente hechas y perfectamente válidas, que están fuera de nuestra horquilla. Además, en nuevas simulaciones obtendríamos valores diferentes. Estamos cuantificando la incertidumbre. Esa es la palabra clave: incertidumbre. Y la cuantificamos, no la eliminamos. 10.1.2 Intervalos de confianza En nuestra simulación, nuestra creación, conocíamos \\(\\theta\\) y esto nos permitía calcular la horquilla. Pero el caso real es que no conocemos \\(\\theta\\). Precisamente tomamos la muestra para saber algo de \\(\\theta\\). Para poder rigurosamente saber algo de \\(\\theta\\) a partir de \\(\\hat{\\theta}\\) necesitamos el razonamiento matemático que vamos a detallar. Sea \\(Y\\) una variable aleatoria que es el resultado de una prueba de Bernoulli. \\(Y = 1\\) si la prueba es un éxito. Esto pasa con probabilidad \\(\\theta\\). Si es un fracaso, \\(Y = 0\\), y esto pasa con probabilidad \\(1 - \\theta\\). El valor esperado de \\(Y\\) es \\(E[Y] = 1\\cdot \\theta + 0\\cdot (1-\\theta) = \\theta\\). Tomamos una muestra de \\(n\\) elementos independientes: si un individuo posee o no la característica es independiente de todos los demás. La proporción de la muestra, \\(\\hat{\\theta}\\), es otra variable aleatoria: \\[\\hat{\\theta} = \\frac{Y + Y + \\cdots + Y}{n}.\\] El valor esperado de \\(\\hat{\\theta}\\) es: \\[E[\\hat{\\theta}] = E\\left[\\frac{Y + Y + \\cdots + Y}{n}\\right] = \\frac{E[Y + Y + \\cdots + Y]}{n} = \\frac{n \\, E[Y]}{n} = \\frac{n\\theta}{n} = \\theta\\] Esto quiere decir que el valor medido, y conocido, \\(\\hat{\\theta}\\) va a estar alrededor de donde está nuestro desconocido \\(\\theta\\). Es una buena noticia. Calculemos ahora la desviación típica de \\(\\hat{\\theta}\\). La desviación típica de \\(Y\\), \\(\\mathrm{sd}(Y)\\), la podemos calcular considerando que una prueba de Bernoulli sigue una distribución binomial con tamaño 1 y probabilidad \\(\\theta\\). Por lo tanto \\(\\mathrm{sd}(Y) = \\sqrt{\\theta (1-\\theta)}.\\) Luego \\[\\begin{eqnarray*} \\mathrm{sd}(\\hat{\\theta}) &amp; = &amp; \\mathrm{sd}\\left(\\frac{Y + Y + \\cdots + Y}{n}\\right)\\\\ &amp; = &amp; \\frac{\\mathrm{sd}(Y + Y +\\cdots +Y)}{n}\\\\ &amp; = &amp; \\frac{\\sqrt{\\mathrm{sd}(Y)^{2} + \\cdots + \\mathrm{sd}(Y)^{2}}}{n}\\\\ &amp; = &amp; \\frac{\\sqrt{\\theta(1-\\theta) + \\cdots + \\theta(1-\\theta)}}{n}\\\\ &amp; = &amp; \\frac{\\sqrt{n\\theta(1-\\theta)}}{n} \\\\ &amp; = &amp; \\sqrt{\\frac{\\theta (1-\\theta)}{n}} \\end{eqnarray*}\\] Desgraciadamente esto no nos ayuda mucho. Hemos obtenido la desviación típica de \\(\\hat{\\theta}\\) en función del desconocido \\(\\theta\\). Para resolver este problema definimos un concepto importante: error estándar. Definimos el error estándar de \\(\\hat{\\theta}\\), \\(\\mathrm{se}(\\hat{\\theta})\\), como \\[\\mathrm{se}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\theta} (1-\\hat{\\theta})}{n}}\\] Es decir, el error estándar tiene la misma expresión que la desviación típica, pero sustituyendo el desconocido \\(\\theta\\) por el conocido \\(\\hat{\\theta}\\). Para poder ahora saber algo de \\(\\theta\\) a partir de \\(\\hat{\\theta}\\) entra uno de los teoremas más importantes de la estadística, el teorema central del límite. Este teorema nos dice que si tenemos muchas variables aleatorias idénticamente distribuidas, con cualquier distribución, y que son independientes una de otra, entonces la media de estas variables tiende a una distribución normal. A menudo se usa la sigla iid que significa «independientes e idénticamente distribuidas». Este teorema es fundamental para muchos resultados de estadística: para saber la distribución de la media de variables aleatorias, no tenemos que saber nada de la distribución de ellas. Eso sí, siempre y cuando las variables sean iid. Volvamos a nuestro problema original. A partir del teorema central del límite se puede establecer que \\[\\frac{\\hat{\\theta} -\\theta}{\\mathrm{se(}\\hat{\\theta})} \\leadsto \\mathrm{N}(0, 1)\\] («\\(\\leadsto \\mathrm{N}(0,1)\\)» se lee como «tiende a la distribución normal de media 0 y desviación típica 1»). Cuanto mayor es \\(n\\) más cerca está la distribución de \\((\\hat{\\theta} -\\theta)/\\mathrm{se}(\\hat{\\theta})\\) de la normal de media 0 y desviación típica 1. Si lo pensamos un poco, esto lo podemos reescribir como \\[\\hat{\\theta} \\leadsto \\mathrm{N}(\\theta, \\mathrm{se(}\\hat{\\theta})).\\] Sabiendo esto podemos recuperar la estrategia que usamos en la simulación. Suponemos que \\(n\\) es lo suficientemente grande para que podamos usar la normal N(0, 1) sin demasiado error. Como en la simulación, nos interesa el rango del, digamos, 90% central de los datos. “Quitamos” de N(0, 1) el 5% del extremo inferior y el 5% del extremo superior. Esto lo podemos hacer con R con la función qnorm(). La instrucción sería qnorm(0.05, 0, 1) para el inferior y qnorm(0.95, 0, 1) para el superior. Los valores que obtenemos son \\(-1,645\\) y \\(1,645\\). Ahora podemos escribir: \\[P[-1,645 \\leq \\frac{\\hat{\\theta} -\\theta}{\\mathrm{se(}\\hat{\\theta})} \\leq 1,645] = 0.9\\] lo que con un poco de álgebra se convierte en: \\[P[\\hat{\\theta}-1,645\\,\\mathrm{se(}\\hat{\\theta}) \\leq \\theta \\leq \\hat{\\theta} + 1,645\\,\\mathrm{se(}\\hat{\\theta})] = 0.9.\\] Es decir que hay una probabilidad de 0,9 de que el valor de toda la población, esa desconocida \\(\\theta\\), esté a 1,645 veces el error estandar por encima o por debajo del \\(\\hat{\\theta}\\), el valor medido en nuestra muestra. A este intervalo se le llama Intervalo de Confianza. Naturalmente, podemos repetir esto para cualquier valor de probabilidad que nos interese. Lo hemos hecho con 0,9, pero lo podemos hacer con 0,8, 0,95, 0,7732… A esta probabilidad se le llama el nivel de confianza. Un intervalo de confianza de proporciones a un nivel de confianza NC es el intervalo centrado en \\(\\hat{\\theta}\\) en el que se estima que estará la proporción de la población \\(\\theta\\) con una probabilidad NC. Algunas cuestiones a tener en cuenta: Nadie asegura que \\(\\theta\\) esté en el intervalo de confianza. Siempre hay una probabilidad de que esté fuera. A la hora de calcular el intervalo estamos suponiendo que hemos tomado la muestra con todo rigor: de forma aleatoria, sin sesgos, etc. Si no es así, si la muestra está mal tomada, no significa que el intervalo es mayor, significa que no sabemos nada: puede ser mayor, puede ser menor, puede estar en otro lado. Lo que hemos hecho en el fondo es una aproximación que es tanto mejor cuánto mayor es \\(n\\). Para valores de \\(n\\) pequeños la incertidumbre es mayor que lo que sale de este procedimiento. Aunque no lo hemos mostrado, la incertidumbre también depende del valor de \\(\\hat{\\theta}\\). Si es muy cercano a 0 o a 1, tenemos un caso problemático, y necesitamos un valor muy muy grande de \\(n\\) para tener una aproximación aceptable. Estamos suponiendo independencia: el que una prueba de Bernoulli dé un determinado valor (éxito o fracaso) no influye en los demás. Por eso en una encuesta no preguntamos a una pandilla de amigos. Hay muchos casos en el que no hay independencia. Por ejemplo, si llueve o no mañana no es independiente de si llueve o no hoy: es más probable que llueva mañana si llueve hoy que si hace sol. A veces no está nada claro: ¿depende el encestar un tiro libre de si se ha encestado o fallado el anterior? Cuánto mayor es el nivel de confianza, mayor será el intervalo: si queremos estar más seguros que el valor de la población está en el intervalo, debemos hacerlo mayor. 10.1.3 Fuga de probabilidad En algunos casos nos puede surgir un problema. Supongamos que preguntamos en Palma a una muestra bien escogida de 100 personas si son hinchas de la UD Porreres. Obtenemos 2 éxitos (son hinchas) y 98 fracasos (ellos se lo pierden). El valor de \\(\\hat{\\theta}\\) es 0.02. Hacemos los cálculos para un nivel de confianza de 0.95. El error estándar es \\[\\mathrm{se} = \\sqrt{\\frac{0.02\\cdot 0.98}{100}} = 0.014\\] Para un nivel de confianza de 0.95 hemos de multiplicar el error estándar por un factor (obtenido con qnorm(0.975, 0, 1) de 1.96. El intervalo de confianza queda: \\[ [0.02 - 0.014\\cdot 1.96, 0.02 + 0.014\\cdot 1.96] = [-0.007, 0.047] \\] Nos ha dado una proporción negativa, lo que es imposible. No basta con cambiar el \\(-0.007\\) por un \\(0\\), el problema es más grave: estamos dando probabilidad a sucesos imposibles. Tenemos lo que se llama una fuga de probabilidad. Esto significa que el cálculo es incorrecto y, por lo tanto, el extremo superior de nuestro intervalo no es \\(0.047\\). Si nos encontramos ante esta situación podemos: Indicar que no se puede calcular con precisión este intervalo de confianza (y tirar nuestros cálculos). Sólo podemos decir que la proporcion es pequeña. O grande, pues tenemos el mismo problema si es cercana a 1. Si la fuga es pequeña, cambiar el extremo inferior por 0 (o el superior por 1 si estamos al otro extremo) e indicar que el intervalo de confianza es aproximado. Repetir el experimento pero con un \\(n\\) mayor. Cuanto mayor es \\(n\\) más estrecho es el intervalo y menos fuga hay. Es por eso que si las proporciones están cerca de 0 o de 1 hemos de usar un valor de \\(n\\) más grande de lo que en principio podría parecer. Usar otros métodos para calcular los intervalos de confianza (y cualquier otro cálculo de inferencia). Existen métodos específicos para problemas como este, pero no los explicaremos aquí. 10.1.4 Un ejemplo En nuestro sistema de control de calidad hemos inspeccionado 83 circuitos y 54 se han calificado de «Cumplen especificaciones». ¿Cuál es el intervalo de confianza con un nivel de confianza del 90%?¿Y con un nivel de confianza del 95%? Empecemos por calcular \\(\\hat{\\theta}\\). Han sido 54 éxitos de 83 intentos. Por lo tanto \\[\\hat{\\theta} = 54/83 = 0.6506.\\] Calculemos a continuación el error estándar: \\[\\mathrm{se}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\theta} (1 - \\hat{\\theta})}{n}} = \\sqrt{\\frac{0.6506 (1 - 0.6506)}{83}} = 0.0523.\\] Ahora hemos de calcular el factor por el que hemos de multiplicar el error estándar. Este factor depende del nivel de confianza. Usaremos R. Llamamos nc a la variable con el nivel de confianza, entonces podemos calcular los factores mediante la instrucción qnorm((1+nc)/2). Notemos que los parametros de qnorm() mean y sd tienen como valores por defecto 0 y 1 respectivamente y por eso no es necesario introducirlos y que basta calcular un valor, puesto que debido a la simetría de la distribución normal, el otro valor es el de signo opuesto. Para nc = 0,9 ya lo hemos calculado antes y sabemos que es 1,645. Entonces el intervalo de confianza es \\[ [0.6506 - 1.645\\cdot 0.0523,\\; 0.6506 + 1.645\\cdot 0.0523] = [0.565, \\; 0.737].\\] Para un nivel de confianza del 95% lo único que cambia es el factor. Con la función qnorm() calculamos el nuevo factor y es 1,956. El intervalo de confianza con este nuevo nivel de confianza es \\[ [0.6506 - 1.956\\cdot 0.0523,\\; 0.6506 + 1.956\\cdot 0.0523] = [0.548, \\; 0.753].\\] En resumen, hay una probabiliad de 0,9 que la proporción de la población esté en el intervalo [0.565, 0.737] y una probabilidad de 0.95 de que esté en [0.548, 0.753]. Y una probabilidad menor, pero que no hemos de olvidar, de que esté fuera de estos intervalos. 10.1.5 Resumen de intervalos de confianza de proporciones Sea \\(\\theta\\) la proporción de toda una población con una cierta característica. Tomamos una muestra de tamaño \\(n\\), suficeintemente grande. La muestra ha sido tomada con todo rigor. Llamamos \\(\\hat{\\theta}\\) a la proporción de la muestra con la característica. Un intervalo de confianza de proporciones a un nivel de confianza NC es el intervalo centrado en \\(\\hat{\\theta}\\) en el que se estima que estará la proporción de la población \\(\\theta\\) con una probabilidad NC. Para calcular el intervalo de confianza debemos: Calcular \\(\\hat{\\theta}\\); Calcular el error estándar \\[\\mathrm{se}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\theta} (1-\\hat{\\theta})}{n}};\\] Determinar el nivel de confianza NC que queremos para nuestro intervalo; Calcular el factor \\(\\mathit{fc}\\) para este nivel de confianza. En R podemos usar la función qnorm()}:fc = qnorm((1+nc)/2)}; El intervalo de confianza para este nivel de confianza es \\[ [\\hat{\\theta} - \\mathit{fc}\\cdot \\mathrm{se}(\\hat{\\theta}), \\; \\hat{\\theta} + \\mathit{fc}\\cdot \\mathrm{se}(\\hat{\\theta})].\\] Si hay fuga de probabilidad, decidir qué se hace. 10.2 Incertidumbre en muestras de medias El muestreo consiste en escoger los datos de algunos individuos de una población, llamada una muestra, para obtener información de toda la población a partir de ella. No es difícil darse cuenta que si tomo dos muestras de la misma población es muy poco probable obtener exactamente los mismos resultados. Incluso si lo hago perfectamente bien y no cometo ningún error, cada vez que tome una muestra obtendré resultados algo diferentes. La estadística nos permite cuantificar la incertidumbre asociada a un muestreo bien hecho. Esto se hace a través de los llamados intervalos de confianza. Veamos cómo se calcula el intervalo de confianza de una media de valores. 10.2.1 Una simulación Empecemos por una simulación. Tenemos una población muy numerosa, potencialmente infinita, y medimos una característica numérica de cada uno de los individuos. Quizá la población es de fuentes de alimentación y medimos el voltaje de salida; o la población es de personas y la característica es la altura o el peso; o son años y la característica es la cantidad de lluvia caída en una estación meteorológica determinada. En nuestro caso vamos a recrear los datos tomados por el científico belga Adolphe Quetelet. Quetelet midió el perímetro torácico de 5738 soldados escoceses y encontró que se aproximaba muy bien a una distribución normal de media 101.1 cm y desviación típica 5,2 cm. Hagamos una simulación con R. Empezamos por recrear los datos de Quetelet. La hacemos a partir de rnorm. Usamos la función set.seed() que nos permite establecer la “semilla” del generador de números aleatorios. Así, aunque la secuencia sigue siendo aleatoria, cada vez que ejecute el programa me saldrá la misma secuencia. Esto significa que si ejecutan este script deberían obtener exactamente los mismos resultados que los mostrados aquí. # Recreamos los datos de los 5738 soldados escoceses tomados por Quetelet. # Medida de pecho: 101.1 cm de media y 5.2 cm de desviacion tipica. Usamos # set.seed para poder reproducir valores aleatorios set.seed(2101) chest = rnorm(5738,101.1,5.2) mu = mean(chest) La media de toda la población la representamos con una letra griega, \\(\\mu\\). En este caso, es \\(\\mu =\\) 101.07, ligeramente diferente del 101.1 introducido en rnorm(). Vamos a coger ahora 1000 muestras diferentes, cada una de 15 individuos. Lo vamos a organizar en una matriz donde cada columna es una muestra. No es necesario coger las 1000 muestras una por una: basta coger los 15 000 valores de golpe y organizarlos adecuadamente. # Creamos 1000 muestras de 15 elementos dt = sample(chest, 15000, replace = T) muestras = matrix(dt, nrow = 15, ncol = 1000) Calculamos las medias de cada muestra. Como cada columna es una muestra, hemos de calcular las medias de las columnas. R tiene una función para esto: #Calculamos las medias mu_techo = colMeans(muestras) mu_techo[1:5] ## [1] 98.62854 102.12771 102.01141 102.89417 101.27689 Vemos que los 5 primeros valores son 98.63, 102.13, 102.01, 102.89, 101.28. Llamamos a cada una de las medias de las muestras “mu-techo” o “mu-gorro” y lo vamos a representar por \\(\\hat{\\mu}\\). A menudo se le representa con \\(\\bar{x}\\), con la barra sobre la variable indicando que es una media. Esto es confuso, pues la variable poblacional es \\(\\mu\\) y las de la muestra \\(x\\), y prefiero mantener la notación que las variables poblacionales sean letras griegas y los circunflejos indican que son valores de muestras. El histograma de los \\(\\hat{\\mu}\\) de la simulación es Camo en el caso de las proporciones, estamos interesados en el rango del 90% central de los datos. Hacemos lo mismo que entoneces: eliminamos el 5% más bajo y el 5% más alto y miramos el rango de lo que nos queda. Para ello ordenamos los \\(\\hat{\\mu}\\) y miramos el que está en la posición 50 y 950. Es prácticamente el mismo código que el usado en la sección anterior: # Las ordenamos mu_techo = sort(mu_techo) # El 90% central prob1 = 0.90 mu_techo[((1-prob1)/2)*1000] ## [1] 98.85767 mu_techo[((1+prob1)/2)*1000] ## [1] 103.322 En esta simulación en concreto obtenemos que el rango está entre 98.9 y 103.3. Es decir que si escogemos una muestra de las 1000 al azar, tenemos una probabilidad del 90% de que \\(\\hat{\\mu}\\) de esta muestra esté entre estos dos valores. Podemos escribirlo como \\[P[98,9 \\leq \\hat{\\mu} \\leq 103,3] = 0.9\\] Como hemos creado este mundo, conocemos la media. Esto nos permite reescribir la expresión como \\[P[101,07 - 98,95 = 2,11 \\leq \\hat{\\mu} - \\mu \\leq 103,3 - 101,07 = 2,24] = 0.9\\] Y esto nos permite escribir \\[P[ \\hat{\\mu} - 2,11 \\leq \\mu \\leq \\hat{\\mu} + 2,24] = 0.9\\] Es decir, que si cogemos una muestra al azar y medimos la proporción de esta muestra, \\(\\hat{\\mu}\\), tenemos una probabilidad de \\(0.9\\) de que \\(\\mu\\), la media de la población total, esté \\(2,11\\) por debajo o \\(2,24\\) por encima de este valor. Podemos repetir esto con cualquier probabilidad que queramos. Por ejemplo 0.8 o 0.95: # El 80% central prob2 = 0.80 mu_techo[((1-prob2)/2)*1000] ## [1] 99.35537 mu_techo[((1+prob2)/2)*1000] ## [1] 102.7825 # El 95% central prob3 = 0.95 mu_techo[((1-prob3)/2)*1000] ## [1] 98.51402 mu_techo[((1+prob3)/2)*1000] ## [1] 103.7399 En estos casos obtenemos que hay una probabilidad de 0.8 de que la media de la población total \\(\\mu\\) esté en \\([99.35,\\, 102.79]\\) o, lo que es lo mismo, en \\(\\hat{\\mu}\\pm 0,045\\). Y una probabilidad de \\(0.95\\) de que esté en \\([98.51,\\, 103.74]\\) o, lo que es lo mismo, en \\(\\hat{\\mu}\\pm 2,61\\). Es importantísimo no olvidar que esto son probabilidades. Hay un buen número de muestras, perfectamente hechas y perfectamente válidas, que están fuera de nuestra horquilla. Además, en nuevas simulaciones obtendríamos valores diferentes. Estamos cuantificando la incertidumbre. Esa es la palabra clave: incertidumbre. Y la cuantificamos, no la eliminamos. 10.2.2 Intervalos de confianza En nuestra simulación, nuestra creación, conocíamos \\(\\mu\\) y esto nos permitía calcular la horquilla. Pero el caso real es que no conocemos \\(\\mu\\). Precisamente tomamos la muestra para saber algo de \\(\\mu\\). Para poder rigurosamente saber algo de \\(\\mu\\) a partir de \\(\\hat{\\mu}\\) necesitamos el razonamiento matemático —casi análogo al hecho en el caso de las proporciones— que vamos a detallar. Sea \\(X\\) una variable aleatoria que es el resultado de una medida numérica. De \\(X\\) no sabemos nada: no sabemos su distribución, no sabemos ni tan siquiera si es continua o discreta. Llamaremos \\(\\mu\\) al valor esperado de \\(X\\), \\(E[X] = \\mu\\), y \\(\\sigma\\) a la desviación típica de \\(X\\), \\(\\sigma = \\mbox{sd}[X]\\). Tomamos una muestra de \\(n\\) elementos. La muestra la tomamos de manera que las medidas sean independientes. Obtenemos así \\(n\\) valores de \\(X\\), todas independientes e idénticamente distribuidas, lo que llamábamos iid. La media de la muestra es \\(\\hat{\\mu}\\) y la desviación típica de la muestras es \\(\\hat{\\sigma}\\) (aquí si usamos el circunflejo). La media de la muestra, es otra variable aleatoria: \\[\\hat{\\mu} = \\frac{X + X + \\cdots + X}{n}.\\] El valor esperado de \\(\\hat{\\mu}\\) es: \\[E[\\hat{\\mu}] = E\\left[\\frac{X + X + \\cdots + X}{n}\\right] = \\frac{E[X + X + \\cdots + X]}{n} = \\frac{n \\, E[X]}{n} = \\mu\\] Esto quiere decir que el valor medido, y conocido, \\(\\hat{\\mu}\\) va a estar alrededor de donde está nuestro desconocido \\(\\mu\\). Es una buena noticia. Calculemos ahora la desviación típica de \\(\\bar{X}\\), la media de las variables aleatorias: \\(\\mbox{sd}[\\bar{X}]\\). Es la desviación típica de una suma de variables aleatorias, dividida por una constante: \\[\\begin{eqnarray*} \\mbox{sd}[\\bar{X}] &amp; = &amp; \\mbox{sd}\\left[\\frac{X + X + \\cdots + X}{n}\\right]\\\\ &amp; = &amp; \\frac{\\mbox{sd}[X + X + \\cdots + X]}{n}\\\\ &amp; = &amp; \\frac{\\sqrt{\\sigma^2 + \\sigma^2 + \\cdots + \\sigma^2}}{n}\\\\ &amp; = &amp; \\frac{\\sqrt{n \\cdot \\sigma^2}}{n} = \\frac{\\sigma}{\\sqrt{n}} \\end{eqnarray*}\\] Desgraciadamente esto no nos ayuda mucho. Hemos obtenido la desviación típica de \\(\\hat{\\mu}\\) en función de la desconocida \\(\\sigma\\). Para resolver este problema hacemos algo muy parecido a lo que hacíamos en el caso de las proporciones: calculamos la desviación típica de la muestra y definimos el error estándar de \\(\\hat{\\mu}\\), \\(\\mathrm{se}(\\hat{\\mu})\\), como \\[\\mathrm{se}(\\hat{\\mu}) = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\] Es decir, el error estándar tiene la misma expresión que la desviación típica, pero sustituyendo la desconocida \\(\\sigma\\) por la conocida \\(\\hat{\\sigma}\\). Estamos en condiciones de volver a aplicar el teorema central del límite. Podemos establecer que \\[\\frac{\\hat{\\mu} - \\mu}{\\mathrm{se(}\\hat{\\mu})} \\leadsto \\mathrm{N}(0, 1)\\] Otra vez, cuanto mayor es \\(n\\) más cerca está la distribución de \\((\\hat{\\mu} - \\mu)/\\mathrm{se}(\\hat{\\mu})\\) de la normal de media 0 y desviación típica 1. Sabiendo esto podemos recuperar la estrategia que usamos en la simulación. Suponemos que \\(n\\) es lo suficientemente grande para que podamos usar la normal N(0, 1) sin demasiado error. Como en la simulación, nos interesa el rango del, digamos, 90% central de los datos, “quitamos” de N(0, 1) el 5% del extremo inferior y el 5% del extremo superior. Esto lo podemos hacer con R con la función qnorm(). La instrucción sería qnorm(0.05, 0, 1) para el inferior y qnorm(0.95, 0, 1) para el superior. Los valores que obtenemos son \\(-1,645\\) y \\(1,645\\). Ahora podemos escribir: \\[P[-1,645 \\leq \\frac{\\hat{\\mu} - \\mu}{\\mathrm{se(}\\hat{\\mu})} \\leq 1,645] = 0.9\\] lo que con un poco de álgebra se convierte en: \\[P[\\hat{\\mu}-1,645\\,\\mathrm{se(}\\hat{\\mu}) \\leq \\mu \\leq \\hat{\\mu} + 1,645\\,\\mathrm{se(}\\hat{\\mu})] = 0.9.\\] Es decir que hay una probabilidad de 0,9 de que el valor de toda la población, esa desconocida \\(\\mu\\), esté a 1,645 veces el error estandar por encima o por debajo del \\(\\hat{\\mu}\\), el valor medido en nuestra muestra. Este es el Intervalo de Confianza de la media. Naturalmente, podemos repetir esto para cualquier valor de probabilidad que nos interese. Lo hemos hecho con 0,9, pero lo podemos hacer con 0,8, 0,95, 0,7732… A esta probabilidad se le llama el nivel de confianza. Un intervalo de confianza de medias a un nivel de confianza NC es el intervalo centrado en \\(\\hat{\\mu}\\) en el que se estima que estará la media de la población \\(\\mu\\) con una probabilidad NC. Algunas cuestiones a tener en cuenta. Estas son similares a las que teníamos en el caso de las proporciones: Nadie asegura que \\(\\mu\\) esté en el intervalo de confianza. Siempre hay una probabilidad de que esté fuera. A la hora de calcular el intervalo estamos suponiendo que hemos tomado la muestra con todo rigor: de forma aleatoria, sin sesgos, etc. Si no es así, si la muestra está mal tomada, no significa que el intervalo es mayor, significa que no sabemos nada: puede ser mayor, puede ser menor, puede estar en otro lado. Estamos suponiendo independencia. Cuánto mayor es el nivel de confianza, mayor será el intervalo: si queremos estar más seguros que el valor de la población está en el intervalo, debemos hacerlo mayor. Hay una cuestión específica al caso de intervalos de confianza de medias: ¿cómo de rápido se acerca \\((\\hat{\\mu} - \\mu)/\\mathrm{se}(\\hat{\\mu})\\) a la distribución normal? Esto depende mucho de la problematicidad de la población. Y requiere un apartado propio. 10.2.3 La distribución t de Student No hemos puesto ninguna condición sobre la distribución de \\(X\\). Mientras nos aseguremos que los elementos de la muestra son independientes, puede ser cualquier cosa. Pero ya nos podemos imaginar que no va a dar lo mismo una distribución que otra. Aquí es donde entra en juego la problematicidad de la población. Distingamos varios casos, de menos problemáticos a más. Caso 1: distribución normal. El primer caso es que \\(X\\) sigue una distribución normal. En este caso se sabe exactamente cómo se acerca \\((\\hat{\\mu} - \\mu)/\\mathrm{se}(\\hat{\\mu})\\) a la distribución normal al aumentar \\(n\\). Esto lo recoge la distribución t de Student. Esta distribución la desarrolló William S. Gosset mientras trabajaba para la Guiness en el control de calidad de las cervezas. Tenía prohibido por la empresa publicar nada (para guardar el secreto industrial) y por eso usó un seudónimo: Student. La distribución t tiene un único parámetro: los grados de libertad. Es un número mayor que 0 y para el cálculo de los intervalos de confianza equivale a \\(n-1\\). A medida que \\(n\\) aumenta, la distribución t se acerca a la normal N(0, 1) exactamente de la forma que queremos. Por lo tanto si \\(X\\) sigue una distribución normal, usando la distribución t en vez de N(0, 1) tenemos el intervalo de confianza de forma exacta y no aproximada incluso para valores tan pequeños como \\(n = 3\\). Lo único que cambia en el método de trabajo es que hemos de usar la función qt() en vez de qnorm(). Caso 2: distribuciones de problematicidad baja. En caso de problematicidad baja, la distribución de \\(\\hat{\\mu}\\) se acerca a N(0, 1) bastante rápidamente. Seguimos usando la distribución t para mayor seguridad y se considera que con valores tan pequeños como \\(n = 6\\) la aproximación es buena. Caso 3: distribuciones de problematicidad media. Si la problematicidad es media, porque es claramente asimétrica o tenemos algunos valores atípicos no muy extremos, podemos seguir usando el método descrito con la distribución t si cogemos \\(n = 15\\) o mayor. Pero la incertidumbre es mayor y no nos podemos fiar mucho de los resultados. Caso 4: distribuciones de problematicidad alta. Si la problematicidad es alta, con distribuciones fuertemente asimetricas y valores atípicos extremos, nunca podemos sentirnos seguros. Podemos calcular el intervalo de confianza si las \\(n\\) son grandes (30, 50 o más) pero es por poder decir algo. La incertidumbre es demasiado alta para poder usar los resultados. 10.2.4 Fuga de probabilidades Al igual que en el caso de las proporciones, puede darse el caso de tener un intervalo de confianza que incluya valores imposibles, por ejemplo pesos negativos. Es menos habitual que en el caso de las proporciones. Cuando se da, normalmente se trata el caso como si fuera de problemáticidad alta. 10.2.5 Un ejemplo Queremos medir el peso de las galletas que entran en una bolsa en una fábrica artesanal. No tenemos aparatos de medida, sino que se meten galletas hasta que “esté llena”. Los datos parecen no ser problemáticos y por lo tanto cogemos el peso de 8 bolsas para hacer nuestra media. Los valores que obtenemos son: 443, 439, 466, 486, 462, 443, 494 y 476 Calculamos la media y la distribución estándar de la muestra y obtenemos \\[\\hat{\\mu} = 463.62; \\qquad \\hat{\\sigma} = 20.85\\] El error estándar es \\[\\mathrm{se}(\\hat{\\mu}) = \\frac{\\hat{\\sigma}}{\\sqrt{n}} = \\frac{20.85}{\\sqrt{8}} = 7.37.\\] Queremos calcular el intervalo de confianza con niveles de confianza del 85% y 95%. Usamos la distribución t de Student con 7 grados de libertad para determinar los factores por los que hemos de multiplicar el error estándar. En R qt(0.925,7) ## [1] 1.616592 qt(0.975,7) ## [1] 2.364624 Entonces el intervalo de confianza con un nivel de confianza del 85% es \\[[463.62 - 7.37\\cdot 1.617,\\; 463.62 + 7.37\\cdot 1.617] = [451.7,\\; 475.5]\\] y con un nivel de confianza del 95% es \\[[463.62 - 7.37\\cdot 2.365,\\; 463.62 + 7.37\\cdot 2.365] = [446.2,\\; 481.1]\\] 10.2.6 Resumen de intervalos de confianza de medias Sea \\(\\mu\\) la media de toda una población de una variable de interés. Tomamos una muestra de tamaño \\(n\\), suficientemente grande. La muestra ha sido tomada con todo rigor. Llamamos \\(\\hat{\\mu}\\) a la media de la muestra de la variable de interés. Un intervalo de confianza de medias a un nivel de confianza NC es el intervalo centrado en \\(\\hat{\\mu}\\) en el que se estima que estará la madia de la población \\(\\mu\\) con una probabilidad NC. Para calcular el intervalo de confianza debemos: Estudiar la problematicidad de la distribución y escoger un tamaño de muestra adecuado si no es muy problemática. Si es muy problemática los resultados jamás serán suficientemente fiables. Calcular \\(\\hat{\\mu}\\); Calcular el error estándar \\[\\mathrm{se}(\\hat{\\mu}) = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\] Determinar el nivel de confianza NC que queremos para nuestro intervalo; Calcular el factor \\(\\mathit{fc}\\) para este nivel de confianza usando la distribución t. En R podemos usar la función qt()}:fc = qt((1+nc)/2, n-1)}; El intervalo de confianza para este nivel de confianza es \\[ [\\hat{\\mu} - \\mathit{fc}\\cdot \\mathrm{se}(\\hat{\\mu}), \\; \\hat{\\mu} + \\mathit{fc}\\cdot \\mathrm{se}(\\hat{\\mu})].\\] 10.3 Comparación de intervalos de confianza Cuando se acercan elecciones nos inundan de encuestas y siempre comparan una encuesta con la anterior para ver si ha habido un «cambio en la intención de voto». Para controlar la calidad de una máquina de pintado se mide el grosor de pintura en varios puntos para ver si de promedio ha cambiado con respecto a hace unos días, ya que esto nos permitirá detectar si hay algun problema antes de que se salga de las especificaciones. Sabemos que al tratar con muestras hay una incertidumbre en la medida relacionada con la variabilidad inherente en el muestreo y por lo tanto no esperamos obtener exactamente la misma proporción en las encuestas o la misma media de grosor de la pintura. ¿Pero cómo podemos saber si una pequeña variación en la muestra representa una variación en la población? Esta es una de las preguntas fundamentales de la estadística que se irá respondiendo de varias maneras. Empecemos respondiéndola a partir de los intervalos de confianza. 10.3.1 No puedo decir que sean distintos En una encuesta de intención de voto obtenemos que 476 de 1374 encuestados tienen intención de votar al Partido Especulativo (PE). Esto nos da \\(\\hat{\\theta}_{1} = 0.346\\). Escogemos un nivel de confianza de 90% y obtenemos el intervalo de confianza \\([0.325; 0.368]\\). Al cabo de un mes repetimos la encuesta y nos responden que piensan votar al PE 512 de 1412 encuestados, lo que nos da \\(\\hat{\\theta}_{2} = 0.363\\) y un intervalo de confianza \\([0.342; 0.384]\\). En la figura siguiente se muestran gráficamente estos intervalos de confianza. En los periódicos afines al PE cuentan alborozados que la intención de voto ha subido, mientras que los críticos dicen que hay un «empate técnico» y que no ha variado. ¿Qué dice la estadística? Lo que queremos es saber si las proporciones de toda la población, \\(\\theta_{1}\\) y \\(\\theta_{2}\\), han cambiado. Es decir si \\(\\theta_{1}\\) es mayor o menor que \\(\\theta_{2}\\). Para determinar esto tenemos como evidencia \\(\\hat{\\theta}_{1}\\) y \\(\\hat{\\theta}_{2}\\). Una primera respuesta es lógica y no estadística. ¿Ha cambiado la proporción? Seguro que sí. Es imposible que nadie haya cambiado de opinión y además ha habido nacimientos y muertes. Seguro que ha cambiado. Para eso no necesitamos la estadística. Además, la estadística clásica, que es la que explicamos aquí, no puede responder a la pregunta de si ha cambiado. Tampoco si ha cambiado mucho. Lo que la estadística puede responder, y sólo añadiendo probabilidades, es a la pregunta «Con la evidencia que tengo, ¿puedo decir que sean diferentes?». Nótese que las posibles respuestas son Esta evidencia me permite decir que hay una determinada probabilidad de que sean diferentes por un lado y Esta evidencia no me permite decir que sea probable que sean diferentes. Claramente un tanto enrevesado. Pero esto es lo que la estadística puede hacer y más vale que nos acostumbremos a ello. Otra manera de verlo, que no es exacta pero que reconcilia la lógica y la estadística y es más fácil de entender, es la siguiente. La lógica nos dice que la proporción seguro que ha cambiado. Lo que nos interesa saber es si ha crecido. La estadística nos permite decir, dada la evidencia y con una cierta probabilidad, si ha crecido ha decrecido no sé si ha crecido o decrecido Podríamos decir en este tercer caso que, aunque seguro que son distintos, son indistinguibles. Es muy importante entender qué es lo que puede y no puede afirmar la estadística. Hay que distinguir entre «No puedo decir que son diferentes» con «Son iguales». Y siempre a partir de la evidencia que se tenga. Con evidencia diferente, pueden salir conclusiones distintas. 10.3.2 Cálculo de intervalos de confianza de diferencias Volvamos al problema original, ¿tengo evidencia que la intencion de voto ha cambiado? O visto de la segunda manera ¿puedo considerar probable que haya crecido? Si miramos la gráfica, aunque \\(\\hat{\\theta}_{2}&gt; \\hat{\\theta}_{1}\\), vemos que hay mucho solapamiento entre los dos intervalos. No es difícil imaginarse que esta diferencia entre los valores medidos \\(\\hat{\\theta}_{1}\\) y \\(\\hat{\\theta}_{2}\\) sea debido a variaciones del muestreo y que también pudiera ser que \\(\\theta_{1} &lt; \\theta_{2}\\). ¿Pero cómo lo podemos calcular de forma rigurosa? Lo que tenemos que hacer es calcular el intervalo de confianza de \\(\\theta_{1} - \\theta_{2}\\). O de \\(\\theta_{2} - \\theta_{1}\\) que es en el fondo lo mismo. Hacer un cáclulo preciso de este intervalo de confianza de la diferencia es un tanto complicado y lo dejaremos a R, pero la idea básica es simple, hacer un cálculo aproximado, también lo es. Vamos primero al caso del intervalo de confianza de la diferencia de proporciones. Tenemos dos variables aleatorias \\(\\hat{\\theta}_{1}\\) y \\(\\hat{\\theta}_{2}\\), de valores esperados \\(\\theta_{1}\\) y \\(\\theta_{2}\\) y desviaciones típicas \\(\\sigma_{1}\\) y \\(\\sigma_{2}\\) y queremos hallar la distribución de \\(\\theta_{1} - \\theta_{2}\\). Sabemos que el valor esperado de esta resta será \\(\\theta_{1} -\\theta_{2}\\) y que su desviación típica es \\(\\sqrt{\\sigma_{1}^{2} + \\sigma_{2}^{2}}\\). Seguimos con el problema de no saber \\(\\sigma_{1}\\) y \\(\\sigma_{2}\\), pero lo podemos aproximar mediante el error estándar. Luego podemos decir que el error estándar de \\(\\hat{\\theta}_{1} - \\hat{\\theta}_{2}\\) es \\(\\sqrt{\\mathrm{se}(\\hat{\\theta}_{1})^{2} + \\mathrm{se}(\\hat{\\theta}_{2})^{2}}\\). Con esto podemos calcular para cualquier nivel de confianza que queremos una aproximación del intervalo de confianza de la diferencia de las proporciones. Para el intervalo de confianza de la diferencia de medias seguimos la misma idea. Tenemos dos variables aleatorias \\(\\hat{\\mu}_{1}\\) y \\(\\hat{\\mu}_{2}\\) de valores esperados \\(\\mu_{1}\\) y \\(\\mu_{2}\\) y desviaciones típicas \\(\\sigma_{1}\\) y \\(\\sigma_{2}\\) y queremos hallar la distribución de \\(\\hat{\\mu}_{1} - \\hat{\\mu}_{2}\\). Sabemos que el valor esperado de esta resta será \\(\\mu_{1} -\\mu_{2}\\) y que su desviación típica es \\(\\sqrt{\\sigma_{1}^{2} + \\sigma_{2}^{2}}\\). Seguimos con el problema de no saber \\(\\sigma_{1}\\) y \\(\\sigma_{2}\\), pero lo podemos aproximar mediante el error estándar: \\(\\sqrt{\\mathrm{se}(\\hat{\\mu}_{1})^{2} + \\mathrm{se}(\\hat{\\mu}_{2})^{2}}\\). Hay un problema adicional a resolver: ¿qué grado de libertad debemos usar para la distribución t?. Cogemos el peor caso: el menor entre \\(n_{1} -1\\) y \\(n_{2} -1\\). Con esto podemos calcular aproximadamente el intervalo de confianza de la diferencia de las medias. Una vez tenemos este intervalo de confianza de la diferencia, sea de proporciones o de medias, hemos de responder a la pregunta de si podemos afirmar que uno es mayor que el otro. Este intervalo nos da, con la confianza que hayaos usado, la diferencia de los valores de las poblaciones. Por ejemplo, si nos sale, para uno de proporciones, que el IC es [0,075; 0,092] esto quiere decir que, con la confianza que sea, la proporción \\(\\theta_{1}\\) es entre un 7,5% mayor y un 9% mayor que la proporción \\(\\theta_{2}\\). Vemos que en este caso tenemos bastante confianza que \\(\\theta_{1} &gt; \\theta_{2}\\). En cambio, si para uno de medias nos sale que el IC es [-2,3; 4,5], esto quiere decir que \\(\\mu_{1}\\) tanto puede ser 2,3 unidades menor que \\(\\mu_{2}\\) como 4,5 unidades mayor. Luego no sabemos si \\(\\mu_{1}\\) es mayor que \\(\\mu_{2}\\) o no. Son indistinguibles. De estos ejemplos extraemos como saber si dos estadísticos —proporciones o medias— son o no indistinguibles: si los extremos cambian de signo, o equivalentemente si el valor 0 está incluido en el intervalo, son indistinguibles. Si ambos extremos son positivos o negativos, podemos deducir, con la confianza que sea, que uno es mayor que el otro. Incorrectamente se suele decir que no podemos decir que son diferentes. Y, aún más incorrectamente, a veces se dice que son iguales. Nosotros diremos que, con la evidencia que tenemos, son indistinguibles. Comparación gráfica. Si queremos saber de forma numérica cuál es el intervalo de confianza de la diferencia, no tenemos más remedio que hacer los cálculos, ya sea de forma aproximada como hemos explicado antes, o, mucho mejor, de forma más exacta usando R, como explicaremos en el apartado siguiente. Pero si lo que queremos es simplemente saber si dos estadísticos son indistinguibles o no, nos puede bastar una comparación gráfica. Partimos de dos intervalos de confianza con el mismo nivel de confianza. Dibujamos ambos, uno encima de otro, tal como vemos en la figura: Si ambos intervalos solapan mucho como es el caso (a), entonces se puede demostrar que los estadísticos son indistinguibles. ¿Qué quiere decir solapar mucho? Pues que el valor muestral del primero está en el intervalo del segundo y que el valor muestral del segundo está en el intervalo del primero. Ambas cosas. Si no solapan en absoluto, como es el caso (b), entonces se puede demostrar que lso estadísticos no son indistinguibles: el intervalo de confianza de la diferencia no va a contener el 0. Si solapan algo, como es el caso (c), no podemos decir nada y hay que calcular el intervalo de confianza de la diferencia. 10.3.2.1 Calculando intervalos con R Hemos mostrado en las secciones precedentes cómo se calculan intervalos de confianza de una proporción o una media ``a mano’’. Ahora veremos cómo se hace con R y extenderemos el cálculo a intervalos de confianza de diferencias de proporciones y medias. Intervalo de confianza de proporciones. La función de R prop.test() nos permite calcular intervalos de confianza. Su uso para el intervalo de confianza de una proporción es prop.test(x, n, conf.level = 0.95). Sus parámetros principales son: x es el número de éxitos, n es el número de intentos y conf.level es el nivel de confianza, que por defecto es del 95%. Para calcular el intervalo de confianza del primer caso del ejemplo inicial escribimos prop.test(475, 1234, 0.9). La salida que obtenemos es: prop.test(476,1374, conf.level = 0.9) ## ## 1-sample proportions test with continuity correction ## ## data: 476 out of 1374, null probability 0.5 ## X-squared = 129, df = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: true p is not equal to 0.5 ## 90 percent confidence interval: ## 0.3252813 0.3682002 ## sample estimates: ## p ## 0.3464338 Hay algunas cosas que podemos reconocer de la salida. Tras data: tenemos los datos de partida: 476 éxitos de 1374 intentos. Unas líneas más abajo tenemos el intervalo de confianza: \\([0.3252; 0.3682]\\) y finalmente el valor de \\(\\hat{\\theta}: 0.346\\). El resto de la salida en este momento no nos interesa. El método que usa R para calcular el intervalo de confianza es más complejo y sofisticado que el que explicamos nosotros. En este caso han salido los mismos valores a 3 decimales, pero en otros casos pueden ser algo distintos. El método de R es algo más preciso, sobre todo con \\(n\\) pequeñas, y es el que debemos usar. En el caso de querer calcular el intervalo de confianza de la diferencia de proporciones, los parámetros x y n se convierten en vectores: el vector de éxitos y el vector de intentos. En el ejemplo inicial teníamos que las dos muestras eran 476 éxitos de 1374 y 512 de 1412. Para introducirlo en R necesitamos dos vectores de dos posiciones: el de éxitos es (476, 512) y el de intentos, que es (1375, 1412). Un error frecuente es darle a R un vector de cada caso (que serían para este ejemplo (476, 1374) y (512, 1412)). No es esto lo que R quiere, sino por un lado los éxitos y por otro los intentos. Supongamos que ahora queremos que el nivel de confianza sea del 95%. Como es el valor por defecto no tenemos que ponerlo y nos queda: prop.test(c(476,512),c(1374,1412)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(476, 512) out of c(1374, 1412) ## X-squared = 0.72671, df = 1, p-value = 0.394 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.05241245 0.02006753 ## sample estimates: ## prop 1 prop 2 ## 0.3464338 0.3626062 Vemos que el intervalo de confianza de la diferencia \\(\\theta_{1}-\\theta_{2}\\) es \\([-0.052; 0.020]\\). Esto quiere decir que, con una probabiliad de 0.95, la diferencia puede ir desde que \\(\\theta_{1}\\) sea un 2% mayor a \\(\\theta_{2}\\) a que \\(\\theta_{2}\\) sea un 5% mayor que \\(\\theta_{1}\\). Con esta evidencia no sabemos cuál es mayor, no son distinguibles. Intervalo de confianza de medias. Para calcular los intervalos de confianza de medias usamos la función de R t.test(). Esta función hace muchas más cosas, que veremos en secciones posteriores, pero ahora sólo nos interesa el intervalo de confianza. Para ver su uso partamos del ejemplo de la sección anterior, del peso medio de bolsas de galletas. Recordemos que teníamos 8 pesos que eran 443, 439, 466, 486, 462, 443, 494 y 476. La función tiene dos parámetros principales que son x, el vector de datos, y conf.level, el nivel de confianza, con un valor por defecto de 0.95. En el ejemplo calculábamos el intervalo de confianza con un nivel de confianza del 85%. Creamos el vector pesoGalletas y lo introducimos como parámetro en t.test(): pesoGalletas = c(443, 439, 466, 486, 462, 443, 494, 476) t.test(pesoGalletas, conf.level = 0.85) ## ## One Sample t-test ## ## data: pesoGalletas ## t = 62.906, df = 7, p-value = 6.738e-11 ## alternative hypothesis: true mean is not equal to 0 ## 85 percent confidence interval: ## 451.7105 475.5395 ## sample estimates: ## mean of x ## 463.625 De la salida nos interesan 3 ítems: tras data vemos el nombre de nuestro vector; tenemos el intervalo de confianza, que es \\([451.7105; 475.5395]\\) y finalmente la media del vector que es \\(463.625\\). En este caso R calcula el intervalo de confianza con el método que explicamos y los resultados son idénticos. La función t.test() requiere todos los datos: no se le puede meter la media y desviación típica. Si sólo tenemos eso, tendremos que calcular el intervalo de confianza a mano. En el caso de querer calcular el intervalo de confianza de la diferencia, necesitamos introducir los dos vectores de datos. El conjunto de datos BushApproval del paquete UsingR contiene los datos de la aprobación del presidente norteamericano George W. Bush durante su mandato según diferentes agencias de noticias. Vamos a comparar la media de aprobación según las cadenas Fox y la revista Newsweek. Metemos los 64 valores de la cadena Fox en el vector BAf y los 55 de la revista Newsweek en el vector BAn y buscamos el intervalo de confianza de la diferencia con un nivel de confianza del 95% con t.test(): library(UsingR) attach(BushApproval) BAf = BushApproval[who == &quot;fox&quot;,]$approval BAn = BushApproval[who == &quot;newsweek&quot;,]$approval t.test(BAf, BAn) ## ## Welch Two Sample t-test ## ## data: BAf and BAn ## t = 0.25254, df = 103.28, p-value = 0.8011 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.856791 4.982359 ## sample estimates: ## mean of x mean of y ## 65.67188 65.10909 detach(BushApproval) Recordamos que 0.95 es el valor del nivel de confianza por defecto y por lo tanto no hace falta introducirlo. Vemos en la salida que las medias de aprobación son \\(65.67\\) para la Fox y \\(65.10\\) para Newsweek, bastante parecidas, y que el intervalo de confianza es \\([-3.86; 4.98]\\). Esto quire decir que, con una probabilidad del 95%, la media ``real’’ de aprobación de la cadena Fox puede ser desde \\(3.86\\) puntos por debajo del de Newsweek a \\(4.98\\) puntos por encima. 10.3.3 Más ejemplos En una cervecería han cambiado la receta de una de las cervezas y quieren saber si gusta más. Pasaron una pequeña encuesta con la cerveza antigua y con la nueva. Con la antigua, 183 personas de 434 dijeron que era «Buena» o «Muy buena». Con la nueva receta, son 251 personas de 501 encuestadas las que la han calificado de «Buena» o «Muy buena». A partir de esta evidencia, ¿hay más gente a quién le gusta la nueva cerveza que la antigua? Empecemos por calcular los intervalos de confianza de las proporciones de las dos cervezas. Vamos a suponer en todo el problema un nivel de confianza del 95%. Usamos R y las instrucciones prop.test(183, 434) y prop.test(251,501). De ellas obtenemos que las proporciones medidas son \\(\\hat{\\theta}_{a} = 0.422\\) y \\(\\hat{\\theta}_{n} = 0.501\\), una diferencia de proporciones del 8%. Esto no nos asegura que \\(\\theta_{n} &gt; \\theta_{a}\\). Miramos los intervalos de confianza y son \\([0.375; 0.470]\\) para la antigua y \\([0.456; 0.546]\\) para la nueva. Se solapan un poco. Seguimos sin estar seguros si hay diferencia entre las proporciones reales o no. En forma gráfica, los resultados son: Calculemos el intervalo de confianza de la diferencia. El código de R es: BoMB = c(183, 251) n = c(434, 501) prop.test(BoMB, n) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: BoMB out of n ## X-squared = 5.5709, df = 1, p-value = 0.01826 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.14532785 -0.01335018 ## sample estimates: ## prop 1 prop 2 ## 0.421659 0.500998 Obtenemos un intervalo de confianza de la diferencia de \\([-0.145; -0.013]\\). Es decir es probable que la cerveza antigua guste a una menor proporción de gente. No sabemos exactamente cuánta es esa diferencia de proporciones, pero cuantificamos nuestra incertidumbre mediante el intervalo de confianza de la diferencia y damos una probabilidad del 95% de que la cerveza antigua guste a entre un 1% y un 15% menos de gente. O lo que es lo mismo, la nueva guste a entre un 1% y un 15% más de gente. No hemos de olvidar que hay una probabilidad del 5% que la diferencia de las proporciones reales sea menor o mayor que estos valores. En el fichero Alturas2013.csv están las alturas de los alumnos de la asignatura de estadística desde el año 2011 al 2013, junto con la de sus padres y sus madres. En la columna «Talla» está la altura del alumno; en las columnas «TallaP» y «TallaM» están las de los padres y madres respectivamente; en la columna «Sexo» está el sexo del alumno; la columna «Duplicado» indica si el dato está duplicado (alumnos repetidores dieron sus datos más de una vez) y finalmente en la columna «Curso» está el curso de donde proceden los datos. Usaremos esta muestra como muestra de todos los jóvenes de Mallorca y queremos saber si la altura media de todos los jóvenes mallorquines, \\(\\mu_{j}\\) es mayor que la de sus padres, \\(\\mu_{p}\\). Empecemos por obtener los datos. Leemos en R el fichero, eliminamos los duplicados y las alumnas y los datos incompletos (algunos alumnos no dieron toda la información pedida): alturas = read.table(&quot;datos/Alturas2013.csv&quot;, header = T, sep = &quot;;&quot;) #Solo hombre y no duplicados altHSD = alturas[alturas$Duplicado == &quot;N&quot; &amp; alturas$Sexo == &quot;H&quot;,] #Quitamos datos con NA altHSD = altHSD[complete.cases(altHSD),] Lo primero que haremos es calcular los intervalos de confianza de las medias de las dos poblaciones. Seguimos eligiendo un nivel de confianza del 95%: attach(altHSD) ## The following objects are masked _by_ .GlobalEnv: ## ## Curso, Sexo, Talla, TallaM #Padres e hijos por separado t.test(Talla) ## ## One Sample t-test ## ## data: Talla ## t = 160.5, df = 56, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 168.0168 172.2639 ## sample estimates: ## mean of x ## 170.1404 t.test(TallaP) ## ## One Sample t-test ## ## data: TallaP ## t = 319.26, df = 161, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 174.7518 176.9272 ## sample estimates: ## mean of x ## 175.8395 La gráfica con los dos intervalos está en la figura siguiente. Vemos que en este caso no solapan: la de los jóvenes (en rojo) tiene una media \\(\\hat{\\mu}_{j} = 178.5\\) mientras que la de los padres (en zaul) es \\(\\hat{\\mu}_{p} = 175.8\\) y los intervalos con \\([177.4; 179.5]\\) para los jóvenes y \\([174.8; 176.9]\\) para los padres. El que los intervalos no solapen es una indicación clara que la media “real” \\(\\mu_{j}\\) de los jóvenes es mayor que la de sus padres, \\(\\mu_{p}\\). Pero para tener una idea de cuánto, necesitamos el intervalo de confianza de la diferencia de medias. La instrucción t.test(Talla, TallaP) nos lo calcula. Obtenemos un intervalo de \\([1.13; 4.09]\\). Seguimos con incertidumbre, pero la cuantificamos y podemos decir que, con una probabilidad de 0,95, los jóvenes son de media entre \\(1.1\\mbox{ cm}\\) y \\(4.1\\mbox{ cm}\\) más altos que sus padres. Y hay una probabilidad del 5% que la diferencia sea menor o mayor. 10.3.4 Resumen de comparación de intervalos de confianza La estadística clásica no permite establecer si las proporciones de dos poblaciones o la media de dos poblaciones son iguales o distintas. Lo que permite es decir «Los datos me permiten tener una cierta seguridad de que son distintas» o «Los datos no me permiten tener una seguridad de que son distintas». Otra manera de verlo es «Estos datos me permiten tener una cierta seguridad para determinar cuál es mayor» y «Con estos datos no tengo suficiente seguridad para determinar cuál es mayor». Si no podemos determinar que son distintos, o no podemos determinar cuál es el mayor, diremos que los datos son indistinguibles. Lo primero que debemos hacer es calcular los intervalos de confianza de ambas medias o ambas proporciones con el mismo nivel de confianza. Si los intervalos no se solapan, hay una alta probabilidad que uno es mayor que el otro. Si se solapan tanto que el valor medido de uno (\\(\\hat{\\mu}\\) o \\(\\hat{\\theta}\\)) está en el intervalo del otro y el del otro en el intervalo del uno, hay una alta probabilidad de que sean indistinguibles. Si hay un solapamiento menor, no sabemos si son indistinguibles o no. En los tres casos conviene calcular el intervalo de confianza de la diferencia de las medias o proporciones. La idea básica parte de que estamos restando variables aleatorias: el valor esperado de las restas es la resta de valores esperados, que es la resta de los valores medidos, y la desviación típica de la diferencia es la raíz cuadrada de la suma de los cuadrados de las desviaciones típicas. Se puede calcular a partir de aquí el error estándar de la diferencia, pero es algo más complicado que en el caso de sólo tener una media o proporción y lo dejaremos a R. Las funciones prop.test() para las propociones y t.test() para las medias nos dará toda la información que queremos, tanto en el caso de una variable como en la diferencia de dos variables. En el caso de la diferencia, si el 0 está en el intervalo de confianza, diremos que las variables son indistinguibles. Si no lo está sabemos cuál es la mayor y el intervalo nos dice, con una probabilidad igual al nivel de confianza, el rango en el que va a estar la diferencia de las medias de las poblaciones o las proporciones de las poblaciones. "],
["contrastes-de-hipotesis.html", "Capítulo 11 Contrastes de hipotesis 11.1 Experimentos estadísticos para un contraste de hipótesis 11.2 Interpretación del p-valor.", " Capítulo 11 Contrastes de hipotesis Un primer caso. Estamos paseando por el Arenal y nos encontramos con un trilero que “juega” con los turistas. Antes de jugar nosotros (somos un poco ludópatas) decidimos estudiar si el juego es justo o no (somosludópatas, pero no estúpidos). Si el juego es justo el trilero debería ganar de media la mitad de las veces. Pero como hay la variabilidad natural de lo aleatorio, puede ser que en un juego justo tenga una buena racha y gane más de la mitad de las veces si sólo miro unas pocas partidas. Decido observar 40 partidas para ver si gana más veces de las 20 que tocaría (si gana menos veces es su problema y no el mío). Por la variabilidad de la situación estoy dispuesto a aceptar que gane algo más de 20 partidas, pero no mucho más. ¿Pero cuánto es “mucho” en este caso? Consideraré que para mí es mucho si la probabilidad de ganar tanto es menos que el 15%. Este 15% es puramente subjetivo. Es mi dinero y mi decisión de cuánto riesgo es demasiado riesgo. Entonces, ¿a partir de cuántas partidas ganadas por el trilero decido que no me fío? Saco mi tableta, abro R y tecleo pbinom(22, 40, p=0.5,lower.tail = F) y me dice que la probabilidad de ganar 22 o más partidas es 0.21. Probamos con 23: pbinom(23, 40, p=0.5, lower.tail = F) y R me calcula una probabilidad de 0.13 (si no quiero ir probando, qbinom(0.15, 40, p=0.5, lower.tail = F) me da directamente el 23 que busco). Por lo tanto, si gana 23 o más de las 40 partidas siguientes considero que esto es demasiado improbable para mi gusto, no me fío y no jugaré. En cambio si gana 22 o menos, echaré unas partidas. Un segundo caso. Estoy diseñando un circuito, construyo un prototipo y quiero hacer una prueba. Según mis cálculos por un cierto punto tiene que pasar una intensidad de 10 mA y quiero comprobar en este punto si todo va bien. Si la intensidad medida es muy diferente a los 10 mA, tanto si es más como si es menos, significa que algo no va bien y que hay que revisar a fondo el diseño y la construción del prototipo. ¿Pero cuánto es “muy diferente” en este caso? Sé que por variaciones de temperatura o voltajes, y también por errores de las medidas, puedo esperar una cierta variabilidad. Lo malo es que no sé cuánta variabilidad puedo esperar de las medidas. Decido tomar 10 medidas y vamos a suponer que la intensidad es realmente 10 mA. Decido que si la probabilidad de tener una media como la que me salga es menor que 0.05 —este valor es también puramente subjetivo— habrá que revisar. Tomo las 10 medidas y me salen 10.4, 9.5, 9.6, 10.9, 11.0, 10.8, 11.2, 10.5, 9.9, 11.5. La media de mi muestra es \\(\\hat{i} = 10.53\\) y el error estándar es se(\\(\\hat{i}\\)) = 0.215. Es una suposición razonable que la distribución de la intensidad es una normal, por lo tanto la media es una distribución t y construyo la variable \\[t_{0} = \\frac{\\hat{i} - 10}{se(\\hat{i})} = \\frac{0.53}{0.215} = 2.46\\] Ahora puedo calcular la probabilidad de tener por pura variabilidad de la muestra una media alejada 0.53 mA por arriba o por abajo de mis 10 mA, o lo que es lo mismo 2.46 errores estándar por arriba o por abajo. Dado que la distribución t es simétrica, puedo calcular un caso (por ejemplo, alejado por arriba) y multiplicar por 2 para tener los dos casos: por arriba y por abajo. Calculo en R 2*pt(t0, 9, lower.tail = F) y me sale 0.0359. Toca desmontar y revisar. 11.1 Experimentos estadísticos para un contraste de hipótesis El contraste de hipótesis es la técnica fundamental de la estadística inferencial. También es la peor usada. No es fácil de entender y a partir de ellas se comenten tantos errores que es muy cuestionada. La American Statistical Association emitió en el 2016 un duro escrito sobre esta cuestión con una serie de guías normativas de uso. Otros especialistas en estadística piden directamente su desaparición. Pero se sigue usando. Mucho. Por lo tanto hay que saber bien qué hace y qué no hace y los abusos y errores más habituales. Si queremos realizar un experimento estadístico que acabe en un contraste de hipótesis debemos hacer lo siguiente: Antes de tomar medidas: Lo primero que tenemos que hacer es enunciar la hipótesis nula, que es la que vamos a poder rechazar. Una hipótesis nula \\(H_{0}\\) siempre es de la forma variable = valor. Ejemplos de hipótesis correctamente formuladas son “proporción de partidas ganadas = 0.5”, “intensidad = 10 mA”. Hay muchas maneras de formular mal la hipótesis. Por ejemplo las del tipo “El Mallorca subirá a primera” ni siquiera permiten asignar un valor numérico. Otro error típico son las hipótesis del tipo “Mi coche es más potente que el tuyo”. Este segundo tipo son fáciles de poner en forma variable = valor: “diferencia de potencias = 0”. Lo segundo es decidir qué es lo que va a hacer “saltar la alarma”. En el primer caso era que el trilero ganara más partidas de las debidas. En el segundo era que la intensidad fuera diferente de la especificada. A esto se le llama la hipótesis alternativa \\(H_{a}\\) y puede tomar 3 formas: variable ≠ valor, variable &gt; valor o variable &lt; valor. En nuestro primer caso era “proporción de partidas ganadas &gt; 0.5”; en el segundo, “intensidad ≠ 10 mA”. La variable y el valor deben ser los mismos que en la hipótesis nula, lo que varía es la relación. Debe notarse que la hipótesis alternativa del mismo experimento puede ser diferente para diferentes investigadores. Por ejemplo, en el caso del trilero, para el jugador la alarma salta si la proporción de partidas ganadas es mayor que 0.5, mientras que para el trilero saltaría si la proporción es menor y para el fabricante de la moneda que usa saltaría si la proporción es distinta. Y ya lo último es uno de los puntos controvertidos y peligrosos: decidir cuántas medidas vamos a tomar y a partir de qué probabilidad vamos a “hacer sonar la alarma”. A esta probabilidad umbral, que es subjetivo, se le llama nivel de significación del contraste de hipótesis. En el primer caso eran 40 partidas y un nivel de significación de 0.15, y en el segundo eran 10 medidas y un nivel de significación de 0.05. Uno de los abusos más graves es decidir el nivel de significación después de tomar los datos. Así siempre puedo escoger un nivel que haga que salga lo que yo quiero: por ejemplo, si me sale una probabilidad de 0.047 y quiero que esté por debajo, digo que el nivel de significación es 0.05; si quiero que esté por encima, digo que es 0.01. Otro abuso similar es decidir después cuántos datos tomo. Si no me sale lo que yo quiero, tomo más datos o quito algunos, hasta que me salga. Esto casi siempre es posible ya que a mayor número de datos el error estándar dismunuye y la probabilidad calculada baja. Tomar las decisiones del nivel de significación y número de datos antes de tomar las medidas ayuda a mejorar la fiabilidad del procedimiento. Y ahora estamos listos para empezar a tomar medidas. Después de tomar medidas: Ya hemos tomado nuestras medidas. Ahora hemos de calcular la probabilidad de tener medidas como estas o “peores” suponiendo que la hipótesis nula es cierta. A esta probabilidad se le llama el p-valor. “Peores” significa “más hacia la alternativa”. En el primer caso, si el trilero gana 26 de 40 partidas, el p-valor es la probabilidad de que gane 26 o más partidas de las 40 suponiendo que la probabilidad de ganar cada una es 0.5. Es una distribución binomial, por lo tanto la función de R pbinom() nos permite hacer el cálculo. Pero calcular binomiales de números moderadamente elevados y sin ordenador es casi imposible y por lo tanto se hace una aproximación, que es matemáticamente válida: se calcula el estadístico \\(t_{0}\\) de la diferencia de la proporción medida \\(\\hat{\\theta}\\) y la proporción supuesta en la hipótesis nula, dividido por el error estándar: \\[t_{0} = \\frac{\\hat{\\theta} - \\theta_{0}}{\\mathrm{se}(\\theta_{0})} \\] Hay un diferencia respecto a lo que cálculabamos para los intervalos de confianza: como centramos la normal en \\(\\theta_{0}\\) calculamos \\(\\mathrm{se}(\\theta_{0})\\) y no \\(\\mathrm{se}(\\hat{\\theta})\\), que es lo que hacíamos con los intervalos de confianza. Es la misma expresión cambiando el valor de \\(\\theta\\): \\[ \\mbox{se}(\\theta_{0}) = \\sqrt{\\frac{\\theta_{0}\\,(1 - \\theta_{0})}{n}}\\] Como con los intervalos de confianza, si \\(\\theta_{0}\\) no está cerca de los extremos y \\(n\\) es suficientemente grande, este estadístico se aproxima a una distribución normal, y podemos calcular la probabilidad con pnorm(). Si \\(H_{a}\\) es “variable ≠ valor” tenemos que calcular la probabilidad de que se aleje por encima o por debajo. Por ejemplo, si en vez de partidas ganadas, queremos saber si saca demasiadas caras o cruces lanzando una moneda y saca 24 caras, tenemos que calcular la probabilidad de sacar 24 caras o más en 40 intentos o sacar 24 cruces o más en 40 intentos. Es la suma de las dos probabilidades por separado. Como la distribución normal es simétrica, basta calcular uno de los casos y multiplicar por dos. Si en vez de proporciones estamos haciendo el experimento sobre medias, usaremos la distribución t para calcular las probabilidades. Supongamos que nuestra hipótesis nula es \\(H_{0}\\): variable = \\(\\mu_{0}\\) y que de nuestras medidas tenemos la media muestral \\(\\hat{\\mu}\\) y el error estándar \\(se(\\hat{\\mu})\\). para poder calcular las probabilidades con la distribución t definimos la variable \\[t_{0} = \\frac{\\hat{\\mu} - \\mu_{0}}{\\mathrm{se}(\\hat{\\mu})}.\\] En este caso \\(\\mathrm{se}(\\hat{\\mu})\\) es exactamente lo mismo que lo que calculábamos en el caso de los intervalos de confianza. Con esto podemos calcular el p-valor con la función de R pt(). Como antes, si \\(H_{a}\\) es variable \\(\\neq \\mu_{0}\\) hemos de multiplicar por 2 para tener en cuenta los casos por encima y por debajo (o las “dos colas” como se dice en jerga). 11.1.1 Procedimiento de cálculo del p-valor. El procedimiento de cálculo del p-valor usando R es el siguiente: Proporciones: La hipótesis nula es \\(H_{0}: V = \\theta_{0}\\). El resultado de las medidas es \\(x\\) éxitos de \\(n\\) intentos. Entonces, \\(\\hat{\\theta} = x/n\\) y definimos \\[t_{0} = \\frac{\\hat{\\theta} - \\theta_{0}}{\\mathrm{se}(\\theta_{0})} \\] En función de la hipótesis alternativa \\(H_{a}\\), calculamos el p-valor: \\(H_{a}\\) Instrucción de R \\(V &lt; \\theta_{0}\\) pnorm(t0) \\(V &gt; \\theta_{0}\\) pnorm(t0, lower.tail = FALSE) \\(V \\neq \\theta_{0}\\) 2 * pnorm(abs(t0), lower.tail = FALSE) Medias: La hipótesis nula es \\(H_{0}: V = \\mu_{0}\\). El resultado de las \\(n\\) medidas es una media muestral \\(\\hat{\\mu}\\) y un error estándar se(\\(\\hat{\\mu}\\)). Entonces definimos una variable \\[t_{0} = \\frac{\\hat{\\mu} - \\mu_{0}}{se(\\hat{\\mu})}\\] y calculamos el p-valor en función de la alternativa: \\(H_{a}\\) Instrucción de R \\(V &lt; \\mu_{0}\\) pt(t0, df = n-1) \\(V &gt; \\mu_{0}\\) pt(t0, df = n-1, lower.tail = FALSE)} \\(V \\neq \\mu_{0}\\) 2 * pt(abs(t0), df = n-1, lower.tail = FALSE) 11.2 Interpretación del p-valor. Recordemos que el p-valor es la probabilidad de, suponiendo que la hipótesis nula es cierta, tener datos como los obtenidos o más hacia la alternativa (“peores”). Cuánto mayor es el p-valor más probable es, suponiendo que \\(H_{0}\\) es cierta, obtener datos como estos o más hacia la alternativa. O en otras palabras, más consistentes son los datos con la idea de una hipótesis nula cierta. Cuanto menor es el p-valor menos probable es obtener datos como estos o peores si la hipótesis nula es cierta. Es decir, menos consistentes son los datos con la idea de que \\(H_{0}\\) es cierta. Quizá hemos tenido mala suerte, pero quizá \\(H_{0}\\) es falsa. El peor abuso del p-valor es el compararlo con el nivel de significación: si el p-valor es mayor que el nivel de significación, declaramos que \\(H_{0}\\) es cierta, si es menor, declaramos que es falsa y que la alternativa es cierta. Esto es un absurdo, como se muestra en el siguiente ejemplo. Queremos comercializar un suplemento alimenticio para reducir el colesterol llamado Sanacol. El departamento de publicidad quiere poder decir que tomándolo durante un mes el colesterol se reduce de media un 10%. Si no llega a este 10%, el éxito comercial es dudoso. Escogemos una muestra de personas de 9 personas con colesterol alto y un nivel de significación de 0.05 (un valor muy habitual). Nuestra hipótesis nula es \\(H_{0}\\): reducción media = 10%. La alternativa es que es mayor que este 10%. Tomamos los niveles de colesterol son de 221, 235, 208, 214, 235, 201, 222, 248 y 218. Después de un mes de tomar Sanacol sus niveles se han reducido a 180, 205, 184, 193, 191, 185, 193, 212 y 204. Hacemos un t-test con el porcentaje de reducción de cada individuo y nos sale un p-valor de 0,053, por encima del nivel de significación de 0,05. Por lo tanto declaramos que la hipótesis nula es cierta y que Sanacol no hace nada significativo en la reducción del colesterol. La campaña de publicidad se nos ha ido al garete. Pero, remirando los análisis con el técnico de laboratorio, vemos que el nivel de colesterol del último era un poquito menor que 204. Quizá incluso 203. Rehacemos el t-test suponiendo que es 203 y, ¡albricias!, el p-valor ha pasado a valer 0,047, por debajo del nivel de significación. Por lo que rechazamos la hipótesis nula, aceptamos la alternativa y Sanacol es una maravilla. Este ejemplo, que parece una parodia, no lo es. No es un caso real, pero hay muchos casos reales en los que se hace exactamente lo que se decribe aquí. Esto es debido a que se toma el nivel de significación, especialmente el valor 0,05, como una especia de “número mágico” que distingue lo bueno de lo malo o lo estadísticamente cierto de lo estadísticamente falso. Si aplicamos un poco de sentido común, resolvemos esta situación. Si el nivel de colesterol de uno de los participantes en el experimento baja un poquito, el p-valor también baja un poquito. Luego es un poquito más difícil que los resultados sean debido a variación natural del muestreo. Antes y después del cambio de 204 a 203 tenemos esencialmente lo mismo. Todo el problema viene de tener el “número mágico” de 0,05. Si nos olvidamos del nivel de significación, desaparecen los problemas. Es un error considerar que el nivel de significación es un número mágico que implica la verdad o falsedad de las hipótesis. Es muy necesario tener un criterio de qué va a suponer “saltar la alarma” antes de tomar los datos. Como hemos dicho, si lo hacemos después es muy fácil deformar los razonamientos para que salga lo que querramos. Pero el nivel de significación es un valor de referencia y no un umbral “duro” que hace ciertas o falsas las hipótesis. Si estamos cerca o por debajo del nivel de significación, es que aquí hay algo que vale la pena estudiar más a fondo. Nada más. Y siempre es el conjunto que se debe mirar, no sólo el p-valor. Aunque el trilero gane 20 veces, o incluso menos, quizá gane todas las apuestas donde hay mucho dinero, y pierda las que hay poco. O hay extrañas rachas de 8 o 9 ganadas (o perdidas) seguidas. Y quizá por mi circuito pasan muy cerca de lo 10 mA especificados, pero algún componente está más caliente de lo normal, o veo fluctuaciones muy raras. Si consideramos el p-valor como un dato más a tener en cuenta, es útil. Si lo consideramos como el único valor importante, el que nos hace decidir en un sentido o en otro, estamos cometiendo un error grave de procedimiento. "],
["anova.html", "Capítulo 12 ANOVA 12.1 Nada es gratis (y los errores se acumulan) 12.2 Punto de partida 12.3 Tutorial de ANOVA en R", " Capítulo 12 ANOVA 12.1 Nada es gratis (y los errores se acumulan) ¿Por qué se elige casi siempre el 95% como el nivel de confianza de los intervalos de confianza? En parte es desconocimiento o vaguería: todo el mundo lo hace así porque todo el mundo lo hace así. Pero “todo el mundo lo hace así” porque es un buen punto de equilibrio. Imaginemos que buscamos la media de anchura del pulgar, por ejemplo para diseñar un pulsador. Tomamos medidas y calculamos que la anchura media, con un nivel de confianza del 60%, es de 3,21 cm a 3,36 cm. Tenemos poca incertidumbre en la medida —poco mas de ± 2,2%— pero nuestra seguridad en estos valores es baja: es muy probable que el valor real sea inferior o superior. Es un intervalo poco útil. Si subimos el nivel de confianza al 99,9% tenemos un intervalo de 2,93 cm a 3.65 cm. Ahora tenemos mucha seguridad, pero la incertidumbre ha crecido mucho —es más que ± 10%— y sigue siendo poco útil para diseñar el pulsador. Y esto es muy típico en ingeniería: lo que ganamos por un lado lo perdemos por otro. La experiencia ha mostrado que un nivel de confianza de alrededor del 95% (3,10 cm a 3,47 cm en nuestro ejemplo) nos da un buen equilibrio entre incertidumbre y precisión. ¿Y qué pasa si para saber una sola cosa de una sola población necesito realizar 10 o 15 intervalos de confianza? Podemos pensar que cada intervalo de confianza es una moneda. Sale “cara” si la media poblacional está en el intervalo y cruz si no. Un nivel de confianza del 95% significa que sale cara el 95% de las veces. Si para nuestra prueba necesitamos 15 intervalos de confianza y el nivel de confianza es del 95%, entonces necesitamos calcular la probabilidad de obtener 15 caras seguidas. Esta probabilidad es \\(0.95^{15} = 0.463\\). Vemos que habremos “acertado” en las 15 medias menos del 50% de las veces. Podemos intentar arreglar esto aumentando el nivel de confianza de manera que la probabilidad de que las 15 medias poblacionales estén en los intervalos sea del 95%. Es decir, queremos una moneda tal que la probabilidad de tener 15 caras seguidas es del 95%. Esto exige que el nivel de confianza de cada intervalo sea del 99.7% (\\(\\sqrt[15]{0.95} = 0.997\\)). Luego para conseguir una seguridad adecuada del conjunto hemos de perder fuertemente en la precisión de cada intervalo. Con los p-valores tenemos un problema similar. Hay dos posibles errores que podemos cometer: mantenernos en la hipótesis nula cuando hubiéramos tenido que cambiarnos a la alternativa o habernos cambiado a la alternativa cuando hubiéramos tenido que permanecer en la nula. Estos errores tienen los muy desafortunados nombres de error de tipo II y error de tipo I respectivamente (nunca me acuerdo cuál es cuál). Intentar reducir la probabilidad de un tipo de error lo único que hace es aumentar la del otro. Y si tenemos que hacer muchos contrastes para una única población tenemos el mismo problema, o aún peor, que con los intervalos de confianza. Uno podría pensar que realizar 15 contrastes de hipótesis con sus 15 intervalos de confianza para una única población no pasa casi nunca. Lo contrario, no es nada inusual. Imaginemos que estamos realizando un estudio sobre nutrición y tenemos 6 dietas (mediterránea, vegetariana, hiper proteica, etc.) y queremos saber su influencia en el nivel de colesterol. Tendríamos que comparar el nivel de colesterol par a par (mediterránea contra vegetariana, mediterránea contra hiper proteica, etc). Tenemos 15 pares, luego hay que realizar 15 contrastes de hipótesis. Para resolver este problema los estadísticos han creado métodos que permiten realizar la comparación conjunta de todos los pares en una única prueba. Cuando lo que tenemos es una variable numérica y una cualitativa, en vez de hacer 15 t-test, realizamos una única prueba llamada ANOVA; cuando tenemos dos variables cualitativas, en vez de realizar 15 prop-test, realizamos una única prueba llamada \\(\\chi^{2}\\) (Ji-cuadrado). En este documento estudiaremos el ANOVA y dejamos el \\(\\chi^{2}\\) para después. 12.2 Punto de partida Sigamos con el ejemplo del nivel de colesterol y las dietas. Tenemos 120 individuos, 20 para cada una de las 6 dietas (variable cualitativa) y el nivel de colesterol de cada individuo (variable cuantitativa). Queremos saber si la dieta influye en el nivel de colesterol. La primera pregunta que nos hacemos es “¿Es el nivel de colesterol el mismo en todas las dietas?”. Si es el mismo, entonces no parece que las dietas en estudio influyan en el nivel de colesterol. Si no es el mismo, nos hace pensar que sí que influyen y que hay unas dietas mejores que otras en este aspecto. Queremos hacer esta comparación de una vez, no entre cada par de dietas. Veamos el razonamiento básico que permite hacerlo. En la figura siguiente tenemos dos conjuntos de datos, llamados Caso 1 y Caso 2. Tenemos 3 grupos diferentes en cada caso. Los puntos negros son los datos individuales, mientras que los diamantes rojos son las medias de cada grupo. Mirando sólo los datos del Caso 1, sin hacer cuentas, llegamos a la conclusión que los tres grupos de datos representados son muy similares y no vemos diferencias entre ellos. Mientras que si miramos a los del Caso 2, claramente vemos que sí que son diferentes. Lo interesante es que las medias de los 3 grupos del Caso 1 son iguales a las medias de los 3 grupos del Caso 2. ¿Entonces, por qué en un caso los consideramos diferentes y en el otro no? La diferencia en la conclusión viene del hecho que la dispersión (varianza o desviación típica) dentro de cada grupo del Caso 1 es claramente mayor a la dispersión de las medias de los grupos, mientras que la dispersión de los datos de cada grupo del Caso 2 es claramente inferior a la dispersión de las medias de los grupos. Esta es la clave que vamos a explotar. Lo que vamos a hacer es crear un estadístico que es la razón entre la varianza dentro de cada grupo y la varianza entre los grupos. A este estadístico lo vamos a llamar \\(F\\). La expresión matemática resultante es: \\[ \\mathrm{SS\\; dentro} = \\sum^{p}_{j = 1}\\sum^{n_{j}}_{i = 1}(X_{ij} - \\bar{X}_{.j})^{2}\\] \\[\\mathrm{SS\\; entre} = \\sum_{j}n_{j}(\\bar{X}_{.j} - \\bar{X})^{2}\\] \\[F = \\frac{\\frac{\\mathrm{SS\\; entre}}{p-1}}{\\frac{\\mathrm{SS \\; dentro}}{n-p}}\\] La sigla SS significa “sum of squares” (suma de cuadrados). El número de niveles es \\(p\\), el número de individuos en cada nivel es \\(n_{j}\\) y \\(n\\) es el número total de individuos. La media total es \\(\\bar{X}\\) y la media en cada nivel es \\(\\bar{X}_{.j}\\)} No es difícil ver que si todas las medias son iguales, el numerador de \\(F\\) es 0, y por lo tanto \\(F = 0\\) y si las medias no son iguales, entonces \\(F &gt; 0\\). Lo bueno es que si los datos dentro de cada nivel siguen una distribución normal, entonces se sabe calcular la probabilidad de que \\(F\\) tome un valor concreto al coger una muestra. Esto nos permite hacer un constraste de hipótesis y calcular un p-valor. La hipótesis nula es H0: \\(F = 0.\\) Este valor \\(F = 0\\) ocurre si todas las medias son iguales. La hipótesis alternativa es Ha: \\(F &gt; 0\\), que ocurre si no todas las medias son iguales. Usando las fórmulas matemáticas mostradas, calculamos \\(\\hat{F}\\), y entonces el p-valor es Prob[\\(X &gt; \\hat{F}\\; |\\; F = 0\\)]. Este método se llama Análisis de la Varianza (Analysis of Variance) y se conoce por su sigla ANOVA. Como puede verse, calcular un ANOVA es tedioso, con muchas sumas de cuadrados y ya nadie lo hace a mano, sino que utiliza las funciones incorporadas en los paquetes estadísticos. R tiene 3 funciones que permite el cálculo del ANOVA, aunque aquí sólo hablaremos de 2. No dan exactamente los mismos resultados, pues realizan funciones un poco diferentes a las vistas aquí (y diferentes entre sí). Además, presentan diferentes funcionalidades. Más adelante hay un tutorial de ANOVA con los detalles del uso, aquí sólo explicaré la estructura básica y las diferencias. Como se deduce del ejemplo, un ANOVA se usa cuando tengo dos variables, una cuantitativa (Q) y otra cualitativa (N). Estas funciones de R trabajan sobre un dataframe en las que hay estas dos variables, y puede haber más. La notación es la misma que la que usábamos para hacer un diagrama de cajas o un stripchart: Q~N. La primera función que tiene R para calcular ANOVA se llama aov(). Esta función exige desviaciones típicas iguales de la variable cuantitativa para cada nivel de la cualitativa. Su ventaja principal es que provee información para poder calcular intervalos de confianza de todas las diferencias. Para calcular estos intervalos de confianza se debe utilizar la función TukeyHSD(). Esta función calcula todos los intervalos “de golpe” y no tiene el problema indicado en la primera sección. La segunda función se llama oneway.test(). Es menos restrictiva que aov() pues permite que las desviaciones típicas no sean iguales. Tiene el parámetro var.equal que permite indicar si las varianzas (y por lo tanto las desviaciones típicas) son iguales o no. En caso de duda, es conveniente decir que no lo son. Dadas estas diferencias, vemos que si sabemos que las varianzas en cada nivel son iguales, podemos usar aov(), lo que nos permitirá calcular los intervalos de confianza con TukeyHSD(). Si no estamos seguros que sean iguales, o sabemos seguro que no son iguales, debemos usar oneway.test() y no podremos calcular los intervalos de confianza con TukeyHSD(). Ambas funciones nos dan un p-valor que se interpreta de la forma habitual. Recordemos que H0 es (informalmente) que las medias son todas iguales y que Ha es (informalmente) que no son todas iguales. El p-valor se calcula suponiendo que se cumple H0 y nos da una indicación de lo “normal” que es la muestra. Digamos que el p-valor nos sale 0,28. Esto quiere decir que, suponiendo que todas las medias son iguales, esta muestra es normal, es decir, que lo que vemos es consistente con el hecho de que todas las medias sean iguales. No tenemos, por tanto, ningún motivo para abandonar H0. Seguimos suponiendo que todas las medias son iguales. En cambio si nos sale un p-valor de 0,00063, entonces una de dos, o las medias son todas iguales y tenemos una muestra que es extraordinariamente poco probable o no se cumple H0 y nos pasamos a Ha. En este caso, lo razonable es pasarse a Ha. Si el p-valor fuera 0.11, entonces esta prueba del ANOVA nos da poca información y no nos permite decantarnos ni por uno ni or otro. El ANOVA solo nos da información sobre la pregunta “¿son todas las medias iguales?”. Si lo son, pues ya está. Pero si no lo son querremos saber qué dieta o diaeas on mejor qeu las otras. Querremos saber si es que hay una que es distinta a las demás; si todas son distintas entre sí; si hay 3 iguales por aquí, dos iguales por allá y una que va por libre o qué. Este análisis no es difícil, pero si que puede ser largo, con diferentes pasos. En el tutorial se muestra como realizarlo. 12.3 Tutorial de ANOVA en R El Análisis de varianza, conocido como ANOVA (ANalysis Of VAriance) es una prueba estadística que nos permite analizar el caso de datos con dos variables, una cuantitativa y otra cualitativa. En particular nos ayuda a determinar si las medias de la variable cuantitativa para cada uno de los factores de la cualitativa son iguales o no. Detalles de por qué se usan los ANOVA, de los cálculos involucrados y del contraste de hipótesis que se realiza están en el documento asociado, titulado ANOVA. En este tutorial nos centraremos en las funciones que tiene R para calcular los ANOVA, cómo se usan y un ejemplo de análisis. No es demasiado simple ni intuitiva la manera en la que se hace este análisis en R. Es más, hay 3 maneras de hacerlo. Dependiendo de los datos, podemos usar una función o hemos de usar otra. Y unas funciones nos dan una información que otras no lo hacen. Veamos el funcionamiento de las 3 funciones y esto nos ayudará a elegir cuál necesitamos en cada caso 12.3.1 El problema El conjunto de datos babies del paquete UsingR contiene datos de salud de 1236 nacimientos. Para este tutorial sólo nos van a interesar 2 variables: el peso del bebé al nacer (la variable cuantitativa) y el hecho de si la madre fumaba o no (la variable cualitativa). La columna wt nos da el peso en onzas del bebé al nacer y la columna smoke nos indica si la madre fuma o no. Tiene 5 niveles: 0 (nunca), 1 (fuma en la actualidad), 2 (fumó hasta el inicio del embarazo), 3 (fumó en el pasado, hace tiempo que no fuma) y 9 (No sabe/No contesta, NS/NC). Podemos usar el dataframe babies directamente, pero para más comodidad vamos a crear un dataframe nuevo con sólo las dos columnas que nos interesan. Para ello usamos la función subset() que nos permite extraer un subconjunto del dataframe. De paso vamos a quitar el nivel 9 (NS/NC) que no añade información y puede añadir ruido: library(&quot;UsingR&quot;) bebes = subset(babies, smoke!= 9, select = c(&quot;wt&quot;,&quot;smoke&quot;)) head(bebes) ## wt smoke ## 1 120 0 ## 2 113 0 ## 3 128 1 ## 4 123 3 ## 5 108 1 ## 6 136 2 attach(bebes) Hemos hecho un attach() (conectar) para no tener que escribir el nombre de la variable cada vez. Siempre conviene echar un vistazo a la forma que tienen los datos. Habría que hacer un estudio completo de estadística descriptiva. Para este tutorial, simplemente vamos a hacer un boxplot: boxplot(wt~smoke) Vemos que no hay unas enormes diferencias, aunque parece que el factor 1 (la madre ha fumado durante el embarazo) puede que tenga un peso un poco inferior. Hagamos el ANOVA para comprobarlo. 12.3.2 El primer método: oneway.test() En cualquiera de los tres métodos, R quiere que los datos estén en un dataframe con pares (valor, factor). Por suerte, en nuestro dataframe bebes ya están así y no hemos de hacer ninguna transformación. La función mas simple para calcular un ANOVA es oneway.test(). Su estructura de llamada es la siguiente: oneway.test(wt~factor(smoke), var.equal = F) ## ## One-way analysis of means (not assuming equal variances) ## ## data: wt and factor(smoke) ## F = 24.505, num df = 3.00, denom df = 266.31, p-value = 4.925e-14 Hemos usado factor(smoke) y no directamente smoke porque los niveles son números (0, 1, 2 y 3) y queremos asegurarnos que R lo considera una variable cualitativa y no una numérica. También, como no sabemos si las varianzas (o desviaciones típicas) son iguales en todos los casos hemos indicado que pueden ser diferentes con el parámetro var.equal. En la salida nos da el estadístico F (con valor 24.5) que describimos más arriba. Y obtenemos el p-valor. Es muy pequeño. Esto quiere decir, que si las medias fueran todas iguales, la probabilidad de obtener datos como estos o con diferencias aún mayores es minúscula. Los datos son poco consitentes con la idea de medias iguales y es más verosímil pensar que la hipótesis nula (todas las medias son iguales) no se cumple y afirmar que al menos una media es diferente a las demás. Sospechamos del caso 1, pero hay que confirmarlo. Una manera de hacerlo es realizar otro ANOVA, pero sin el caso del que sospechamos. Creamos una nueva variable bebessinfum: bebessinfum = bebes[smoke != 1,] Realizamos otro ANOVA: oneway.test(wt~factor(smoke), data = bebessinfum, var.equal = F) ## ## One-way analysis of means (not assuming equal variances) ## ## data: wt and factor(smoke) ## F = 0.35239, num df = 2.00, denom df = 167.91, p-value = 0.7035 &lt;Hemos usado en esta ocasión el parámetro data para indicar el nombre de la variable y no tener que escribirla en cada columna. Vemos que el p-valor es ahora de 0.7035 y por lo tanto hay una alta probabilidad de, si hacemos otro muestreo, obtener datos con medias así de diferentes o aún más diferentes. Los datos son consistentes con la hipótesis nula (las medias son iguales). Parece ser que el caso 1 es el único que tiene media diferente. ¿Pero cuánto? 12.3.3 El segundo método: aov() Si queremos saber más que simplemente el p-valor, si queremos saber si hay diferencia entre las medias y lo grande que puede ser, necesitamos una función que realiza cálculos más complejos que oneway.test(). Esta función es aov(). Esta función exige que varianzas iguales de la variable cuantitativa (el peso en nuestro caso) para cada nivel de la cualitativa (si fuman o no). Simplemente de la gráfica vemos que no parece que haya muchas diferencias. Vamos a comprobarlo. sd(bebes[smoke == 0, ]$wt) ## [1] 17.10966 sd(bebes[smoke == 1, ]$wt) ## [1] 18.09895 sd(bebes[smoke == 2, ]$wt) ## [1] 17.8037 sd(bebes[smoke == 3, ]$wt) ## [1] 18.60828 Están todos entre 17.1 y 18.6. Consideramos que la diferencia no es muy grande y decidimos que sí podemos utilizar aov(). La información que nos interesa la podemos obtener con los intervalos de confianza. Una primera idea es calcular todos los intervalos par a par: 0-1, 0-2, 0-3, 1-2, 1-3, 2-3. Ya explicamos en el documento por qué esto es una mala idea: si para un par de variables tenemos una probabilidad de 0.95 que la media poblacional esté dentro del intervalo, para los 6 pares, la probabilidad de que todas las medias estén dentro de los intervalos es de 0.746 (¿Cómo se calcula?). R tiene una función para calcular los intervalos de confianza de todos los pares de variables de un ANOVA. Esta función se llama TukeyHSD(). Primero hay que hacer el ANOVA con aov() y después pasar a esta función el resultado para que calcule los intervalos de confianza. Hemos de usar obligatoriamente aov() y no puede hacerse el ANOVA con oneway.test(), ya que esta función no calcula todo lo que necesita TukeyHSD(). aovres = aov(wt~factor(smoke), data = bebes) summary(aovres) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(smoke) 3 23638 7879 25.19 8.2e-16 *** ## Residuals 1222 382290 313 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TukeyHSD(aovres) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = wt ~ factor(smoke), data = bebes) ## ## $`factor(smoke)` ## diff lwr upr p adj ## 1-0 -8.668069 -11.511237 -5.824902 0.0000000 ## 2-0 0.306637 -4.752975 5.366249 0.9986503 ## 3-0 1.659320 -3.230154 6.548793 0.8188239 ## 2-1 8.974706 3.868683 14.080730 0.0000398 ## 3-1 10.327389 5.389904 15.264874 0.0000005 ## 3-2 1.352683 -5.119938 7.825304 0.9498367 Noten que en la función no hemos puesto el parámetro var.equal = F ya que el método de cálculo de esta función exige que las varianzas sean iguales. Nótese también que el valor calculado del estádístico F no es idéntico (aunque es bastante parecido). En la salida de TukeyHSD() hemos de notar que dice que el nivel de confianza es del 95% family wise, es decir en conjunto y no para cada intervalo. Esto es, hay una probabilidad de 0.95 que todas las medias estén en los intervalos calculados. Tenemos para cada par de niveles el valor de la diferencia de las medias (diff), los extremos inferior y superior del intervalo de confianza (lwr y upr) y el p-valor resultante del contraste de hipótesis con la hipótesis nula “H0: la diferencia de medias de este par es 0”. Notamos que en el par 1-0 la diferencia es de -8.7 onzas y el intervalo y el p-valor son inconsistentes con la idea de que las medias sean iguales. En el 2-1 la diferencia es de 9.0 onzas y tenemos la misma inconsistencia. Finalmente en el par 3-1 la diferencia es de 10.3 onzas y otra vez es inconsistente con la idea de que las medias sean iguales. En los otros casos las diferencias son de menos de 2 onzas y los p-valores son muy altos por lo que no podemos rechazar que las medias sean diferentes. Si hay una diferencia entre las medias, es demasiado pequeña para poder asegurar con estos datos que las medias sean distintas. Los números nos dan una información detallada, pero es más fácil obtener una idea global con un gráfico. Por suertes es muy fácil dibujar estos intervalos de confianza: plot(TukeyHSD(aovres)) La raya vertical nos indica dónde está el 0 y vemos que los intervalos de confianza de diferencias con el nivel 1 no pasa por el 0 mientras que todos los demás sí lo hacen. Esto nos muestra gráficamente lo que ya habíamos observado numéricamente. 12.3.4 El tercer método Hemos visto que las dos funciones estudiadas, oneway.test() y aov() no hacen exactamente lo mismo. Si queremos especificar que las varianzas pueden no ser iguales debemos usar oneway.test() pero si queremos usar TukeyHSD() para calcular los intervalos de confianza, hemos de usar la función aov() y sólo lo podemos hacer si las varianzas son suficientemente parecidas. El tercer método es usar la combinación de las funciones lm() y anova(): lmres = lm(wt~factor(smoke)) anova(lmres) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(smoke) 3 23638 7879.4 25.187 8.196e-16 *** ## Residuals 1222 382290 312.8 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 detach(bebes) (Noten que hemos hecho un detach(bebes). No vamos a usar más este dataframe por lo tanto conviene desconectarlo. Si nos olvidamos de hacer los detach() pronto nos veremos en un lío). Los cálculos son los mismos que realiza la función aov() pero no podemos usar TukeyHSD() sobre los resultados. Este es un método que se usa si nos interesa hacer un lm() y además hacer un ANOVA. Para sólo hacer el ANOVA, no vale la pena. 12.3.5 ¿Y si los datos no están como los quiere R? Hemos visto 3 maneras de calcular un ANOVA, y hemos visto que para los tres métodos R quiere que los datos estén como dos columnas en un data frame: en una columna están los valores cuantitativos (el peso de los bebés en nuestro ejemplo) y en la otra columna los factores (características de consumo de tabaco de la madre). Pero a veces los datos no están así. Un caso es el conjunto de datos ewr del paquete UsingR. Este conjunto contiene los tiempos de pista antes de despegar o después de aterrizar de los vuelos en el aeropuerto de Newark (uno de los aeropuertos de Nueva York). Veamos cómo están organizados los datos: head(ewr) ## Year Month AA CO DL HP NW TW UA US inorout ## 1 2000 Nov 8.6 8.3 8.6 10.4 8.1 9.1 8.4 7.6 in ## 2 2000 Oct 8.5 8.0 8.4 11.2 8.2 8.5 8.5 7.8 in ## 3 2000 Sep 8.1 8.5 8.4 10.2 8.3 8.6 8.2 7.6 in ## 4 2000 Aug 8.9 9.1 9.2 14.5 9.0 10.3 9.2 8.7 in ## 5 2000 Jul 8.3 8.9 8.2 11.5 8.8 9.1 9.2 8.2 in ## 6 2000 Jun 8.8 9.0 8.8 14.9 8.4 10.8 8.9 8.3 in Cada fila nos da el tiempo medio en pista para un mes y año determinados para 8 compañías aéreas. La última columna nos dice si es tiempo de pista de vuelos que han llegado (in) o han partido (out). Nos interesa hacer un ANOVA para saber si algunas compañías tienen que esperar más en pista antes de lagar a la terminal que otras. Es decir, si el tiempo de pista depende de la compañía aérea. Los datos no están en el formato que necesitamos para hacer el ANOVA. Escojamos sólo los vuelos que aterrizan y eliminamos las columnas de año y més, que no nos interesan: ewrin = subset(ewr[ewr$inorout == &quot;in&quot;,], select = 3:10) head(ewrin) ## AA CO DL HP NW TW UA US ## 1 8.6 8.3 8.6 10.4 8.1 9.1 8.4 7.6 ## 2 8.5 8.0 8.4 11.2 8.2 8.5 8.5 7.8 ## 3 8.1 8.5 8.4 10.2 8.3 8.6 8.2 7.6 ## 4 8.9 9.1 9.2 14.5 9.0 10.3 9.2 8.7 ## 5 8.3 8.9 8.2 11.5 8.8 9.1 9.2 8.2 ## 6 8.8 9.0 8.8 14.9 8.4 10.8 8.9 8.3 Podríamos crear el dataframe “a mano” y no sería difícil: creamos un vector son los tiempos de la compañía AA (tAA = ewrin$AA), creamos otro vector con el factor (fAA = rep(&quot;AA&quot;, length(tAA))), repetimos lo mismo para las demás compañías y después concatenamos los vectores y creamos el dataframe. Pero R nos da una función que nos hace eso. Se llama stack(): ewrinst = stack(ewrin) names(ewrinst) = c(&quot;tiempo&quot;, &quot;compAer&quot;) Ya de paso hemos dado un nombre adecuado a las dos columnas. Si hacemos un ANOVA obtenemos: oneway.test(tiempo~compAer, data = ewrinst, var.equal = F) ## ## One-way analysis of means (not assuming equal variances) ## ## data: tiempo and compAer ## F = 16.471, num df = 7.000, denom df = 74.629, p-value = 6.262e-13 Y vemos que tenemos un p-valor de prácticamente 0. Es decir, si las medias fueran todas iguales, tenemos una probabilidad insignificante de obtener datos así o con medias aún más distintas. Parece mucho más probable que al menos una compañía llega en menos tiempo a la terminal que las demás. Saber cuál (o cuáles) son y cuánta es la diferencia se consigue repitiendo para estos datos lo que hemos hecho para los bebés. Adelante. "],
["la-prueba-de-ji-cuadrado.html", "Capítulo 13 La prueba de Ji-Cuadrado 13.1 Prueba de ji-cuadrado de bondad de ajuste 13.2 Prueba \\(\\chi^2\\) de bondad de ajuste con R 13.3 La prueba \\(\\chi^2\\) de homogeneidad 13.4 La prueba \\(\\chi^{2}\\) de independencia 13.5 Resumen", " Capítulo 13 La prueba de Ji-Cuadrado Cuando estudiamos estadística descriptiva, vimos que los datos a realizar y las gráicas a dibujar dependían del tipo de datos. Si teníamos una variable numérica, podíamos calcular medias, caurtiles, etc. y realizar histogramas, daigramas de cajas. Si era una cualitativa, podíamos dibujar un diagrama de barras, si eran dos cualitativas, una tabla de contingencia y diagramas de barras agrupados, etc. Y lo mismo pasa con los contrastes de hipótesis. Tenemos diferentes tipos de pruebas en función de las variables: si tenemos una variable cualitativa con dos niveles, usamos un prop.test; si tenemos una varaible numérica, usamos un t-test; Si tenemos dos variables, una de ellas numéricaa, y la otra cualitativa, un ANOVA. La siguiente prueba que vamos a estudiar es la de \\(\\chi^2\\), pronunciado “ji-cuadrado” que nos sirve si tenemos una variable cualitativa con más de dos niveles, o dos variables cualitativas. Uno nota lingüística: \\(\\chi\\) es una letra griega que en Español se llama “ji” y en Catalán, “ki”. En Inglés se escribe “chi” y se pronuncia “kai”. Desgraciadamente lo habitual es hacer un híbrido y escribirlo en ingles y pronunciarlo a la española: “chi cuadrado”. La pronunciación correcta es “ji-cuadrado” en Español, “ki-quadrat” en Catalán y “kai-squared” en Inglés. 13.1 Prueba de ji-cuadrado de bondad de ajuste En una distribución binomial sólo hay dos posibles resultados que llamamos éxito'' yfracaso’’. Esto corresponde a una variable cualitativa con sólo dos niveles y mediante un prop-test podemos establecer si la proporción poblacional sigue o no algún valor predicho, por ejemplo, si al lanzar una moneda obtenemos cara la mitad de las veces. Pero muchas veces tenemos variables cualitativas con más de dos niveles y queremos saber si la proporción de cada nivel se ajusta a lo que debería. Es el caso del lanzamiento de un dado, con 6 posibles resultados. Una posibilidad es hacer un prop-test por cada nivel: ¿ha salido el “1” 1/6 de las veces? ¿ha salido el “2” 1/6 de las veces?… Pero como vimos al estudiar el ANOVA, hacer muchas pruebas, 6 prop-test en este caso, nos crea un problema de equilibrio entre la confianza de nuestro resultado y la precisión obtenida. Como en aquel caso, lo que nos interesa es tener una única prueba que nos haga todas las comparaciones de golpe. Es decir, una única prueba que nos determine si el dado está cargado o no. Esta es la prueba de \\(\\chi^2\\) de bondad de ajuste. Si tiramos una moneda sólo hay dos posibilidades y el uso del prop-test es perfectamente adecuado. Pero si tiramos un dado tenemos 6 probabilidades. Si quisiéramos usar los prop-test tendríamos que hacer 6 y ver si la probabilidad de que salga un “1” es 1/6 o no; la probabilidad de que salga un “2” es 1/6 o no, etc. Supongamos que tiramos un dado 180 veces con los siguientes resultados: 1 2 3 4 5 6 33 38 25 24 27 33 Sabemos que si el dado es “bueno” tocaría salir cada número 30 veces. Entendemos que es normal que no salga exactamente 30 veces, pero esos 38 doses nos preocupan un poco. ¿Cómo podríamos medir lo diferente que es la salida que hemos obtenido (en conjunto) con la salida teórica de un dado? Pensando un poco es fácil pensar en la siguiente solución: miramos la diferencia entre cada salida y lo que debería haber salido y lo sumamos: \\[3 + 8 + 5 + 6 + 3 + 3 = 28.\\] En otras palabras, hacemos \\[\\sum |x_{o} - x_{t}|,\\] siendo \\(x_{o}\\) el número de veces observado (lo que nos ha salido) y \\(x_{t}\\) el número de veces teórico que nos predice la teoría de la probabilidad. Este método tiene dos problemas. Uno es técnico: el valor absoluto no es derivable en el 0 y es además una función complicada de usar. El otro es fundamental: cuantas más tiradas hagamos más grande nos saldrá la diferencia. Una diferencia de 5 puede ser malísimo si hemos tirado el dado 10 veces pero buenísimo si lo hemos tirado 100. Hemos de meter el número de tiradas que hemos hecho de alguna manera. Para eliminar el valor absoluto usamos la técnica habitual de sustituirlo por la diferencia al cuadrado. Y para meter el número de tiradas, dividimos estas diferencias por el número de veces teórico que tocaría salir. Entonces nos queda \\[\\chi^{2}_{0} = \\sum \\frac{(x_{0} - x_{t})^{2}}{x_{t}}.\\] En nuestro ejemplo nos queda \\[\\chi^{2}_{0} = \\frac{(33 - 30)^{2}}{30} + \\frac{(38 - 30)^{2}}{30} + \\frac{(25 - 30)^{2}}{30} + \\frac{(24 - 30)^{2}}{30} + \\frac{(27 - 30)^{2}}{30} + \\frac{(33 - 30)^{2}}{30} = 5.067.\\] Este método tiene dos problemas. Uno es técnico: el valor absoluto no es derivable en el 0 y es además una función complicada de usar. El otro es fundamental: cuántas más tiradas hagamos más grande nos saldrá la diferencia. Una diferencia de 5 puede ser malísimo si hemos tirado el dado 10 veces pero buenísimo si lo hemos tirado 100. Hemos de meter de alguna manera en nuestra fórmula el número de tiradas que hemos hecho. Para eliminar el valor absoluto usamos la técnica habitual de sustituirlo por la diferencia al cuadrado. Y para meter el número de tiradas, dividimos estas diferencias por el número de veces teórico que tocaría salir. Entonces nos queda \\[\\chi^{2}_{0} = \\sum \\frac{(x_{0} - x_{t})^{2}}{x_{t}}.\\] En nuestro ejemplo nos queda \\[\\chi^{2}_{0} = \\frac{(33 - 30)^{2}}{30} + \\frac{(38 - 30)^{2}}{30} + \\frac{(25 - 30)^{2}}{30} + \\frac{(24 - 30)^{2}}{30} + \\frac{(27 - 30)^{2}}{30} + \\frac{(33 - 30)^{2}}{30} = 5.067.\\] Pues ya tenemos una medida: \\(\\chi^{2}_{0} = 5.067\\) (en esta prueba el valor muestral se escribe \\(\\chi^{2}_{0}\\) y no \\(\\hat{\\chi}^{2}\\). El motivo es probablemente tipográfico: el superíndice y el curcunflejo se molestan). ¿Pero eso es mucho o poco? Por suerte la variable aleatoria que hemos calculado, \\(\\chi^{2}_{0}\\), tiene una distribución conocida y podemos saber lo probable que es tener un valor como \\(5.067\\) o peor. ¿Qué queremos decir con “peor”? Pues peor quiere decir más alejado de la distribución teórica, y por lo tanto un valor \\(\\chi^{2}_{0}\\) aún mayor que el \\(5.067\\) de nuestra muestra. La distribución se llama, como podríamos suponer, \\(\\chi^{2}\\). Esta distribución tiene un parámetro llamado grados de libertad. En este caso tenemos 5 grados de libertad: sólo hay 5 valores independientes ya que si sabemos qué ha salido para 5 cualesquiera de los valores del dado podemos calcular cuánto ha salido en el otro. Naturalmente, R tiene funciones para calcular probabilidades según esta distribución. Usando la función calculamos la probabilidad de que nos haya salido un valor \\(\\chi^{2}_{0} = 5.067\\) o mayor: . La probabilidad calculada es \\(0.408\\), casi un 41%. Pongamos lo que hemos hecho en la forma de un contraste de hipótesis. La hipótesis nula es que el dado sigue una una distribución determinada (en este caso 1/6 en todos los casos); la hipótesis alternativa es que no la sigue; calculamos como estadístico \\(\\chi^{2}_{0}\\); y obtenemos un p-valor: la probabilidad de que el valor del estadístico sea como el calculado o peor suponiendo cierta la hipótesis nula. Escribamos este contraste de hipótesis de forma esquemática: La hipótesis nula es H0: \\(\\chi^{2} = 0.\\) Este valor ocurre su la variable sigue la distribución de probabilidad fijada. La hipótesis alternativa es Ha:\\(\\chi^{2} &gt; 0.\\) Esto ocurre cuando la variable no sigue la distribución de probabilidad fijada. Calculamos el valor muestral (es costumbre usar \\(\\chi^{2}_{0}\\) y no \\(\\hat{\\chi}^2\\)) \\[\\chi^{2}_{0} = \\sum \\frac{(\\mbox{observado} - \\mbox{teórico})^{2}}{\\mbox{teórico}}.\\] El p-valor es Prob[\\(\\chi^{2} &gt; \\chi^{2}_{0} \\; |\\) H0]. Esto lo podemos calcular en R con la instrucción pchisq($\\chi^{2}_{0}$, df = n-1, lower.tail = FALSE) Después, con el p-valor, las gráficas, información adicional, nuestra experiencia y todo lo que podamos, tomamos la decisión que corresponda. En este caso, si las probabilidades son iguales (el dado es justo), la probabilidad de obtener valores como los que vemos o más alejados de “todos iguales a 1/6” es del 41%. Luego no tenemos evidencia para creer que no se cumple la hipótesis nula, es decir, no tenemos evidencia para creer que el dado está cargado. Esta prueba recibe el nombre de prueba \\(\\chi^2\\) de bondad de ajuste: nos da una indicación de lo bien (o mal) que se ajusta la variable aleatoria a una distribución de probabilidad dada. Veamos otro ejemplo. Antes de una elecciones generales un periódico hizo una encuesta a 2400 personas y obtuvo los siguientes resultados: PSOE PP Podemos Ciudadanos IU Encuesta 809 655 382 226 180 En las elecciones se obtuvieron las siguientes proporciones: PSOE PP Podemos Ciudadanos IU Elecciones 0,3543 0,2676 0,1484 0,0928 0,0689 ¿Podemos considerar que la encuesta hizo una buena predicción del resultado de las elecciones? Si somos concienzudos y hacemos, como debemos, unas comprobaciones previas, notaremos dos problemas: se encuestaron a 2400 personas pero aqui sólo aparecen 2252, y en el resultado de las elecciones las proporciones no suman 1.0 sino 0.932. El motivo es claro: sólo tenemos los resultados de los 5 partidos con más votos. Hay dos formas de resolver este problema. Uno es eliminar las opciones minoritarias: aunque se haya entrevistado a 2400 personas, sólo consideramos las 2252 respuestas de los 5 partidos minoritarios. Esto implica también reescalar los resultados de las elecciones para que sumen 1.000. Para ello dividimos lo que tenemos por la suma. En este caso dividimos entre 0.932: el PSOE tendría una proporción ajustada de 0.3543/0.932 = 0.3802; el PP de 0.2676/0.932 = 0.2871, etc. Así las proporciones suman 1. La otra forma de resolver el problema es agrupar todas las opciones minoritarias en una sola, que podemos llamar “Otros” y le asignamos las \\(2400-2252 = 148\\) encuestas y la proporción de votos que nos falta: \\(1.0 - 0.932 = 0.068\\). Cuál de las dos soluciones escogemos dependerá de cada caso. Vamos a usar la primera opción. Los resultados electorales reescalados son: PSOE PP Podemos Ciudadanos IU Elecciones 0,3802 0,2871 0,1592 0,0996 0,0739 Calculemos según las elecciones cuál debería haber sido la respuesta “ideal” a la encuesta: Encuesta a 2252 personas: PSOE PP Podemos Ciudadanos IU Encuesta 809 655 382 226 180 Ideal 856.1 646.6 358.6 224.2 166.5 No hay ningún problema que los valores teóricos tengan decimales. Son eso, valores teóricos y no personas. Ahora podemos calcular el estadístico \\(\\chi^{2}_{0}\\): \\[\\begin{eqnarray*} \\chi^{2}_{0} &amp; = &amp; \\frac{(809 - 856.10)^{2}}{856.10} + \\frac{(655-646.60)^{2}}{646.60} + \\frac{(382-358.58)^{2}}{358.58} + \\\\ &amp; &amp; + \\frac{(226-224.23)^{2}}{224.23} + \\frac{(180-166.48)^{2}}{166.48}\\\\ &amp; = &amp; 5.34. \\end{eqnarray*}\\] Ahora calculamos el p-valor con la ayuda de R: pchisq(5.34, 4, lower.tail = FALSE). Obtenemos esta probabilidad es \\(0.254\\), un 25%. Interpretemos: Si los votos en el momento de la encuesta se distribuyen como indica el resultado de las elecciones hay un 25% de probabilidades de que, por variabilidad del muestreo, en la encuesta obtengamos datos como estos o peores (más separados de lo que pasó en las elecciones). Otra vez no tenemos evidencia sufieciente para pensar que lo obtenido en la encuesta sea diferente de lo que se obtuvo en las elecciones. Podemos considerar que la encuesta hizo una predicción adecuada de los resultados electorales. 13.2 Prueba \\(\\chi^2\\) de bondad de ajuste con R Hemos visto como calcular el estadístico \\(\\chi^{2}_{0}\\) y el p-valor con pchisq(). Pero, como podíamos suponer, R tiene una función que calcula la prueba \\(\\chi^2\\) de bondad de ajuste directamente: chisq.test(). Para el caso de bondad de ajuste, la función tiene 3 parámetros: pchisq.test(x, p = rep(1/length(x), length(x)), rescale.p = FALSE). El primer parámetro, x, es el vector de valores obtenidos en nuestra observación o experimento. El segundo parámetro, p, es el vector de probabilidades a la que suponemos se ajusta x. Debe tener la misma longitud que x y por defecto toma el valor de que todas las probabilidades sean iguales. El tercer parámetro, rescale.p, es para el caso que hayamos eliminado algunos casos minoritario y queremos que reescale el vector de probabilidades para que sume 1. Si mantenemos el valor por defecto (no se reescala) y el vector de probabilidades no suma 1, nos dará un error. Al usar esta función, la hipótesis nula es que el vector x sigue la distribucion de probabilidades de p y la alternativa es que no la sigue. La función nos calcula el estadístico \\(\\chi^{2}_{0}\\) y el p-valor. Veamos el uso de esta función con nuestros dos ejemplos. El dado. Es el caso más simple. Debemos introducir lo que hemos obtenido lanzando el dado y como nuestra distribución de probabilidades es que todas sean iguales y este es el valor por defecto, no hay que escribirlo. Entonces queda: chisq.test(c(33, 38, 25, 24, 27, 33)) ## ## Chi-squared test for given probabilities ## ## data: c(33, 38, 25, 24, 27, 33) ## X-squared = 5.0667, df = 5, p-value = 0.4078 Nos sale exactamente lo mismo: \\(\\chi^{2}_{0}\\) = 5.0667 y un p-valor de 0.4078. La encuesta. Este caso es un poco más complejo y tiene más posibilidades que vamos a explorar. Empezamos por crear las variables: encuesta = c(809, 655, 382, 226, 180) elecciones = c(0.3543, 0.2676, 0.1484, 0.0928, 0.0689) Pero si hacemos la prueba, chisq.test(encuesta, p = elecciones) obtenemos un mensaje de error: Error in chisq.test(encuesta, p = elecciones) : probabilities must sum to 1. R nos ha pillado que las probabilidades no suman 1. Si reescalamos se arregla todo: chisq.test(encuesta, p = elecciones, rescale.p = TRUE) ## ## Chi-squared test for given probabilities ## ## data: encuesta ## X-squared = 5.341, df = 4, p-value = 0.2541 y obtenemos lo mismo que cuando lo hicimos a mano. ¿Y si hubiéramos añadido el apartado de “otros” qué hbiera salido? Es fácil hacerlo. Creamos dos nuevas variables añadiendo lo que nos falta y hacemos la prueba: encuestaCom = c(encuesta,148) eleccionesCom = c(elecciones,0.068) chisq.test(encuestaCom,p = eleccionesCom) ## ## Chi-squared test for given probabilities ## ## data: encuestaCom ## X-squared = 6.8963, df = 5, p-value = 0.2285 El p-valor baja un poquito, pero esencialmente no cambia. 13.2.1 Problematicidad: el aviso de chisq.test() Supongamos que el objetivo de resultados académicos de esta asignatura fuera tener un 15% de sobresalientes, un 30% de notables, un 40% de aprobados, un 10% de suspensos y un 5% de no presentados. Al final de un curso con 70 matriculados obtenemos 12 sobresalientes, 18 notables, 26 aprobados, 10 suspensos y 4 no presentados. Queremos saber si podemos considerar que hemos cumplido los objetivos. Hacemos un \\(\\chi^2\\) de bondad de ajuste con R: obj = c(0.15,0.30,0.40,0.10,0.05) resAc = c(12,18,26,10,4) chisq.test(resAc, p = obj) ## Warning in chisq.test(resAc, p = obj): Chi-squared approximation may be ## incorrect ## ## Chi-squared test for given probabilities ## ## data: resAc ## X-squared = 2.1429, df = 4, p-value = 0.7095 El p-valor es muy alto, lo que nos puede llevar a pensar que el ajuste es adecuado, pero obtenemos un aviso de que los resultados pueden ser incorrectos. ¿Qué ha pasado? Lo que ha pasado es que nuestros datos son demasiado problemáticos. Veamos por qué. Al calcular \\(\\chi^{2}_{0}\\) cada sumando es una fracción de (obtenido – teórico)\\(^{2}\\)/teórico. Si el valor teórico en algún caso es muy pequeño esa fraccción será muy grande y dominará sobre las demás. Y además cualquier pequeño cambio para este nivel minoritario representará un cambio muy grande en el conjunto. En nuestro ejemplo, un no presentado más o menos puede cambiarlo todo. Por eso los datos son problemáticos. Es importante darse cuenta lo que convierte los datos en problemáticos no son los resultados obtenidos, sino los valores teóricos que deberíamos obtener. En este caso no nos molesta los 4 no presentados obtenidos, sino que teóricamente deberíamos tener 3,5 (un 5% de 70). En general, el aviso aparece si el número teórico que deberíamos obtener para uno o más niveles es menor que 5. La manera más adecuada de resolver el problema es de previsión: un breve estudio preliminar nos puede indicar las proporciones aproximadas que vamos a obtener y entonces diseñamos el experimento de manera que la muestra sea de tamaño suficiente. Pero a veces calculamos mal y tras conseguir la muestra tenemos algún nivel con un valor teórico demasiado bajo. O no podemos elegir el tamaño de la muestra. Por ejemplo en este caso tenemos los alumnos que tenemos y no podemos conseguir más. Ya vimos las soluciones posibles: eliminar los no presentados y reescalar las probabilidades o unir niveles. En este caso tiene sentido unir los no presentados con los suspensos. Lo hacemos así: obj2 = c(0.15,0.30,0.40,0.15) resAc2 = c(12,18,26,14) chisq.test(resAc2, p = obj2) ## ## Chi-squared test for given probabilities ## ## data: resAc2 ## X-squared = 1.9524, df = 3, p-value = 0.5823 El aviso ha desaparecido. Tenemos un p-valor de 0,58, lo que nos indica que no hay evidencia para pensar que no se hayan cumplido los objetivos. Ya hemos visto que la prueba de \\(\\chi^2\\) de bondad de ajuste es una extensión del prop-test si tenemos una variable cualitativa con más de dos niveles. Vamos a extender ahora al caso de tener dos variables cualitativas. En este caso tenemos dos pruebas de \\(\\chi^2\\): la de homogeneidad y la de independencia, que como veremos, es en el fondo la misma prueba. 13.3 La prueba \\(\\chi^2\\) de homogeneidad Cuando empezaron a utilizarse los cinturones de seguridad en los coches había dudas de su efectividad. Incluso había algunos que defendían que eran perjudiciales y era más seguro ir sin cinturón. Para saber si hay algo de cierto en estas dudas, se recogieron datos de accidentes en los que estuvieron involucradas 86 769 personas. De estas 13 861 llevaban cinturón y en 72 908, no. Se clasificaron los daños recibidos por cada persona involucrada en “nada” (sin daños), “leve”, “medio” y “grave”. Los datos, en forma tabular, son los siguientes: nada leve medio grave Total con cinturón 12 813 647 359 42 13 861 sin cinturón 65 963 4000 2642 303 72 908 Total 78 776 4647 3001 345 86 769 Queremos saber si los que llevaban cinturón salieron mejor parados que los que no. Empecemos por mostrar los datos gráficamente. En la figura siguiente representemos los porcentajes de personas con y sin cinturon para cada una de los niveles de gravedad de los daños. No parece que haya mucha diferencia, aunque vemos en la tabla que la diferencia mayor es entre los “grave” y esta diferencia apenas se ve en el gráfico. Queremos aplicar la misma idea que la prueba \\(\\chi^2\\) de bondad de ajuste: sumar las diferencias al cuadrado de los valores observados con los teóricos. ¿Pero cuáles son los valores teóricos? No tenemos una distribución de probabilidad de la que partir. Vamos a suponer que la distribución de daños entre los que llevaban cinturón es la misma que entre los que no la llevaban. No sé cuál es esa distribución, pero supongamos que es la misma en ambos casos. ¿Cuántos casos debería haber en cada una de las 8 celdas de la tabla? Queremos una tabla con los mismo valores que tenemos en los totales de filas y columnas pero que tengan en ambas filas la misma distribución. Nótese que no hay ninguna diferencia a priori entre las dos variables, por lo tanto podríamos buscar que tuvieran las mismas distribuciones en las columnas. Los resultados serían idénticos. Fijémonos en la primera columna. Queremos que haya un total de 78 776 y que su proporción sea de 13 861 a 72 908. No es difícil ver que queremos \\[\\frac{78~776}{13~861 + 72~908}\\times 13~861 = 12~584,15\\] en la fila superior y \\[\\frac{78~776}{13~861 + 72~908}\\times 72~908 = 66~191,85\\] en la fila inferior. Repetimos para todas las columnas y obtenemos la tabla de valores teóricos siguiente: nada leve medio grave Total con cinturón 12 584,15 742,34 479,40 55,11 13 861 sin cinturón 66 191,85 3904,66 2521,60 289,89 72 908 Total 78 776 4647 3001 345 86 769 Ahora podemos calcular el estadístico \\(\\chi_{0}^{2}\\) igual que lo hacíamos en el caso de bondad de ajuste: \\[\\chi_{0}^{2} = \\frac{(12~813 - 12~584,15)^{2}}{12~584,15} + \\frac{(647-742,34)^{2}}{742,34} + \\cdots + \\frac{(303-289,89)^{2}}{289,89} = 59,22\\] El número de grados de libertad es el número de filas menos uno por el número de columnas menos uno: \\((4-1)(2-1) = 3\\): si nos dan los totales y el valor de 3 de las celdas, podemos reconstruir la tabla entera. Ahora podemos calcular la probabilidad de, si las distribuciones fueran iguales, obtener un valor de \\(\\chi_{0}^{2}\\) como este o aún mayor: pchisq(59.224, 3, lower.tail = FALSE).La probabilidad es de \\(8,6\\times 10^{-13}\\), es decir, minúscula. Lo más probable es que las distribuciones sean diferentes entre los que lleven cinturón y los que no. Es decir, que a la hora de sufrir daños en un accidente no es lo mismo llevar cinturón que no. La prueba de \\(\\chi^2\\) no nos dice cuál es “mejor”, sólo que son distintos. Mirando los datos y las gráficas hemos de establecer qué diferencias hay y lo importantes que son. En este caso vemos que los que llevan cinturón tienen una mayor probabilidad de no sufrir ningún daño, una pequeña menor probabilidad de tener daños leves o medios y una probabilidad bastante menor de sufrir daños graves. Vemos que hay una clara correlación entre llevar cinturón y la gravedad de las lesiones en un accidente. Por medios no estadísticos, podemos establecer que llevar cinturón causa una disminución de las lesiones, sobre todo de las graves, en caso de accidente. 13.3.1 Definición formal Generalicemos lo que hemos hecho en este ejemplo. Tenemos dos variables, que llamaremos A y B, ambas cualitativas. La variable A tiene niveles \\(a_{1}, \\dots, a_{i}, \\dots, a_{n}\\) y la variable B tiene niveles \\(b_{1}, \\dots, b_{j}, \\dots, b_{m}\\). Los valores observados \\(o_{ij}\\) los tenemos en la tabla de contingencias de frecuencias absolutas es: \\[ \\begin{array}{c|ccccc|c} &amp; b_{1} &amp; … &amp; b_{j} &amp; … &amp; b_{m} &amp; Totales\\\\\\hline a_{1} &amp; o_{11} &amp; … &amp;o_{1j} &amp; … &amp; o_{1m} &amp; T_{a1} \\\\ … &amp; … &amp; … &amp; … &amp; … &amp; … &amp; … \\\\ a_{i} &amp; o_{i1} &amp; … &amp;o_{ij} &amp; … &amp; o_{im} &amp; T_{ai} \\\\ … &amp; … &amp; … &amp; … &amp; … &amp; … &amp; … \\\\ a_{n} &amp; o_{n1} &amp; … &amp;o_{nj} &amp; … &amp; o_{nm} &amp; T_{an} \\\\\\hline Totales &amp; T_{b1} &amp; … &amp; T_{bj} &amp; … &amp; T_{bm} &amp; T \\end{array}\\] Los totales de fila \\(T_{ai} = o_{i1} + \\cdots + o_{ij} + \\cdots + o_{im}\\) son el total de individuos que hay en cada nivel de la variable A y análogamente con los totales de columnas \\(T_{bj}\\). Naturalmente, \\(T\\) es el total de individuos de la tabla. Para calcular los valores teóricos \\(t_{ij}\\) seguimos lo hecho en el ejemplo. Vemos entonces que son \\[t_{ij} = \\frac{T_{bj}}{T} \\cdot T_{ai} = \\frac{T_{ai}\\cdot T_{bj}}{T}\\] Este cálculo es simétrico en filas y columnas, es decir, si trasponemos la tabla y convertimos las filas en columnas y viceversa, obtenemos los mismos valores teóricos, como debe ser. Con los valores observados y teóricos, el valor de \\(\\chi_{0}^{2}\\) es \\[\\chi_{0}^{2} = \\sum_{i,j} \\frac{(o_{ij} - t_{ij})^{2}}{t_{ij}}\\] Y con este valor de \\(\\chi_{0}^{2}\\) podemos calcular el p-valor usando la distribución \\(\\chi^{2}\\) con \\((n-1)(m-1)\\) grados de libertad. 13.3.2 Prueba \\(\\chi^2\\) como contraste de hipótesis Reescribamos lo visto de manera formal. Tenemos dos variables cualitativas, en el ejemplo, una variable es el cinturón, con dos niveles: “con” y “sin”; la otra variable es el nivel de lesiones tras el accidente, con cuatro niveles “nada”, “leve”, “medio” y “grave”. La hipótesis nula es H0: \\(\\chi_{0}^{2} = 0\\) que sucede si una variable sigue la misma distribución con respecto a los niveles de la otra variable (es homogenea). La hipótesis alternativa es Ha: \\(\\chi_{0}^{2} &gt; 0\\), que sucede cuando no siguen la misma distribución.. El estadístico es \\(\\chi_{0}^{2}\\), el sumatorio de (observado – teórico)\\(^{2}\\)/teórico. Los valores teóricos se calculan fácilmente a partir de los observados. La distribución es una \\(\\chi^2\\) y podemos calcular el p-valor: la probabilidad, suponiendo cierta la hipótesis nula, de obtener un valor de \\(\\chi_{0}^{2}\\) como el obtenido o mayor. 13.3.3 Prueba \\(\\chi^2\\) de homogeneidad con R Hemos visto como calcular el estadístico \\(\\chi^{2}_{0}\\) y el p-valor con pchisq(). También hemos visto que es necesario calcular previemante los valores esperados. No es que sea difícil, pero es un tanto largo y complejo. Es más conveniente usar chisq.test(). En el caso de la prueba de homogeneidad hemos de darle los datos como una matriz de observaciones. No es necesario dar las probabilidades, que ni siquiera existen. Creamos los vectores con (con cinturón) y sin (sin cinturón) la matriz y añadimos nombres para que sea más legible. A partir de estos dos vectores creamos la matriz con la instrucción rbind(): con = c(12813, 647,359,42) names(con) = c(&quot;nada&quot;, &quot;leve&quot;, &quot;medio&quot;, &quot;grave&quot;) sin = c(65963,4000,2642,303) names(sin) = c(&quot;nada&quot;, &quot;leve&quot;, &quot;medio&quot;, &quot;grave&quot;) cint = rbind(con,sin) Teniendo la matriz, la instrucción chisq.test(cint) nos da lo que queremos: chisq.test(cint) ## ## Pearson&#39;s Chi-squared test ## ## data: cint ## X-squared = 59.224, df = 3, p-value = 8.61e-13 13.4 La prueba \\(\\chi^{2}\\) de independencia Como vimos al estudiar teoría de probabilidad, decimos que dos variables aleatorias A y B son independientes si y sólo si Prob[A y B] = Prob[A]\\(\\cdot\\)Prob[B] para cualquier par de valores que puedan tomar las variables. Si A y B son variables discretas y finitas, podemos estudiar la independencia de dos variables mediante un experimento estadístico. Para ello debemos coger una muestra y comparar en conjunto las probabilidades Prob[A y B] y Prob[A]\\(\\cdot\\)Prob[B]. Como estos estudios conjuntos los hemos hecho con una prueba de \\(\\chi^2\\), parece razonable pensar que podemos usar una prueba de \\(\\chi^2\\) para determinar la independencia de probabilidad de dos variables. Veamos cómo se hace. Hemos cogido nuestra muestra y esto da lugar a una tabla de contingencia de valores observados como la que hemos mostrado anteriormente y reproducimos aquí: \\[ \\begin{array}{c|ccccc|c} &amp; b_{1} &amp; … &amp; b_{j} &amp; … &amp; b_{m} &amp; Totales\\\\\\hline a_{1} &amp; o_{11} &amp; … &amp;o_{1j} &amp; … &amp; o_{1m} &amp; T_{a1} \\\\ … &amp; … &amp; … &amp; … &amp; … &amp; … &amp; … \\\\ a_{i} &amp; o_{i1} &amp; … &amp;o_{ij} &amp; … &amp; o_{im} &amp; T_{ai} \\\\ … &amp; … &amp; … &amp; … &amp; … &amp; … &amp; … \\\\ a_{n} &amp; o_{n1} &amp; … &amp;o_{nj} &amp; … &amp; o_{nm} &amp; T_{an} \\\\\\hline Totales &amp; T_{b1} &amp; … &amp; T_{bj} &amp; … &amp; T_{bm} &amp; T \\end{array} \\] De esta tabla podemos leer la probabilidad Prob[(A = \\(a_{i}\\)) y (B = \\(b_{j}\\))]: es \\(o_{ij}/T\\). Esto quiere decir que \\(o_{ij}\\) = Prob[(A = \\(a_{i}\\)) y (B = \\(b_{j}\\))]\\(\\cdot T\\). Para poder comparar, hemos de calcular cuántos teóricamente deberíamos tener si la probabilidad fuera el producto de probabilidades. Es fácil ver que es: \\[t_{ij} = \\mbox{Prob[A } = a_{i}] \\cdot \\mbox{Prob[B } = b_{j}] \\cdot \\mbox{T}\\] Las dos probabilidades Prob[A = \\(a_{i}\\)] y Prob[B = \\(b_{j}\\)] también las podemos sacar de la tabla: \\[ \\mbox{Prob[A } = a_{i}] = \\frac{T_{ai}}{T} \\quad \\mbox{y} \\quad \\mbox{Prob[B } = b_{j}] = \\frac{T_{bj}}{T}.\\] Y nos queda \\[t_{ij} = \\frac{T_{ai}}{T} \\cdot \\frac{T_{bj}}{T} \\cdot T = \\frac{T_{ai}\\cdot T_{bj}}{T}\\] Que es exactamente el mismo valor teórico que habíamos obtenido en la prueba de homogeneidad. Por lo tanto, desde el punto de vista del cálculo, las pruebas de homogeneidad y de independencia son la misma prueba. Si lo pensamos un poco, es lo natural: si, por ejemplo, el color de ojos fuera independiente del color de pelo, entonces podríamos esperar que para cada color de pelo la distribución de color de ojos fuera siempre la misma. Como no lo es, sabemos que no son independientes. Y análogamente, si vemos que hay la misma distribución del color de pelo para cada color de ojos, querría decir que ambos colores son independentes. Como las distribuciones no son iguales, establecemos que hay una dependencia. En conclusión, la prueba de \\(\\chi^2\\) de homogeneidad y la prueba de \\(\\chi^2\\) de independencia son en el fondo la misma prueba. Lo que cambia es la forma de plantear la pregunta. Hay una diferencia importante que no tratamos aquí: el diseño de un experimento donde queremos estudiar la independencia es diferente del diseño que haríamos en el caso de homogeneidad. Dado que en esta asignatura no estudiamos diseño de experimentos, podemos considerar la diferencia entre ambas pruebas de \\(\\chi^2\\) una cuestión de nomenclatura y nada más. *** 13.4.1 Prueba \\(\\chi^2\\) de independencia como contraste de hipótesis ¿Cuál es la hipótesis nula en la prueba de \\(\\chi^2\\) de independencia? Tiene que ser “la misma” que en el caso de homogeneidad. Como acabamos de ver, si hay homogeneidad, es que tenemos independencia. Luego, informalmente, la hipótesis nula es que hay independencia, y la alternativa es que no, que hay dependencias entre las variables. Formalmente, la nula es que \\(\\chi^{2}_{0} = 0\\) y la alternativa es que \\(\\chi^{2}_{0} &gt; 0\\). Formamente en el contraste de hipótesis la hipótesis nula es H0: \\(\\chi^{2} = 0\\), que es lo que tendríamos si las variables fueran independientes. La hipótesis alternativa es Ha: \\(\\chi^{2} &gt; 0\\), que es lo que debe aarecer si las variables no son independientes. A partir de la muestra calculamos \\[\\chi^{2}_{0} = \\sum \\frac{(\\mbox{observado} - \\mbox{teórico})^{2}}{\\mbox{teórico}}.\\] Esto nos permite calcular el p-valor como Prob[\\(X &gt; \\chi^{2}_{0} \\; |\\; \\chi^{2} = 0\\)]. 13.4.2 Un ejemplo Queremos saber si el consumo de tabaco en adolescentes depende del sexo. Usamos el conjunto de datos samhda del paquete UsingR que contiene datos del comportamiento de chicos en edad escolar. Usamos dos variables: amt.smoke, que indica la cantidad de días que ha fumado en el último mes, y la variable gender, con el sexo. La codificación de las variables es la siguiente: amt.smoke gender 1: todos los días 1: hombre 2: 20 a 29 días 2: mujer 3: 10 a 19 días 7: NS/NC 4: 6 a 9 días 5: 3 a 5 días 6: 1 a 2 días 7: ningún día 98 y 99: NS/NC Empezamos por crear un data frame reducido, que llamaremos Aux con las dos variables que nos interesan y quitando los NS/NC. Después crearemos la tabla de contingencias de frecuencias absolutas. Llamaremos esta tabla TabSex: library(UsingR) Aux = subset(samhda, amt.smoke &lt; 98 &amp; gender &lt; 7, select = c( &quot;gender&quot;, &quot;amt.smoke&quot;)) TabSex = table(Aux) La tabla resultante es la siguiente: amt.smoke gender 1 2 3 4 5 6 7 1 16 3 5 6 7 24 64 2 16 4 8 4 7 19 40 Vemos que dados algunos valores bajos, sospechamos que al hacer el \\(\\chi^2\\) tendremos el aviso de la función. Antes de seguir, lo comprobamos. Y efectivamente es así: chisq.test(TabSex) ## Warning in chisq.test(TabSex): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: TabSex ## X-squared = 4.1468, df = 6, p-value = 0.6568 Podemos juntar las columnas con valores 2 y 3 por un lado y con valores 4 y 5 por otro. Así tendríamos los niveles “Siempre”, “A menudo”, “Ocasionalmente”, “Casi nunca” y “Nunca”, lo que parece bastante razonable. TabSex2 = cbind(TabSex[,1], TabSex[,2] + TabSex[,3], TabSex[,4] + TabSex[,5], TabSex[,6], TabSex[,7]) colnames(TabSex2) = c(&quot;Siempre&quot;, &quot;A menudo&quot;, &quot;Ocasionalmente&quot;, &quot;Casi nunca&quot;, &quot;Nunca&quot;) Hacemos la gráfica: barplot(prop.table(TabSex2, 1), beside = T, col = c(&quot;lightblue&quot;, &quot;forestgreen&quot;)) legend(&quot;topleft&quot;, legend = c(&quot;Hombres&quot;, &quot;Mujeres&quot;), fill = c(&quot;lightblue&quot;, &quot;forestgreen&quot;)) Vemos que hay algunas diferencias, las mayores en los niveles “A menudo” y “Nunca”’. Veremos si esto es suficiente para romper la independencia. Hacemos la prueba de \\(\\chi^2\\) . La hipótesis nula es que el consumo de tabaco es independiente del sexo y la alternativa es que sí depende. chisq.test(TabSex2) ## ## Pearson&#39;s Chi-squared test ## ## data: TabSex2 ## X-squared = 3.8743, df = 4, p-value = 0.4233 Con un p-valor de 0,42 estos datos no aportan evidencia para apartarnos de la hipótesis nula. Consideramos que el consumo de tabaco es el mismo para dolescentes de ambos sexos. 13.5 Resumen Si tenemos una variable cualitativa con sólo dos niveles y queremos saber si el número de “exitos” es algún valor previsto concreto, podemos hacer un prop-test. Si tenemos más de dos niveles, ya no podemos usar el prop-test, pues tendríamos que hacer muchas pruebas y la probabilidad de error se va a acumular. Es el mismo problema que teníamos con el ANOVA. Y al igual que con el ANOVA, la solución es utilizar una nueva prueba que calcule lo bien qeu se ajustan todos los niveles simultáneamente: es la prueba de %^2$ de bondad de ajuste. Es en el fondo un contraste de hipótesis donde la hipótesis nula es, informalmente, que todos los niveles siguen las probabilidades de alguna distribución prefijada, y la alternativa es que no lo siguen. La función de R chisq.test() nos realiza lso cálculos. Si nuestros datos son tales que los niveles menos abundantes tienen muy pocos casos teóricos, típicamente menos que 5, consideramos que son datos demasiado problemáticos. Podemos obtener un valor de \\(\\chi_0^2\\) y un p-valor, pero son poco fiables. En este caso a veces tenemos la posibilidad de agrupar los casos menos abundantes en “otros” o directamente eliminarlos. Pero hay que ir con cuidado, pues esto no siempre tiene sentido. Si tenemos dos variables cualitativas, hay dos pruebas basadas en \\(\\chi^2\\) que podemos realizar. Una es la prueba de homogeneidad en la que la hipótesis nula es que las distribuciones de todas las filas (o columnas) es la misma, mientras que la alternativa es que no son todas la misma. La otra prueba es la prueba de \\(\\chi^2\\) de independencia, en la que la hipótesis nula es que las dos variables son independientes y la alternativa es que no lo son. Desde el punto de vista del cálculo a realizar, las dos pruebas son la misma, lo que cambia es la forma de plantear la pregunta que queremos contesar. Para realizar las pruebas con R usamos la función chisq.test(tcont). Tiene un único parámetro que es la tabla de contingencia de frecuencias absolutas. "],
["regresión-lineal.html", "Capítulo 14 Regresión Lineal 14.1 Cálculo 14.2 Estadística 14.3 Diagnóstico 14.4 Inferencias 14.5 Predicciones", " Capítulo 14 Regresión Lineal Hemos visto cómo estudiar datos cuando tenemos una variable numérica (t.test), una cualitativa (prop.test y \\(\\chi^{2}\\) de bondad de ajuste), una variable numérica y una cualitativa (ANOVA) y dos varialbes cualitativas (\\(\\chi^{2}\\) de homogeneidad/independencia). Nos queda el caso de tener dos variables numéricas. La prueba estadístca habitual en este caso es la regresión lineal con el que encontramos la recta o curva que “mejor” se aproxima a nuestros datos. Es una prueba complicada, que vamos a dividir en varias partes: el cálculo de la recta o curva, las estadísticas involucradas, el diagnóstico de la fiabilidad de la prueba y la predicción de valores nuevos. Empezamos con el cálculo de la recta o curva, que en el fondo no es una cuestión de estadística, sino de cálculo. 14.1 Cálculo 14.1.1 Fundamentos Queremos saber como varía la intensidad que pasa por un componente en función del voltaje que le aplicamos. Vamos a imaginarnos que somos unos científicos de principios del S. XIX estudiando esta cosa nueva llamada electricidad y no conocemos la Ley de Ohm. Montamos un circuito con una fuente de alimentación para aplicar un voltaje y un amperímetro para medir la intensidad. Lo hacemos con todo cuidado, hacemos varias pruebas, mejoramos nuestros procedimientos (vemos, por ejemplo, que el lugar donde colocamos las sondas de medida influyen en el valor que obtenemos) y tomamos nuestras medidas. Son las siguientes: V (voltios) I (mA) 3,0 20 5,0 34 7,0 57 9,0 82 1 11,0 11 14,0 141 17,0 165 20,0 180 25,0 235 30,0 275 V = c(3.0, 5.0, 7.0, 9.0, 11.0, 14.0, 17.0, 20.0, 25.0, 30.0) I = c(20, 34, 57, 82, 111, 141, 165, 180, 235, 275) plot(V, I) Estos son los datos. A la variable que está en el eje X se le llama variable independiente o estímulo. A la variable que está en el eje Y se le llama variable dependiente o respuesta. Nosotros introducimos la variable independiente, puede tomar cualquier valor que queramos, pero medimos la dependiente, que toma el valor que corresponda. Otra forma de verlo es que estimulamos con el voltaje y el componente responde con una cierta intensidad. Vemos que los puntos siguen una extraña curva que no identificamos. Además, durante las pruebas nos fijamos que siempre obteníamos alguna extraña curva, pero que no siempre se parecía a esta. Notamos también que en este caso (y en todos los anteriores) los puntos no formaban exactamente una recta, pero siempre se acercaban bastante. Esto nos lleva a hacer una suposición: vamos a suponer que los puntos deberían seguir realmente una recta y que si no la siguen son por errores experimentales: aunque el primer punto es, dentro de nuestra precisión, (3,0; 20), realmente podría ser el (2,96; 20,4), un poco desviado de donde lo he pintado. O quizá en algún caso no he colocado la sonda con todo el cuidado que debía. Es razonable pensar que los puntos reales están cerca, pero no exactamente donde la teoría predice. Supongamos entonces que en el caso ideal, si no hubiera errores experimentales, los puntos siguieran perfectamente una recta. ¿Qué recta sería? Estamos suponiendo que la ley que regula la intensidad en función del voltaje es realmente \\(I = a + bV\\) y que nuestros puntos se desvían de esta recta por error experimental. Es decir que para cada par \\((V_{i}, I_{i})\\) se cumple que \\[I_{i} = a + bV_{i} + \\varepsilon_{i}\\] donde \\(\\varepsilon_{i}\\) es nuestro error experimental para la medida \\(i\\). A estas cantidades las vamos a llamar residuos. Nótese que si el punto está por encima de la recta el residuo es positivo y si está por debajo, el residuo es negativo. Vamos a dibujar los residuos tenemos la siguiente gráfica: Los residuos no corresponden a la distancia del punto a la recta, sino que es el desplazamiento vertical desde el punto a la recta. Para poder calcular la recta vamos a suponer además que como hemos ido con mucho cuidado en reducir en lo posible los errores experimentales, la recta “real” va a ser aquella que minimiza de forma conjunta los residuos. Siguiendo la misma idea que en la prueba de \\(\\chi^{2}\\), esto va a querer decir que queremos minimizar la suma de los cuadrados de los residuos. Con estas dos suposiciones —el voltaje y la intensidad están relacionados mediante una recta y que la recta es aquella que minimiza la suma de cuadrados de los residuos— hemos convertido nuestro problema en uno de minimización, un problema de cálculo. Ya saben: derivar, igualar a 0, etc. No es trivial resolver este problema de cálculo, pero tampoco es demasiado difícil. No lo vamos a detallar aquí: en Wikipedia o cualquier libro elemental de estadística lo puede encontrar. Simplemente saber que se acaba con dos fórmulas en las que introducimos nuestros puntos y nos permiten calcular los valores de \\(a\\) y \\(b\\). A este método se le llama regresión lineal. Algunas matizaciones. El adjetivo lineal no hace referencia a que hemos calculado una recta, sino al método de cálculo usado. Podemos usar la regresión lineal para calcular cualquier curva que propongamos. Veremos ejemplos más adelante. Es más, este método lo creó el matemático alemán C.F. Gauss no para calcular una recta, sino para calcular una elipse, la de la órbita de Ceres. Aunque este método de regresión se considera estadística, el cálculo de la recta (o curva) en sí no es estadística sino cálculo. El hacer inferencias sobre la recta (o curva) obtenida sí que es estadística y requiere que se cumplan una serie de condiciones que detallaremos en su momento. El que obtengamos una recta, una exponencial o cualquier otra curva no es inherente ni al método ni a los puntos en sí, sino que es una hipótesis del investigador. En otras palabras, el que sea una recta (o exponencial o lo que sea) no “sale” del método sino que lo “mete” el que hace los cálculos. Se suele decir que se calcula la recta que minimiza la suma de las distancias de los puntos a la recta. Aunque informalmente ya nos basta, no es correcto. Como hemos visto, lo que minimiza es la suma de los cuadrados de los residuos. No es lo mismo. Usaremos R para hacer los cálculos. La función a utilizar es lm(). En el caso que queramos calcular una recta, la instrucción tiene la forma lm(y~x), que se lee “\\(y\\) en función de \\(x\\)”. Recordemos que \\(y\\) es la variable dependiente, la respuesta, y que \\(x\\) es la variable independiente, el estímulo. Para nuestro ejemplo: R = lm(I~V) R ## ## Call: ## lm(formula = I ~ V) ## ## Coefficients: ## (Intercept) V ## -4.877 9.566 La ordenada en el origen (lo que aparece en la salida de R como Intercept) es \\(-4,880\\) mA y el coeficiente que multiplica al voltaje (la pendiente) es \\(9,559\\). Es decir la recta de regresión es \\[I = -4,880 + 9,559\\,V.\\] Lo que estos dos coeficientes representan es que, según este modelo, con un voltaje de 0 V pasa por el componente una intensidad de \\(-4,880\\) mA y que por cada voltio adicional que apliquemos, la intensidad sube \\(9,559\\) mA. Sabemos que la ordenada en el origen debería ser 0. Cuando estudiemos la parte estadística de la regresión lineal veremos si este \\(-4,880\\) que hemos obtenido significa que tenemos un error experimental o no. Podemos aplicar la ley de Ohm para obtener de nuestras medidas la resistencia del componente: \\(1000/9,559 = 104,6\\,\\Omega\\) (el 1000 es porque tenemos las intensidades en mA). 14.1.2 Otro ejemplo En nuestro primer ejemplo teníamos una ley física, y las leyes físicas siempre siguen una expresión matemática, a menudo simple. Si además trabajamos en el entorno controlado de un laboratorio, tenemos una variabilidad muy pequeña, como obtuvimos. Vamos a un segundo ejemplo donde no hay ninguna ley física y la variabilidad es mucho mayor. Estamos diseñando una montaña rusa para un parque de atracciones. Es una montaña rusa pequeña en la que sólo se montarán niños de hasta 12 años. Para mejorar la eficiencia queremos estimar el peso de los niños que suben a la atracción. Desgraciadamente no es factible hacer que los niños se pesen a la entrada, ni es posible, por cuestión de coste, añadir una báscula y pesar los vagones con los niños montados. Una solución simple sería contar cuántos niños se montan y multiplicar ese número por el peso medio de un niño, pero buscamos algo mejor. Una posibilidad que queremos estudiar es poner una cámara en el paso de entrada y usarla para medir con bastante precisión la altura de los niños. Como el peso está correlacionada con la altura, esto teóricamente nos permitiría estimar el peso de los niños que se monten en la atracción. En este caso la variable independiente es la altura, lo que medimos e introducimos en el modelo, y la variable dependiente es el peso, lo que estimamos. No hay aquí ninguna ley física, pero si una noción de que cuanto mayor es la altura de un niño, mayor va a ser su peso. Es cierto que el peso no sólo depende de la altura, sino que también depende del sexo del niño, de sus constitución, de lo gordo o delgado que está, etc., pero si el peso depende de la altura en gran medida, este método puede funcionar. Para estudiar nuestras ideas cogemos el conjunto de datos kid.weights del paquete UsingR. Seleccionamos a los mayores de 4 años (48 meses). Creamos las variables alt, con la altura de los niños y peso, con su peso. Lo dibujamos y miramos los datos: library(&quot;UsingR&quot;) #Mayores de 4 años KW4 = kid.weights[kid.weights$age &gt;=48,] peso = KW4$weight*0.454 alt = KW4$height*2.54 plot(alt, peso, xlab = &quot;altura (cm)&quot;, ylab = &quot;peso (Kg)&quot;) Parecen bastante dispersos. No está claro qué curva sería la que más se aproxima a los puntos. Ni siquiera sabemos si la tal curva existe. Vamos a empezar por suponer que es una recta (para qué complicarse la vida de entrada). La calculamos: PA = lm(peso~alt) PA ## ## Call: ## lm(formula = peso ~ alt) ## ## Coefficients: ## (Intercept) alt ## -14.8472 0.3543 Estos dos coeficientes se interpretan de la siguiente manera: el peso de un niño de altura 0 cm es de \\(-14,8\\) Kg y por cada centímetro adicional, el niño pesa \\(0,35\\) Kg más. El primer coeficiente es obviamente absurdo. Esto pasa mucho en la regresión lineal y es debido a que los datos de nuestra muestra están entre 60 cm y 160 cm y, a menos que haya una ley natural conocida, sólo debemos utilizar la recta dentro de este rango: no tienen validez fuera de él (y hemos de tener más dudas en los extremos que en el centro). Esta recta, este modelo, no puede extrapolarse fuera del rango de los datos de partida. Gráficamente queda: plot(alt, peso, xlab = &quot;altura (cm)&quot;, ylab = &quot;peso (Kg)&quot;) abline(PA, col = &quot;red&quot;) Vemos que hay muchos puntos alejados de la recta. Quizá la regresión no sea la solución que buscábamos. Cuando estudiemos la parte de estadística de la regresión podremos precisar más la bondad de esta recta como predictora de pesos. 14.1.3 ¿Y si no es una recta? Como hemos dicho, la regresión lineal no necesariamente se debe aplicar a una recta. Es el caso más simple y más habitual, pero podemos partir de cualquier curva que queramos. Veamos primero un caso típico, el crecimiento exponencial. En este caso transformamos la función para que se convierta en una recta. Después veremos cómo indicar a R otras funciones que queramos utilizar. Crecimiento exponencial Muchos sistemas crecen de forma exponencial durante algunos periodos. Por ejemplo, muchos crecimientos orgánicos (animales, plantas, bacterias) crecen exponencialmente si no hay limitaciones de recursos: cuantos más individuos hay, más nacimientos se producen, lo que hace que haya aún más individuos, lo que hace que haya aún más nacimientos. Esto sigue así hasta que la escasez de recursos hace que no puedan crecer tan rápido, llegando eventualmente a pararse. Pero inicialmente el crecimiento es exponencial. Por un razonamiento análogo, los decrecimientos orgánicos también presentan a menudo una fase exponencial. Se suele utilizar (equivocadamente) el término “crecimiento exponencial” cuando lo que se quiere decir es que hay un crecimiento rápido. Técnicamente, tenemos un crecimiento exponencial si el porcentaje del crecimiento es constante y esto tiene una forma matemática concreta. Sea \\(t\\) el tiempo medido a partir de un cierto instante inicial e \\(y\\) el número de individuos. Entonces tenemos crecimiento exponencial si \\(y = a e^{bt}\\). Comprobemos que esto significa que el crecimiento porcentual por unidad de tiempo es constante. El crecimiento porcentual es el crecimiento en una unidad de tiempo dividido por el tamaño de la población: \\[\\frac{ae^{b(t+1)} - ae^{bt}}{ae^{bt}}\\] Desarrollamos \\[\\frac{ae^{b(t+1)} - ae^{bt}}{ae^{bt}} = \\frac{a(e^{bt}e^{b}) - ae^{bt}}{ae^{bt}} = \\frac{ae^{bt}(e^{b} - 1)}{ae^{bt}} = e^{b} - 1\\] Si \\(b&gt;0\\) entonces \\(e^{b} - 1 &gt; 0\\) y tenemos un crecimiento, mientras que si \\(b &lt; 0\\), \\(e^{b} - 1 &lt; 0\\) y tenemos un decrecimiento. Por ejemplo, si \\(b = 0,4\\) el crecimiento es de \\(e^{0,4} - 1 = 0,49\\), un 49%, mientras que si \\(b = -0,2\\) tenemos un crecimiento de \\(e^{-0,2} - 1 = -0,18\\), es decir un decrecimiento del 18% por unidad de tiempo. Podemos transformar la fórmula del crecimiento exponencial a una fórmula lineal. Si aplicamos logaritmos a ambos lados de la ecuación tenemos: \\[\\log y = \\log(a e^{bt}) = \\log a + \\log e^{bt} = \\log a + bt\\] Luego si \\(y\\) crece exponencialmente, el logaritmo de \\(y\\) crece linealmente. En el fichero Telefonos.csv (pestaña de recursos) tenemos el número de teléfonos por cada 100 habitante en varios países. Cojamos el caso de Nicaragua. Si dibujamos el número de teléfonos por cada 100 habitantes en Nicaragua en función del año, tenemos la siguiente gráfica: Tel = read.csv(&quot;datos/Telefono.csv&quot;, header = T, sep = &quot;;&quot;, dec = &quot;,&quot;) Nicaragua = Tel$Nicaragua plot(Tel$Year, Nicaragua, xlab = &quot;Año&quot;, ylab = &quot;Teléfonos/100 hab&quot;) Vemos que podría ser un crecimiento exponencial. Para comprobarlo vamos a dibujar el logaritmo del numero de teléfonos en función del año: plot(Tel$Year, log(Nicaragua), xlab = &quot;Año&quot;, ylab = &quot;log(Teléfonos/100 hab)&quot;) Vemos que a partir de 1991 hasta el 2006 tenemos algo que se parece a una recta, es decir, un crecimiento aproximadamente exponencial. Lo malo de esta gráfica es que es difícil deducir el número de teléfonos de lo que vemos en la gráfica: por ejemplo el “2” en el eje Y quiere decir \\(e^{2} = 7,4\\) teléfonos por 100 habitantes. Por suerte R nos permite dibujar el logaritmo, pero ajustando la escala al número de teléfonos. Para ello hay que añadir el parámetro log = &quot;y&quot;+ a la función plot: plot(Tel$Year, Nicaragua, log = &quot;y&quot;, xlab = &quot;Año&quot;, ylab = &quot;Teléfonos/100 hab&quot;) Este tipo de gráficas se llaman semilogarítmicas, pues un eje tiene escala lineal y el otro, logarítmico. Vamos a estudiar el crecimiento exponencial de los teléfonos en Nicaragua desde 1991 a 2006. En la variable TNic tenemos los teléfonos/100 Habitantes de Nicaragua desde 1991 a 2006. Creamos una variable Tiempo que es años transcurrido desde 1991 (1991 es el año 0). Y ahora hallamos la recta con la instrucción lm(log(TNic)~Tiempo). Esto nos da un valor para la ordenada en el origen de \\(-0,14\\) y para la pendiente de \\(0,2218\\). Luego la exponencial que minimiza la suma de residuos y que nos sirve de modelo para el crecimiento de teléfonos en Nicaragua es \\[\\mbox{TNic} = 0,866\\, e^{0,2218 t}\\] donde \\(t\\) es el tiempo, medido en años, transcurridos desde el 1 de enero de 1991. Les dejo como ejercicio que averigüen de dónde sale el \\(0,886\\). La gráfica, con la curva de regresión añadida es la siguiente: TNic = Tel[Tel$Year &gt; 1990,]$Nicaragua Tiempo = Tel[Tel$Year &gt; 1990,]$Year - 1991 Crec = lm(log(TNic)~Tiempo) plot(Tel$Year, Nicaragua, log = &quot;y&quot;, xlab = &quot;Año&quot;, ylab = &quot;Teléfonos/100 hab&quot;) curve(exp(Crec[[1]][1])*exp(Crec[[1]][2]*(x-1991)), from = 1991, to = 2006, add = T, col = &quot;red&quot;) Como hemos explicado, el crecimiento porcentual viene dado por \\(e^{b}-1\\). Hacemos el cálculo: \\(e^{0,2218}-1 = 0,25\\). El crecimiento anual medio de teléfonos en este periodos fue del 25%. Otras funciones La fuerza de resistencia aeorodinámica \\(F_{RA}\\) de un coche en movimiento depende de su superficie frontal \\(S\\), la densidad del aire \\(\\rho\\), el coeficiente aerodinámico \\(C_{x}\\) y la velocidad \\(V\\) a la que se mueve y viene dada por la expresión \\[F_{RA} = \\frac{1}{2}\\, \\rho S C_{x} V^{2}.\\] Para calcular el coeficiente aerodinámico se mete el coche en un túnel de viento y se mide la fuerza que ejerce que el aire sobre él para diferentes velocidades del viento. La variable independiente sería la velocidad y la dependiente sería la fuerza de resistencia aerodinámica. Lo hemos hecho con un coche de superficie frontal \\(S = 1,97 \\mbox{m}^{2}\\). La densidad del aire es de \\(\\rho = 1,225 \\mbox{Kg}/\\mbox{m}^{3}\\). El resultado de una prueba es: \\(V\\) (m/s) \\(F_{RA}\\) (Nw) 15 101 18 133 22 145 26 238 31 331 36 442 42 640 Vel = c(15, 18, 22, 26, 31, 36, 42) RA = c(101, 133, 145, 238, 331, 442, 640) plot(Vel, RA, xlab = &quot;Velocidad (m/s)&quot;, ylab = &quot;Res. Aero. (Nw)&quot;) Para calcular el coeficiente queremos hallar la curva de regresión que mejor se ajusta a los datos medidos, es decir, la que minimiza la suma de los cuadrados de. Sabemos, por las leyes físicas de la aerodinámica, que la curva es de la forma \\(F_{RA} = a + bV^{2}\\). Hacemos el cálculo con R. RRA = lm(RA~I(Vel^2)) RRA ## ## Call: ## lm(formula = RA ~ I(Vel^2)) ## ## Coefficients: ## (Intercept) I(Vel^2) ## 3.4432 0.3501 Hemos introducido el tipo de curva en la función lm(), indicando que debe ajustarse al cuadrado de la velocidad. Hemos de escribir I(V^(2)) y no simplemente V^2 ya que dentro de lm() los símbolos de multiplicación (*), división (/), exponenciación (^) y otros tienen un significado propio. La función I() le indica a lm() que utilice estos símbolos como operaciones aritméticas. En la respuesta de R vemos que la ordenda en el origen es \\(3,44\\) y el coeficiente del término \\(V^{2}\\) es \\(0,3502\\). Sabemos que la ordenada en el origen debería ser 0. El resultado de la regresión es un valor pequeño, lo cual es bueno, pero ya veremos si indica algún problema experimental cuando estudiemos la estadística de la regresión. Ahora podemos calcular el coeficiente aerodinámico: Tenemos que \\(\\frac{1}{2}\\, \\rho S C_{x} = 0,3502\\) y de aquí \\(C_{x} = (2 \\cdot 0,3502)/(S \\rho) = 0,29\\). Para un ejemplo final, volvamos al problema de los niños y la montaña rusa. Hemos visto que una recta no describe bien los puntos de nuestra muestra. Podemos probar con alguna otra función. Mirando los datos sin la recta, vemos que para valores de altura por encima de 140 cm hay muchos individuos de peso alto. Esto nos induce a pensar que el peso crece más que linealmente con la altura. Vamos a añadir un término cuadrático al término lineal que teníamos a ver qué pasa. Es decir, queremos una función del tipo \\[\\mbox{Peso} = a + b\\cdot \\mbox{altura} + c\\cdot\\mbox{altura}^{2}.\\] Indicamos a R la función que queremos y miramos los resultados: PAQ = lm(peso ~ alt + I(alt^2)) PAQ ## ## Call: ## lm(formula = peso ~ alt + I(alt^2)) ## ## Coefficients: ## (Intercept) alt I(alt^2) ## 67.602259 -1.105931 0.006235 La función de esta forma que minimiza la suma de los residuos al cuadrado es: \\[\\mbox{Peso} = 67,6 -1,11\\cdot \\mbox{altura} + 0,0062\\cdot\\mbox{altura}^{2}.\\] Si la dibujamos queda: plot(alt, peso, xlab = &quot;altura (cm)&quot;, ylab = &quot;peso (Kg)&quot;) curve(PAQ[[1]][1] + PAQ[[1]][2]*x + PAQ[[1]][3]*x^2, add = TRUE, col = &quot;blue&quot;) Tiene mejor pinta que el caso de la recta, aunque es obvio que esta curva no tiene ningún sentido anatómico: predice que entre los 60 cm y 85 cm de altura el peso disminuye con la altura. Esto no quiere decir que no nos sea útil. Lo sabremos con más precisión cuando estudiemos la parte estadística de la regresión lineal. 14.1.4 Resumen de la parte de cálculo Cuando tenemos dos variables numéricas y en el que vemos una correlación, nos puede interesar encontrar la recta o curva que minimice la suma de los cuadrados de los residuos, es decir, que mejor se aproxima de forma global nuestros datos. El determinar qué recta o curva utilizar no es cuestión de estadística, sino que lo determina el que realiza el estudio basándose en cuestiones teóricas, en su experiencia y lo que ve o simplemente en prueba y error. Una vez decidido qué curva usar, hallar la “mejor” es un problema de minimización, de cálculo. El fundamento en el que se basa es que los valores de la variable dependiente que vemos provienen de la curva pero están “perturbados” por error experimental u otros efectos. Esta perturbación es la que hace que no veamos la recta o curva directamente. Buscamos la curva que hace que las perturbaciones sean mínimas, pues suponemos que la ley física, biológica, ingenieril o lo que sea es la que manda. En algunos casos esto es claramente cierto, pero en otras es una mera suposición y puede que la “ley” de partida no exista, y la curva que buscamos, tampoco. Eso no impide que encontremos una curva, pero no es “real” sino sólo un producto de nuestra imaginación. Hemos visto varios casos: el caso de una recta, el del crecimiento exponencial, que puede transformarse en una recta, o el de una función general. Salvo en el caso de la recta, los cálculos pueden ser muy complejos, pero por suerte tenemos ordenadores, y R, para hacerlos. Ahora bien, la curva obtenida proviene de una muestra. Diferentes muestras de la misma población darán lugar a diferentes curvas. El saber qué podemos decir de la curva “real” a partir de la curva obtenida de nuestra muestra es donde entra la estadística. Y lo que veremos en el siguiente apartado. 14.2 Estadística Vimos en el documento anterior cómo a partir de dos variables numéricas y un tipo de curva propuesta por el investigador, es posible encontrar la que minimiza la suma de los cuadrados de los residuos. Este es un problema puramente de cálculo: minimizar una cierta función. Ahora bien, como la curva calculada depende de la muestra, si cojo muestras diferentes de una misma población estaré obteniendo curvas diferentes. ¿Qué se puede decir de la curva de toda la población a partir de la curva que he obtenido de una muestra concreta? Ese sí es un problema de estadística y es el que trataremos en este documento. Para no ir escribiendo “recta o curva” cada vez, uso el término genérico curva cuando no tiene una forma definida. En particular puede ser una recta. Reservo los términos “recta”, “exponencial”, “cuadrática” etc, para referirme a tipos de curva (o recta) concretas. *** 14.2.1 Incertidumbre en la regresión lineal Lo bueno de simular en un ordenador, no sólo es que puedo conseguir todas las muestras que quiera con suma facilidad, sino que además sé cuál es el valor poblacional del que parto. Retomemos el problema de la ley de Ohm presentado en el documento anterior. Para crear los datos usado en el ejemplo escogí unos valores de la variable independiente, el voltaje, supuse una resistencia de 110 \\(\\Omega\\) y calculé los valores “exactos” de la variable dependiente, la intensidad. Después le añadí el “error experimental”, es decir los residuos, mediante unos valores aleatorios que siguen una distribución normal de media 0 y desviación típica adecuadamente baja. Si la dibujamos queda: V = c(3, 5, 7, 9, 11, 14, 17, 20, 25, 30) Ie = (1000/110)*V # en mA I = Ie+rnorm(length(V), 0, 1500/110) Cada vez que ejecute la última instrucción obtendré una nueva muestra de la intensidad, pero siempre de la misma población. Si cojo 4 muestras y calculo sus rectas de regresión, obtengo el gráfico siguiente (sin los puntos): plot(V,Ie, xlab =&quot;V (voltios)&quot;, ylab = &quot;I (mA)&quot;, type = &quot;n&quot;) for (i in 1:4) { I = Ie+rnorm(length(V), 0, 1500/110) abline(lm(I~V), col = &quot;red&quot;) } abline(0, 100/11, col = &quot;blue&quot;) Las rectas rojas son las obtenidas de la regresión, la recta azul es la que sigue la Ley de Ohm. Vemos que todas las regresiones se acercan a la poblacional, con algunas por encima, otras por debajo, unas con una pendiente mayor, otras menor. Esta variación depende del muestreo. Si quiero hacerme una idea de hasta dónde puede llegar la variablidad en función de la muestra, calculo y pinto muchas rectas, por ejemplo 1000: Vemos que la pendiente presenta cierta incertidumbre y también la ordenada en el origen. No vamos a mostrar cómo establecemos esta incertidumbre, ni siquiera de forma esquemática. Lo que haremos es establecer las condiciones que se han de dar para que podamos calcularla y leeremos de la salida de R los datos que nos interesan. 14.2.2 Condiciones Para calcular la curva de regresión no había condición alguna: dados unos puntos en el plano, es decir dos variables numéricas de la misma longitud, y una curva de una forma determinada, siempre se podía calcular la curva que minimizara la suma de los residuos. Pero para poder calcular las características estadísticas sí que necesitamos que se cumplan algunas condiciones. Los residuos son independientes. Esto quiere decir, por ejemplo, que si estamos midiendo la distancia recorrida por un objeto, esta distancia siempre hay que medirla desde el origen, pues si midiera lo que ha avanzado desde la última medida, un error en una medida se propaga a todas las siguientes y los residuos no serían independientes. Los residuos siguen una distribución normal de media 0 y desviación típica \\(\\sigma\\). Esto es bastante razonable al tomar medidas de algo, pero no tanto si miramos la correlación entre la altura y peso de niños. Si la media no es 0 es que tenemos un error sistemático o un sesgo: estamos añadiendo (o quitando) de forma sistemática una cantidad al valor de la variable. La desviación típica de los residuos es constante. Este es un problema frecuente. Por ejemplo, al tomar medidas, los primeros errores pueden ser mayores ya que hems de acostumbrarnos al aparato y el procedimiento; después disminuye, al aumentar nuestra aptitud; y al final vuelve a crecer por cansancio, aburrimiento u otros motivos. Cuanto menos se cumplan estas condiciones, menos fiables serán los valores estadísticos calculados. En el apartado de diagnóstico veremos cómo determinar lo bien o mal que se han cumplido estas condiciones. Nótese que no hemos puesto condición alguna sobre las variables, sino sólo sobre los residuos. Las variables pueden seguir cualquier distribución, ser unimodales o multimodales, simétricas o asimétricas. No importa. Lo único a lo que hay que ir atento es a los valores atípicos: un único valor atípico puede hacer cambiar mucho el resultado. Esto lo vemos en la siguiente gráfica. Los puntos negros dan lugar a la recta de regresión negra. Pero si añadimos un único valor atípico, el punto rojo, las características de la recta cambian enormemente. 14.2.3 Salida de R En el apartado de cálculo hicimos la regresión lineal R = lm(I ~ V)} y vimos uqe escribiendo R obteníamos los coeficientes de la regresión y nada más. Para obtener mucha más información, usamos summary(): summary(R) ## ## Call: ## lm(formula = I ~ V) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.952 -6.099 -1.543 5.641 11.957 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.877 4.991 -0.977 0.357 ## V 9.566 0.304 31.465 1.13e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.083 on 8 degrees of freedom ## Multiple R-squared: 0.992, Adjusted R-squared: 0.991 ## F-statistic: 990 on 1 and 8 DF, p-value: 1.132e-09 Es mucha información, alguna que nos interesa y otra que aún no. Nos fijaremos en estos momentos en lo que está bajo el epígrafe de Coefficients. En la primera columna (Estimate) tenemos los valores, los mismos que habíamos obtenido tecleando R. Con summary() obtenemos 3 columnas más: el error estándar, un estadístico \\(t\\) y la probabilidad de que sea mayor que \\(|t|\\), es decir, un p-valor. Todo esto nos suena a t.test. Y, efectivamente, esto es lo que se está haciendo. La hipótesis nula es H0: el coeficiente es 0; la hipótesis alternativa es Ha: el coeficiente no es 0. Vemos que el p-valor de la ordenada en el origen es 0,357. Esto quiere decir que, aunque para esta muestra ha salido \\(-4,8798\\), el de la población podría perfectamente ser 0. Lo que nos tranquiliza, pues sabemos por la Ley de Ohm que debe salir 0. Si hubiera salido un p-valor muy pequeño sería una indicación de un problema serio en nuestro experimento. El p-valor de la pendiente es un valor minúsculo, lo que es una indicación clara que la pendiente no es 0. Si tuviéramos un p-valor alto, y por lo tanto la sospecha de que la pendiente es 0, quiere decir que la variable dependiente no es tal: no depende de la independiente. En este caso, que la intensidad no dependería del voltaje. Recordemos que el modelo de partida es que \\(I = a + bV\\). Si \\(b = 0\\), entonces \\(I = a\\) y no depende del voltaje. Tras los coeficientes nos fijaremos en las últimas líneas de la salida. Tenemos el coeficiente de correlación \\(R^{2}\\), que aparece como Adjusted R-squared. La interpretación de este número es el porcentaje de la variación de la variable dependiente, \\(I\\) en el ejemplo, que se puede explicar por la variación de la variable independiente, \\(V\\) en el ejemplo. Como su valor es 0,991, esto quiere decir que el 99,1% de la variación de la intensidad queda explicada por la variación del voltaje, mientras que el 0,9% restante de la variación observada proviene de otras fuentes. En nuestro caso, del error experimental. Cuanto más bajo sea este coeficiente se dice que hay menos correlación entre una variable y otra. Gráficamente, si los puntos están pegados a la curva resultante de la regresión, el coeficiente será alto, si están muy dispersos, el coeficiente será bajo. Si la correlación es baja, es que la dependencia entre variables es baja, lo que relaciona este coeficiente con el p-valor de la pendiente. Pero no es lo mismo: el p-valor es una indicación de si la pendiente puede ser 0 o no, mientras que el coeficiente de correlación \\(R^{2}\\) nos indica que los residuos son muy grandes respecto a la variación de la pendiente. Por ejemplo, puntos cercanos a la recta pero ésta con pendiente baja nos dara un p-valor alto y un coeficiente de correlación también moderadamente alto. Hay un problema de nomenclatura con los coeficientes de correlación. Existen dos: \\(R\\), que puede ser positivo o negativo, y \\(R^{2}\\), que es el cuadrado del anterior y que siempre es positivo. Algunos llaman coeficiente de correlación a ambos, otros llaman coeficiente de determinación al de \\(R^{2}\\) y reservan el término coeficiente de correlación para el de \\(R\\). En este documento nunca nos referiremos a \\(R\\), por lo tanto, siempre que digamos “coeficiente de correlación” nos estamos refiriendo a \\(R^2\\). El último valor en el que nos fijaremos ahora es el p-valor que aparece al final de la salida. De momento nos fijaremos que es exactamente el mismo valor que aparece en la fila de la pendiente: \\(1,15 \\times 10^{-9}\\). Más adelante veremos un caso en el que el valor es distinto. Entonces explicaremos qué es este p-valor. 14.2.4 Intervalos de confianza Si para los coeficientes de la regresión hemos hecho un t-test, esto quiere decir que también podemos calcular intervalos de confianza. Lo podemos hacer a partir de los datos del summary(): tenemos la media, el error estándar e incluso los grados de libertad, luego no es difícil calcular el intervalo de confianza con cualquier nivel de confianza que queramos. Pero es mucho más conveniente ceder este trabajo a R. La función confint() nos calcula los intervalos de confianza de los coeficientes de la regresión: confint(R) ## 2.5 % 97.5 % ## (Intercept) -16.385313 6.632307 ## V 8.864656 10.266763 Vemos, con un 95% de confianza, que la ordenada en el origen de la población está entre \\(-16,4\\) y \\(6,64\\) y que la pendiente está entre \\(8,86\\) y \\(10,26\\). Como usábamos la pendiente para calcular la resistencia, podemos calcular el intervalo de confianza de la resistencia. Con un nivel de confianza del 95% está entre \\(1000/10,26 = 97,45\\,\\Omega\\) y \\(1000/8,86 = 113,00\\,\\Omega\\). Vemos con alivio que el valor real de \\(110\\, \\Omega\\) está en el intervalo. 14.2.5 Otro ejemplo Vamos a anclar estos conocimientos, y añadir alguno nuevo, estudiando más a fondo el ejemplo de la montaña rusa. Queríamos predecir el peso de un niño a partir de su altura. Este es un problema fundamentalmente diferente del anterior. En un experimento controlado en un laboratorio procuramos que lo único que haga cambiar la variable dependiente, la respuesta, sea el estímulo que aplicamos. Y tenemos una ley física que regula la relación entre ambas variables. En este otro caso, no estamos en el laboratorio y en el variable dependiente (el peso) influye, además de la variable independiente (la altura), muchos otros factores (el sexo, la constitución, la alimentación…). Además, seguramente no haya una ley anatómica o fisiológica que regule la relación entre las variables. De ahí la mayor variabilidad, la menor correlación, de los datos, algo que se aprecia a simple vista. Pero no nos importa demasiado, pues en este caso no estamos intentando descubrir cómo funciona el metabolismo de los niños, ni si hay alguna condición médica relevante. Simplemente queremos predecir con una cierta precisión la carga del vehículo para construir una atracción más eficiente. Por eso podemos ir probando curvas a ver si hay alguna que nos funcione. Usábamos como muestra el conjunto de datos kid.weights del paquete UsingR. Seleccionamos a los mayores de 4 años (48 meses). Creamos las variables alt, con la altura de los niños y peso,con su peso. Empezamos estudiando el caso de la recta. library(&quot;UsingR&quot;) #Mayores de 4 años KW4 = kid.weights[kid.weights$age &gt;=48,] peso = KW4$weight*0.454 alt = KW4$height*2.54 PA = lm(peso~alt) plot(alt, peso, xlab = &quot;altura (cm)&quot;, ylab = &quot;peso (Kg)&quot;) abline(PA, col = &quot;red&quot;) Veamos los datos estadísticos que obtenemos haciendo un summary() sobre el resultado de la regresión: summary(PA) ## ## Call: ## lm(formula = peso ~ alt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.419 -5.647 -2.094 1.685 29.852 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -14.84722 4.67785 -3.174 0.00198 ** ## alt 0.35430 0.03946 8.980 1.27e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.979 on 104 degrees of freedom ## Multiple R-squared: 0.4367, Adjusted R-squared: 0.4313 ## F-statistic: 80.63 on 1 and 104 DF, p-value: 1.272e-14 Lo que nos preocupaba cuando hicimos el estudio en el apartado anterior es que no parecía que hubiera una correlación excesivamente grande. Si esto era así, la predicción del peso a partir de la altura iba a ser bastante pobre. Si miramos el coeficiente de correlación \\(R^{2}\\) vemos que es sólo 0,43. Es decir, solo el 43% de la altura queda explicado por la recta. El sexo, constitución, etc. explica la mayor parte. Si usamos una recta, los pronósticos van a ser poco menos que inútiles. Si añadíamos un término cuadrático el gráfico parecía mejor. PAQ = lm(peso ~ alt + I(alt^2)) plot(alt, peso, xlab = &quot;altura (cm)&quot;, ylab = &quot;peso (Kg)&quot;) curve(PAQ[[1]][1] + PAQ[[1]][2]*x + PAQ[[1]][3]*x^2, add = TRUE, col = &quot;blue&quot;) Repetimos el estudio estadístico para ver la mejoría que obtenemos. summary(PAQ) ## ## Call: ## lm(formula = peso ~ alt + I(alt^2)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.870 -4.699 -1.440 1.654 30.212 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 67.602259 18.122691 3.730 0.000313 *** ## alt -1.105931 0.314006 -3.522 0.000640 *** ## I(alt^2) 0.006235 0.001332 4.681 8.72e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.193 on 103 degrees of freedom ## Multiple R-squared: 0.5355, Adjusted R-squared: 0.5265 ## F-statistic: 59.38 on 2 and 103 DF, p-value: &lt; 2.2e-16 El coeficiente de correlación ha subido, pero poco, sólo hasta 0,53. No va a ser un buen pronosticador, pues la mitad de la variación viene de cosas que no medimos. La complicación y el coste de medir la altura parece innecesario: el método más simple y de contar el número de pasajeros y multiplicarlo por el peso medio tiene pinta de ser similarmente bueno. Pero lo que es interesante de esta salida de R es que por primera vez el p-valor del final no coincide con ninguno de los p-valores de los coeficientes de los términos, y además es menor que todos ellos. Esto nos da una pista de qué significa este último p-valor. El p-valor de cada término se obtiene de la hipótesis nula H0: el valor de ese término es 0. El p-valor del final se obtiene de la hipótesis nula H0: todos los términos (menos el Intercept) son 0. 14.2.6 La regresión no muestra qué tipo de curva es En este ejemplo de la montaña rusa hemos estado probando diferentes curvas. En el fondo sabemos que el peso de los niños no está relacionado con su altura mediante una función determinada y unas perturbaciones. La función seguramente no existe. Simplemente estamos buscando maneras de hacer unas predicciones que funcionen “suficientemente bien”. Es un método empírico, sobre los datos y no sobre principio biológico o anatómico alguno. Un error que mucha gente comete es pensar que puedo utilizar los resultados estadísticos, en particular el coeficiente de correlación \\(R^{2}\\), para establecer qué tipo de curva es la que siguen unos datos. Ya dijimos en el documento anterior, que la curva es algo que mete en el modelo el usuario. El ordenador sólo hace los cálculos que se le ordenan. Nunca puede salir nada que no le hayamos metido nosotros antes: si por ejemplo la curva es \\(y = a + b^{\\log x}\\) y no la metemos nosotros, nunca va a poder salir. Si la curva existe, debe determinarse mediante principios científicos y no estadísticos. Para ilustrarlo, volvamos al ejemplo de la ley de Ohm. Ya tenemos la recta de regresión. Vamos a hacer la regresión ahora sobre una función nueva: la suma de una cuadrática y una cúbica. Creamos una muestra aleatoria y calculamos la regresión: set.seed(127) V = c(3.0, 5.0, 7.0, 9.0, 11.0, 14.0, 17.0, 20.0, 25.0, 30.0) I = (1/110)*V+rnorm(length(V), 0, 1.5/110) I = 1000*I #en mA RD = lm(I~I(V^2) + I(V^3)) summary(RD) ## ## Call: ## lm(formula = I ~ I(V^2) + I(V^3)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.2234 -8.2399 0.9995 7.1422 16.4610 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 26.131339 7.683910 3.401 0.011430 * ## I(V^2) 0.739575 0.085330 8.667 5.45e-05 *** ## I(V^3) -0.015704 0.002847 -5.516 0.000892 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.54 on 7 degrees of freedom ## Multiple R-squared: 0.9831, Adjusted R-squared: 0.9783 ## F-statistic: 203.5 on 2 and 7 DF, p-value: 6.286e-07 Obtenemos un coeficiente de correlación \\(R^{2}\\) de 0.98, casi igual de bueno. Quizá piensen que el coeficiente de 0,98 sigue siendo inferior al 0,99 de la recta y por lo tanto la recta es la mejor curva de las dos. Pero este coeficiente de correlación es el de esta muestra concreta, con otras, sale distinto. Prueben con unas cuantas. No les será difícil encontrar una en la que el coeficiente de correlación de la curva cuadrática mas cúbica sea mayor que el de la recta. Consideren que el coeficiente de correlación \\(R^{2}\\), al ser diferente para cada muestra, también tiene su intervalo de confianza, y que por la tanto uno de 0,98 y otro de 0,99 son indistinguibles. Se determina qué curva debemos usar por leyes naturales, sean físicas, químicas, sociológicas… Hemos de determinar primero cuál es el tipo de curva que vamos a usar. Después, la regresión lineal nos ayuda a establecer los parámetros que tiene, por ejemplo la ordenada en el origen y la pendiente, en el caso de una recta. Nada más. 14.2.7 Resumen de la parte de estadística Dada una muestra y un tipo de curva, calcular cuál es la curva concreta que mejor se ajusta a los puntos de la muestra es un problema de cálculo. Pero dado que cada muestra es diferente, determinar qué se puede decir de las características de la curva de toda la población a partir de las de una muestra es un problema de estadística. Si los residuos cumplen las siguientes características Son independientes, Se conforman a una distribución normal de media 0 y desviación típica \\(\\sigma\\), Esta desviación típica es constante, podemos calcular intervalos de confianza de los parámetros de la curva, p-valores para establecer si algún parámetro es 0, el coeficiente de correlación \\(R^{2}\\), que nos indica qué porcentaje del valor de la variable dependiente puede asignarse a variaciones de la independiente, y un p-valor general que nos da información sobre si la variable dependiente es o no una función de la independiente. Nótese que no ponemos ninguna restricción sobre las características de las dos variables numéricas. La regresión lineal puede usarse siempre para cualquier par de variables (si se cumplen las condiciones sobre los residuos, claro está). Esto no quiere decir que no tengamos que ir con cuidado al valorar los resultados, sobre todo si hay algún valor atípico. Establecer si se cumplen las condiciones sobre los residuos no es trivial, pero por suerte R nos da herramientas que podemos usar. Lo veremos en el siguiente apartado. 14.3 Diagnóstico En todas las pruebas estadísticas hay algunas condiciones que deben cumplirse: en un t-test los datos deben seguir una distribución normal, en un prop-test el valor de \\(\\hat{\\theta}\\) no puede ser cercano a 0 o 1, etc. Cuánto más cerca estemos de cumplirlas —nunca se cumplen del todo— más cercanos son los cálculos a lo que teóricamente representan: por ejemplo más cercano está el intervalo de confianza real al que ha salido de nuestros cálculos. Como toda prueba, la regresión lineal también tiene sus condiciones que deben cumplirse y que vimos en el documento anterior. Pero es más difícil ver si se cumplen o no, pues a diferencia de las pruebas vistas hasta ahora, las condiciones no son directamente sobre los datos si no sobre los residuos. Y es mucho más fácil evaluar los datos, que podemos ver, que no los residuos, que no son directamente visibles. Por suerte R aporta herramientas que permite diagnosticar si se cumplen las condiciones sobre los residuos y así poder valorar la fiabilidad de los cálculos. En este documento vamos a estudiar cuáles son estas herramientas y cómo usarlas. 14.3.1 Seis modelos Usaremos seis ejemplos para estudiar las herramientas. Algunos ejemplos nos permitirán ver cómo se cumplen las condiciones y otros, cómo no se cumplen. Varios ejemplos son fabricados. Esto lo hacemos con fines pedagógicos, pues en muchos ejemplos reales las cosas ni se cumplen del todo ni se dejan de cumplir y es mucho más fácil crear de cero un ejemplo dónde se vea con claridad una cuestión que buscar un ejemplo real donde se vea igual de bien. Pero los efectos mostrados no son irreales, son solamente un poco más claros. En todos los ejemplos se muestra el código que se ha usado para la fabricación o de dónde se han obtenido los datos. Esto permitirá al lector ampliar su experiencia, estudiándolos a fondo. Nótese que en donde se usen números aleatorios, se obtendrán valores un poco diferentes a los que se muestran aquí, pero que no cambian la esencia de lo que se explica. Ley de Ohm Nuestro primer modelo ya ha aparecido en documentos anteriores. Tenemos una resistencia al que se le aplica un voltaje y se mide la intensidad. La variable independiente es el voltaje y la variable dependiente es la intensidad. Este es un ejemplo fabricado usando el código siguiente: V = (1:70)/2 Ie = (100/11)*V I1 = Ie+rnorm(length(V), 0, 1500/110) I1[I1 &lt; 0] = 5 # No queremos intensidades negativas… RL1 = lm(I1~V) La gráfica de los datos con la regresión es: plot(V,I1, xlab =&quot;V (voltios)&quot;, ylab = &quot;I (mA)&quot;, main = &quot;Voltaje e Intensidad&quot;) abline(RL1, col = &quot;blue&quot;) Este es un ejemplo ideal, que cumple completamente las condiciones sobre los residuos. Ley de Ohm con valor atípico Este ejemplo es el mismo que el anterior, sólo que se ha añadido un punto más, con un valor atípico, con una intensidad del doble de lo que debería ser. Es sólo un punto de 70 y sobre la gráfica no parece que haya cambiado mucho la recta. El código usado es: Vout = c(V, 36) Iout = c(I1, 700) RLout = lm(Iout ~Vout) plot(Vout,Iout, xlab =&quot;V (voltios)&quot;, ylab = &quot;I (mA)&quot;, main = &quot;Ley de Ohm (v.a.)&quot;) abline(RLout, col = &quot;blue&quot;) Altura y peso de niños Este modelo también ha sido usado en documentos anteriores: miramos el peso de niños en función de su altura. Usamos un modelo lineal. El código y la gráfica son las siguientes: library(UsingR) KW4 = kid.weights[kid.weights$age &gt;=48,] peso = KW4$weight*0.454 alt = KW4$height*2.54 PA = lm(peso~alt) plot(alt, peso, xlab = &quot;Altura (cm)&quot;, ylab = &quot;Peso (Kg)&quot;, main = &quot;Altura y peso de niños&quot;) abline(PA, col = &quot;blue&quot;) Modelos de resistencia aerodinámica Este ejemplo también ha sido usado al explicar el cálculo de curvas de regresión. Tenemos el valor de la resistencia aerodinámica de un objeto en movimiento respecto al aire. Creamos la función a partir de la superficie frontal \\(S\\), la densidad del aire \\(\\rho\\) y el coeficiente de penetración aerodinámica \\(C_{x}\\). Como en el caso de la resistencia, las condiciones sobre los residuos se cumplen perfectamente. Aunque sabemos, por las leyes físicas, que esta fuerza varía con el cuadrado de la velocidad, si sólo miramos los puntos, puede parecer que es una función lineal. Por lo tanto vamos a usar dos modelos: uno lineal y otro cuadrático. Será interesante ver el diagnóstico del caso lineal. El código usado es: rho = 1.225 S = 1.97 Vel = 15:42 Cx = 0.29 RA = 0.5*S*rho*Cx * Vel^2 + rnorm(length(Vel), 0, 25) RALin = lm(RA~Vel) RAq = lm(RA~I(Vel^2)) Y las gráficas resultantes son plot(Vel, RA, main = &quot;Resistencia aerodinámica (lineal)&quot;, xlab = &quot;Velocidad (m/s)&quot;, ylab = &quot;Res. Aero. (Nw)&quot;) abline(RALin, col = &quot;blue&quot;) plot(Vel, RA, main = &quot;Resistencia aerodinámica (cuadrático)&quot;, xlab = &quot;Velocidad (m/s)&quot;, ylab = &quot;Res. Aero. (Nw)&quot;) curve(RAq[[1]][1] + RAq[[1]][2]*x^2, add = TRUE, col = &quot;blue&quot;) 14.3.1.1 Tamaño y potencia de coches En este ejemplo vamos a correlacionar el tamaño de un coche con la potencia de su motor. En buena lógica un coche grande necesita un motor potente. Y a menudo los coches pequeños tiene motores también pequeños. Pero esto es la regla general y por ejemplo los coches deportivos no suelen ser muy grandes pero sí suelen ser potentes, y hay coches grandes con motores relativamente pequeños, por lo que esperamos que lo correlación no sea muy alta. Los datos provienen del conjunto de datos Cars93, del paquete MASS. Como indicador del tamaño cogemos la longitud del coche: es algo mucho mas variable que la anchura y esperamos que sea un buen indicador. Suponemos que la relación longitud-potencia sea lineal. El código usado y la gráfica resultante son: library(MASS) Longitud = Cars93$Length*2.54 C93 = lm(Cars93$Horsepower ~ Longitud) plot(Cars93$Horsepower ~ Longitud, xlab = &quot;Longitud (cm)&quot;, ylab = &quot;Potencia (CV)&quot;, main = &quot;Longitud y potencia de coches&quot;) abline(C93, col = &quot;blue&quot;) 14.3.1.2 Estima de longitudes{-}} En este último ejemplo tenemos objetos con una determinada longitud y pedimos a personas que, sin medirlo, estimen la longitud del objeto. Los datos son fabricados. Es un caso habitual en el que la desviación típica no es constante: en un objeto de 10 cm no te vas a equivocar más allá de unos pocos milímetros, mientras que en un objeto de varios metros es casi imposible ser tan preciso. El código y la gráfica son: Lng = 50 x = 1: Lng y = x for (i in 1:Lng) {sg = y[i]/5 y[i] = y[i] + rnorm(1,0, sg)} plot(x,y, main = &quot;Longitud real y estimada&quot;, xlab = &quot;Longitud real&quot;, ylab = &quot;Longitud estimada&quot;) Inv = lm(y~x) abline(Inv, col = &quot;blue&quot;) Usaremos las herramientas de diagnóstico sobre estos seis modelos. En algunos casos se cumplirán las condiciones y en otras no. Esto nos ayudará a entender cómo podemos establecer la bondad de la regresión que hemos aplicado. 14.3.2 Cinco diagnósticos Una vez tenemos todos los modelos, veamos las cinco herramientas de diagnóstico: la primera nos permitirá determinar si el tipo de curva que hemos escogido para la regresión es adecuado, las tres siguientes son para determinar si se cumplen las condiciones de los residuos, y la última para determinar la influencia de posibles valores atípicos. El orden en el que voy a explicar las pruebas es la que considero más didáctica, pero no es la más adecuada dada la forma en la que R nos presenta la información. En la práctica no tiene mayor importancia el orden en que hagamos estas pruebas. Hay una condición que no se diagnostica con lo que veremos: los residuos deben ser independientes. Esto no es una cuestión estadística sino de procedimiento. Por lo tanto es la manera en que hemos tomado los datos lo que debemos estudiar para saber si se cumple esta condición o no. Vamos a ver las herramientas que tiene R para las demás. 14.3.2.1 ¿Tenemos el tipo de curva correcto? Los diagnósticos se basan sobre todo en cuatro gráficos generados por R sobre el resultado de la regresión. Para verlos, si reg = lm(y ~ x) es la regresión, plot(reg) nos dará las cuatro gráficas de diagnóstico, una por una. Para empezar el diagnóstico vamos a mirar la primera gráfica de diagnóstico que nos presenta R. Como ejemplo, usaremos la regresión de la resistencia aerodinámica. Hemos hecho dos, una lineal y otra cuadrática. Si miramos las gráficas de puntos y la regresión hecha, vemos que ambas parecen adecuadas. Y si miramos los coeficientes de correlación, apenas hay diferencia (0,96 y 0,98). Pero esta primera gráfica de diagnóstico nos va a revelar qué tipo es mejor. En esta gráfica tenemos en el eje X los valores de la variable dependiente, y en el eje Y los valores de los residuos. También tenemos una raya roja que nos da la “media” de los residuos en esa región de valores de la variable dependiente. En el caso de la cuadrática nuestra raya roja es horizontal y cercana al 0. Eso significa que a lo largo de toda la curva los residuos se distribuyen más o menos por igual a ambos lados de la curva propuesta. Que es lo que debiera pasar. En cambio, si miramos el modelo lineal vemos que la curva hace una “onda”: en los valores mayores y menores los residuos son positivos, mientras que en la parte central son negativos. Esto quiere decir que los puntos no se ajustan a nuestra propuesta, una recta en este caso, sino que hacen una curva alrededor de ella. Nuestra propuesta de una recta no es adecuada. 14.3.2.2 La media de los residuos es 0 Sabemos que los residuos deben seguir una distribución normal de media 0 y desviación tipica \\(\\sigma\\) y que además esta desviación típica deber ser constante a lo largo del rango de los datos. Empecemos por la media 0. La información necesaria la obtenemos del summary() de la regresión. Ejecutando summary(RL1) obtenemos esta información del modelos de la Ley de Ohm. La información relevante está en las primeras líneas: summary(RL1) #Good ## ## Call: ## lm(formula = I1 ~ V) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.736 -9.839 -0.398 9.654 37.875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2.1038 3.2633 -0.645 0.521 ## V 9.2394 0.1598 57.827 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 13.51 on 68 degrees of freedom ## Multiple R-squared: 0.9801, Adjusted R-squared: 0.9798 ## F-statistic: 3344 on 1 and 68 DF, p-value: &lt; 2.2e-16 La primera cosa que nos extraña es que aparezca la mediana y no la media. Esto es porque, dado cómo se calcula la regresión, la media de los residuos siempre es exactamente 0. Lo que queremos ver es si los valores obtenidos se distribuyen simétricamente alrededor del 0 o no. Por eso nos da la mediana, los cuartiles y los valores extremos. Vemos que la mediana es muy pequeña comparada con los cuartiles y los extremos. Además, está mas o menos centrada respecto a los cuartiles. El que no lo esté respecto a los valores extremos no es preocupante, pues basta un residuo muy positivo o negativo para que nos descompense los extremos. Por lo tanto consideramos que en este caso los residuos están adecuadamente centrados alrededor del 0, como deberían. En cambio si hacemos lo mismo con el modelo del tamaño y potencia de los coches obtenemos: summary(C93) #Bad ## ## Call: ## lm(formula = Cars93$Horsepower ~ Longitud) ## ## Residuals: ## Min 1Q Median 3Q Max ## -63.061 -29.691 -7.376 10.527 164.479 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -218.1449 57.6695 -3.783 0.000277 *** ## Longitud 0.7779 0.1235 6.296 1.06e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 43.95 on 91 degrees of freedom ## Multiple R-squared: 0.3035, Adjusted R-squared: 0.2958 ## F-statistic: 39.64 on 1 and 91 DF, p-value: 1.058e-08 Vemos que la mediana es relativamente grande, por ejemplo comparado con los valores de los cuartiles y que además está todo desplazado hacia valores negativos. Estos residuos no están centrados alrededor del 0. Si hiciera falta un estudio más a fondo, se podrían extraer los residuos (C93\\$residuals en este ejemplo) y dibujar el diagrama de cajas y el histograma sobre ellos. No se puede hacer un t-test, pues, como hemos dicho, la media es siempre exactamente 0 y el t-test no nos diría nada. Pero en general con la información dada en el summary() nos basta. 14.3.2.3 Los residuos siguen una distribución normal La que nos indica lo bien o mal que los residuos siguen la distribución normal es la segunda de las gráficas de diagnóstico. Es el ya conocido qqnorm(). En el modelo de la resistencia aerodinámica cuadrática creamos los residuos con rnorm(), por lo tanto siguen una distribución normal. Su gráfica es: En cambio el modelo de los niños se desvía bastante: En estos casos teníamos 28 datos en el caso de la resistencia aerodinámica y más de 100 en el caso de los niños. Son suficientes para que esta gráfica nos sea útil. Pero si tenemos una regresión sobre una docena o menos datos, puede muy bien no ser posible establecer, ni con esta prueba ni con ninguna, si los datos siguen una distribución normal o no. En casos de muy pocos datos, normalmente damos el beneficio de la duda y los consideramos normales. 14.3.2.4 La desviación típica es constante La distribución no sólo debe ser normal, sino que la desvación típica debe ser constante. Esto lo vemos en la tercera de las gráficas de diagnóstico. En esta gráfica tenemos en el eje horizontal los valores de la variable dependiente mientras que en el eje vertical tenemos los residuos estandarizados (no importa lo que son). Lo importante es la linea roja que nos indica como varía la “media” de los residuos estandarizados con los valores de la variable dependiente. Si lo miramos en la regresión de la Ley de Ohm, que sabemos que es ideal, vemos que esta linea roja es horizontal y que los puntos están distribuidos de una forma más o menos homogénea alrededor de esta linea. Luego la condición desesada se cumple. Mientras que si lo miramos en el modelo de la estima de longitudes, vemos que la linea sigue una clara pendiente a lo largo de todo su recorrido, indicando que la desviación típica va aumentando con la longitud estimada. La condición no se cumple: 14.3.2.5 La influencia de los valores atípicos La cuarta gráfica de diagnóstico nos muestra la influencia de los valores atípicos sobre los parámetros. A veces el valor atípico se ve claramente, pero otras veces tenemos valores atípicos que no son obvios y los descubrimos en esta cuarta gráfica. En este caso no importa tanto la raya roja, sino las lineas de puntos que representan la distancia de Cook: cuánto mayor es la distancia de Cook de un punto, más influencia tiene en los parámetros de la curva. En el caso de una recta, en la pendiente. En el caso de la resistencia aerodinámica cuadrática, sabemos que los residuos provienen de una normal y además no se apreciaba ningún valor muy alejado de al curva. La cuarta gráfica de diagnóstico nos confirma esto: Casi todos los puntos están centrados y apenas hay alguno que se acerque a la linea de la distancia de Cook de 0,5. Como ejemplo donde hay un obvio valor atípico cogemos la ley de Ohm en donde hemos introducido uno a propósito. Claramente estaba muy alejado de la recta, pero no parecía que la pendiente hubiera cambiado mucho. Pero si miramos esta cuarta gráfica, vemos que hay un punto, nuestro valor atípico, que tiene una distancia de Cook muy superior a 1 y que por lo tanto influye mucho más que los demás en la pendiente de la recta. 14.3.2.6 Diagnóstico más detallado Estas cinco pruebas de diagnóstico nos permiten valorar si hemos escogido el tipo de curva correcto, si se cumplen las condiciones sobre los residuos y si hay algún valor atípico que influye en exceso sobre los parámetros. A menudo, sobre todo en el caso de experimentos que no son de laboratorio y no siguen una ley natural, tenemos dudas en al menos una de estas pruebas. No es raro que lo que haga “fallar” la prueba sean sólo uno o dos puntos y entonces nos gustaría mirarlos más a fondo y posiblemente repetir la regresión sin esos puntos fastidiosos. Para ayudarnos en esta profundización del diagnóstico en los cuatro gráficos se añade el índice junto a los puntos que pueden ser más problemáticos. Por ejemplo, si miramos al caso del valor atípico, vemos que el punto que tiene una distancia de Cook tan elevada es el punto de índice 71. Ese sería nuestro valor atípico y sabiendo el índice es ahora inmediato identificarlo en nuestros datos. Fíjense que siempre nos da los puntos más problemáticos: incluso si todo es ideal, nos indica dos o tres índices por si queremos estudiarlos mas a fondo. Por eso, el que aparezca un número en una gráfica no es preocupante. Pero si los mismos numeros aparecen una y otra vez, conviene dedicarles nuestra atención. 14.3.3 Resumen de diagnóstico Al ser condiciones sobre los residuos, no es fácil hacer un diagnóstico para valorar la bondad de una regresión lineal. Por suerte R nos proporciona información de los residuos y cuatro gráficos que nos ayudan a determinar si el tipo de curva que hemos escogido para la regresión es razonable, si los residuos siguen una distribución normal de media 0 y desviación típica \\(\\sigma\\), si esta desviación típica es constante y si tenemos valores atípicos que nos influyen mucho en el valor de los parámetros. Con esta información es posible valorar, sin demasiada dificultad, la problematicidad de los datos de partida y asignar una fiabilidad a los datos obtenidos en nuestros cálculos. 14.4 Inferencias Ya hemos visto que la función lm() viene con sus t-test incorporados para saber si los coeficientes son 0 y mediante la función confint() podemos obtener los intervalos de confianza de estos coeficientes. Pero quizá el valor 0 de los coeficientes no es el que más nos interese. Podemos querer saber, quizá, si el precio de la gasolina está creciendo más rapido que la inflación, o si lo está haciendo más rápido que el diesel. Con la información que obtenemos de R podemos crearnos nuestros propios constrastes de hipotesis e intervalos de confianza para averiguar lo que nosotros queremos. Lo primero que vamos a ver en este apartado es cómo hacerlo. 14.4.1 Contrastes de hipótesis Sabemos que cuantas más cervezas consumimos mayor será nuestra Tasa de Alcohol en Sangre (TAS). Quremos saber a qué ritmo crece el TAS con el consumo de cervezas. Tenemos 10 individuos que están completamente sobrios. Tras tomar unas cuantas (o muchas) cervezas medimos su tasa de alcohol en sangre. Obtenemos estos datos experimentales: Cervezas 5 2 9 8 3 7 3 5 3 5 TAS 0.10 0.03 0.19 0.12 0.04 0.095 0.07 0.06 0.02 0.05 Si dibujamos los puntos y hacemos la regresión lineal de la TAS en función de las cervezas consumidas, suponiendo una recta, obtenemos la siguiente gráfica: Cervezas = c(5, 2, 9, 8, 3, 7, 3, 5, 3, 5) TAS = c(0.10, 0.03, 0.19, 0.12, 0.04, 0.095, 0.07, 0.06, 0.02, 0.05) Alc = lm(TAS~Cervezas) plot(TAS~Cervezas, xlab = &quot;Núm. Cervezas&quot;, ylab = &quot;Tasa Alcohol en Sangre&quot;, main = &quot;Tasa de alcohol en sangre al beber cerveza&quot;) abline(Alc, col = &quot;blue&quot;) Si hacen el diagnóstico verán que no es maravilloso, pero suficiente para este ejemplo. El salida (parcial) del summary() de la regresión es: &gt; summary(Alc) Call: lm(formula = TAS ~ Cervezas) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.018500 0.019230 -0.962 0.364200 Cervezas 0.019200 0.003511 5.469 0.000595 Residual standard error: 0.02483 on 8 degrees of freedom Multiple R-squared: 0.789, Adjusted R-squared: 0.7626 El p-valor de la pendiente es 0,000595. Recordamos que la hipótesis nula es H0: el coeficiente es 0. Vamos a ver que efectivamente es un t-test. Recordemos que \\[ t = \\frac{\\hat{\\mu} - \\mu_{0}}{\\mbox{se}}\\] En este caso tenemos que \\(\\hat{\\mu}\\) es la pendiente y nos dan el error estándar. Luego: \\[ t = \\frac{\\hat{\\mu} - \\mu_{0}}{\\mbox{se}} = \\frac{0.0192 - 0}{0.0035} = 5.469\\] Lo que coincide con lo mostrado por el summary(). Pero el que el consumo de alcohol sube el TAS es obvio y no nos interesa este contraste de hipótesis. Lo que queremos saber es cuánto sube por cada cerveza. Digamos que en este caso lo que queremos es el contraste de hipótesis con la hipótesis nula que cada cerveza adicional nos sube la tasa de alcohol en 0,02 y con la hipótesis alternativa de que es menos. Simplemente hemos de calcular el nuevo valor del estadístico \\(t\\) con el nuevo valor de \\(\\mu_{0} = 0.02\\): \\[ t_2 = \\frac{0.0192 - 0.02}{0.0035} = -0.0322\\] Y con este nuevo valor del estadístico hemos de calcular el nuevo p-valor. Como sabemos por la salida del summary() que hay 8 grados de libertad, y que la hipótesis alternativa es que es menor, entonces ejecutamos pt(t2, df = 8) y obtenemos un p-valor de 0.488. Nos quedamos con la hipótesis nula de que cada cerveza nos aumenta la TAS en 0,02. 14.4.2 Intervalos de confianza Usamos el conocido conjunto de datos Cars93, del paquete MASS. Nos interesa saber si la relación peso-potencia de los coches de tipo pequeño (Small) es la misma que la de los deportivos (Sporty). El escogemos los coches de cada tipo, pasamos los pesos a Kg, dibujamos los puntos en azul para los deportivos y en rojo para los pequeños, calculamos las regresiones y añadimos las rectas: PotSpor = Cars93[Cars93$Type == &quot;Sporty&quot;, &quot;Horsepower&quot;] PesoSpor = Cars93[Cars93$Type == &quot;Sporty&quot;, &quot;Weight&quot;]*0.454 PotPeq = Cars93[Cars93$Type == &quot;Small&quot;, &quot;Horsepower&quot;] PesoPeq = Cars93[Cars93$Type == &quot;Small&quot;, &quot;Weight&quot;]*0.454 xl = c(min(c(PesoPeq,PesoSpor)), max(c(PesoPeq,PesoSpor))) yl = c(min(c(PotPeq,PotSpor)), max(c(PotPeq,PotSpor))) plot(PesoSpor, PotSpor, xlim = xl, ylim = yl, xlab = &quot;Peso (Kg)&quot;, ylab = &quot;Potencia (CV)&quot;, col = &quot;blue&quot;, main = &quot;Cars 93: deportivos y pequeños&quot;) points(PesoPeq, PotPeq, col = &quot;red&quot;) PPS = lm(PotSpor~PesoSpor) abline(PPS, col = &quot;blue&quot;) PPP = lm(PotPeq~PesoPeq) abline(PPP, col = &quot;red&quot;) Vemos que los coches deportivos, como era de esperar, tienen una relación peso-potencia menor: añaden más caballos por cada Kg de peso adicional. Queremos calcular el intervalo de confianza de a diferencia de esta relación, es decir, de la diferencia de las pendientes. No podemos hacerlo exactamente, pero sí aproximadamente: sabemos los errores estándar y las pendientes, luego podemos aproximar el error estándar de la diferencia como la raíz cuadrada de la suma de los cuadrados, y a partir de aquí ya es simple. En el código que se muestra a continuación se ve cómo conseguir los errores estándar y las pendientes directamente y sin tener que copiarlas de la pantalla: # Los errores estándar: sePPS = summary(PPS)$coefficients[2, 2] sePPP = summary(PPP)$coefficients[2, 2] # Las pendientes: pendPPS = PPS$coefficients[2] pendPPP = PPP$coefficients[2] # El error estándar de la diferencia sedif = sqrt(sePPS^2 + sePPP^2) # Y ya el IC: f = qt(0.975, df = 12) ICdif = (pendPPS - pendPPP) + c(-1,1)*f*sedif ICdif ## [1] 0.02439861 0.33972367 Obtenemos un ICdif = [0,024; 0,400]. Es decir que un coche deportivo tiene entre 0,02 y 0,4 CV adicionales por Kg de peso respecto a los pequeños. 14.5 Predicciones El objetivo final de la estadística es casi siempre poder hacer predicciones. Como ya hemos visto, la regresión lineal es mucho más compleja que un t-test o un \\(\\chi^{2}\\) y hacer predicciones va a ser más difícil. Es intuitivo que si los puntos están cerca de la curva de regresión que estamos estudiando, es decir si el coeficiente de regresión \\(R^{2}\\) es alto, la incertidumbre es baja. Pero si el coeficiente es bajo, la incertidumbre es mayor. Usando ejemplos de documentos anteriores, si queremos predecir la intensidad que pasa por nuestra resistencia a partir del voltaje, tenemos poca incertidumbre y el rango de valores psoibles es estrecho; en cambio si queremos predecir el peso de un niño en función de su altura, el rango será mucho mayor. En general, si queremos predecir el valor de la variable dependiente en función de la independiente vamos a tener que tener en cuenta no sólo el valor de la curva, sino al menos también el coeficiente \\(R^{2}\\). Los cálculos son complejos, pero los ordenadores acuden a nuestra ayuda. La función predict() nos va a ayudar a predecir rangos de valores de nuestra variable dependiente a partir de la independiente. El ejemplo de base será la distancia de frenadas de coches. Usaremos el conjunto de datos cars, con velocidades y distancias de frenado de coches en los años 20 (por eso las velocidades son tan bajas). Lo primero que haremos es pasar las distancias a metros y las velocidades a Km/h. Después dibujaremos los puntos y calcularemos y dibujaremos la recta de regresión. velocidad = cars$speed*1.609 distancia = cars$dist*0.305 DS = lm(distancia~velocidad) DS ## ## Call: ## lm(formula = distancia ~ velocidad) ## ## Coefficients: ## (Intercept) velocidad ## -5.3616 0.7454 Los coeficientes son \\(-5.36\\) para la ordenada en el origen y \\(0.745\\) para la pendiente. Es decir, la recta de regresión es \\(\\mbox{distancia} = -5,36 + 0,745 \\cdot \\mbox{velocidad}\\). La gráfica resultante es: #La regresión suponiendo una recta plot(velocidad, distancia, xlab = &quot;Velocidad (Km/h)&quot;, ylab = &quot;Distancia (m)&quot;, main = &quot;Distancias de frenado&quot;) abline(DS, col = &quot;blue&quot;) Antes de hacer las predicciones, vamos a diagnosticar la bondad de la regresión. Juntamos las 4 gráficas en una usando par(mfrow = c(2,2)): par(mfrow = c(2,2)) plot(DS) par(mfrow = c(1,1)) Vemos en la gráfica resultante que la regresión no es nada problemática. Pasemos pues a hacer predicciones. 14.5.1 Predicción de la curva La función predict() tiene 3 parámetros. El primero es el resultado de la regresión; en el segundo tenemos los valores de la variable independiente sobre los que queremos hacer la predicción; y el tercero es el tipo de predicción. El segundo parámetro tiene una forma particular: debe ser un data frame con tantas filas y columnas como queramos pero una de las columnas debe llamarse exactamente igual que la variable independiente. Es de esa columna de la que extraerá los valores sobre las que hacer la predicción. No ajustarse a este formato es causa de muchos errores. Dos errores bastante frecuentes son dar un vector de valores en vez de un data frame y que la columna del data frame tenga un nombre que no es igual al de la variable independiente. Si la función les da error, asegúrense que no han cometido ninguno de estos dos errores. Hemos dicho que hay varios tipos de predicción. El primer tipo nos devuelve los valores de la curva para los valores que le demos. Si lo que tenemos es una recta, es una forma un tanto complicada de hacerlo, pero si es una curva compleja, puede ser más conveniente. Es el tipo de predicción por defecto y por lo tanto no necesitamos el tercer parámetro. # Predicciones: velocidades de 7 a 40 de 3 en 3 new = data.frame(velocidad = seq(7, 40, 3)) predict(DS, new) ## 1 2 3 4 5 6 7 8 ## -0.143667 2.092600 4.328868 6.565135 8.801402 11.037669 13.273937 15.510204 ## 9 10 11 12 ## 17.746471 19.982738 22.219006 24.455273 Es fácil comprobar que estos datos son, efectivamente, los correspondientes a nuestra recta: DS$coefficients[1] + DS$coefficients[2]*seq(7, 40, 3) ## [1] -0.143667 2.092600 4.328868 6.565135 8.801402 11.037669 13.273937 ## [8] 15.510204 17.746471 19.982738 22.219006 24.455273 14.5.2 Predicción de rango El segundo tipo de predicción es mucho más interesante. Queremos saber el rango de las distancias de frenado para un coche que vaya a una determinada velocidad. Hemos de añadir a la función predict() el parámetro interval = &quot;prediction&quot;. Vamos a usar el mismo data frame que antes. Los resultados son: # Para cada velocidad, rango de posibles distancias de frenado predInt = predict(DS, new, interval = &quot;prediction&quot;) round(predInt, 2) ## fit lwr upr ## 1 -0.14 -10.08 9.79 ## 2 2.09 -7.72 11.90 ## 3 4.33 -5.38 14.04 ## 4 6.57 -3.06 16.19 ## 5 8.80 -0.77 18.37 ## 6 11.04 1.50 20.57 ## 7 13.27 3.75 22.80 ## 8 15.51 5.97 25.05 ## 9 17.75 8.17 27.32 ## 10 19.98 10.35 29.62 ## 11 22.22 12.50 31.94 ## 12 24.46 14.63 34.28 La primera columna nos da el valor de la curva, lo que habíamos obtenido antes. Las otras dos, los extremos inferior y superior del rango. Por ejemplo, para el tercer valor que hemos dado en el data frame (13 Km/h), el valor sobre la curva es 4,33 m, y predecimos que la distancia de frenado para un coche que vaya a 13 Km/h está entre \\(-5,38\\) m y \\(14,04\\)~m. Evidentemente, el valor negativo es absurdo, pero eso R no lo sabe. Con el décimo valor del data frame, predecimos para un coche que vaya a 34 Km/h, una distancia de frenado de entre \\(10,35\\) m y \\(29,62\\) m. Recordemos que estas predicciones se obtienen con nuestro conjunto de datos de partida. Con otro conjunto diferente obtendríamos una recta diferente y unas predicciones distintas. 14.5.3 Predicción de medias El tercer tipo de predicción es el del valor medio. Para nuestro ejemplo, en nuestro ejemplo, la distancia media de frenado de coches que vayan a las velocidades que hemos indicado. En este caso el valor del tercer parámetros es interval = &quot;confidence&quot;. La salida de la función es: # Para cada velocidad, rango de distancias de frenado medias predMed = predict(DS, new, interval = &quot;confidence&quot;) round(predMed, 2) ## fit lwr upr ## 1 -0.14 -3.26 2.97 ## 2 2.09 -0.60 4.79 ## 3 4.33 2.04 6.62 ## 4 6.57 4.64 8.49 ## 5 8.80 7.18 10.42 ## 6 11.04 9.63 12.44 ## 7 13.27 11.94 14.61 ## 8 15.51 14.08 16.94 ## 9 17.75 16.09 19.40 ## 10 19.98 18.00 21.96 ## 11 22.22 19.87 24.57 ## 12 24.46 21.70 27.21 A partir de estos datos podemos predecir que un coche que vaya a 22 Km/h (sexta fila), de media necesitará entre 9,63 m y 12,44 m para frenar y que un coche que vaya a 40 Km/h (última fila), de media necesitará entre 21,70 m y 27,21 m para frenar. Podemos dibujar estas predicciones en nuestra nube de puntos. De paso veremos cómo dibujar lineas a trazos. Usaremos lineas azules para los intervalos de las medias y rojas para las del rango. El código es: plot(velocidad, distancia, xlab = &quot;Velocidad (Km/h)&quot;, ylab = &quot;Distancia (m)&quot;, main = &quot;Distancias de frenado&quot;) abline(DS) lines(new$velocidad, predInt[,2], lty = 2, col = &quot;red&quot;) lines(new$velocidad, predInt[,3], lty = 2, col = &quot;red&quot;) lines(new$velocidad, predMed[,2], lty = 2, col = &quot;blue&quot;) lines(new$velocidad, predMed[,3], lty = 2, col = &quot;blue&quot;) Vemos que en los extremos los rangos son mayores que en el centro. Eso es debido a que cuantos más puntos cercanos haya menos incertidumbre tengo. En el centro tengo más puntos cercanos, los tengo por ambos lados, mientras que en los extremos tengo menos, sólo por un lado. 14.5.4 Resumen de predicciones Aunque R nos dé unos contrastes de hipótesis y unos intervalos de confianza de los parámetros, nos pueden interesar otros distintos. Con los datos que nos proporciona el summary() de una regresión podemos crear nuestros propios t-test y calcular los p-valores correspondientes. Para los intervalos de confianza no sabemos hacer el cálculo exacto, pero sí podemos calcular con facilidad el error estándar de la diferencia y a partir de ahí aproximar un intervalo de confianza de la diferencia de algún parámetro, de la pendiente, por ejemplo. A partir de mi regresión me interesa predecir no sólo los valores de la curva obtenida sino sobre todo rangos de valores, y un intervalo de confianza de los valores medios para cada posible valor de la variable independiente. No son cálculos sencillos, pero la función predict() nos da estos resultados. Esta función da mucha potencia a la regresión lineal. "],
["problemas.html", "Capítulo 15 Problemas 15.1 ¿Qué es la estadística? 15.2 Manejo de R y simulaciones 15.3 Estadística Descriptiva 15.4 Probabilidad y variables aleatórias 15.5 Razonamiento estadístico. 15.6 Anova 15.7 Ji-cuadrado 15.8 Regresión Lineal 15.9 Problemas con todo 15.10 Campos Elíseos 15.11 Tipos de datos 15.12 Estadística descriptiva", " Capítulo 15 Problemas 15.1 ¿Qué es la estadística? Prob I.1 En grupos de 3 ó 4 personas (ni 2 ni 5) deben crear un breve video (aprox. 5 min.) explicando qué es la estadística para ustedes. Suban el video a YouTube o cualquier otro lugar público.Deben entregar un PDF con el nombre de los integrantes del equipo y la URL del video. Habrá un premio al mejor video. Prob I.2 En el Diario de Mallorca encontramos el titular: “La venta de megachalés en Mallorca se estabiliza con precios de más de cuatro millones” (https://www.diariodemallorca.es/mallorca/2020/02/19/venta-megachales-estabiliza-precios-cuatro/1487500.html). Lean la noticia. En ningún sitio lo indica explícitamente, pero deduzcan razonablemente cuál es la población y cuál es la muestra de esta estadística. Escriban un párrafo, que podría aparecer en la noticia, en donde se indica la población y muestra del estudio. Indiquen también otra muestra diferente que se podría haber escogido para hacer esta estadística. Prob I.3 Está interesado en averiguar el porcentaje de alumnos de la UIB que usa cada biblioteca de la universidad. Idee un experimento estadístico para averiguarlo. Establezca la población, y explique cómo va a obtener una muestra significativa y qué medidas va a tomar. Prob I.4 Lee en un titular de periódico: “El graduado medio de la UIB gana 78 215,31€ al año”. ¿Cuál cree que es la población? Indique una forma razonable por la que se pudo obtener una muestra representativa. Prob I.5 La siguiente gráfica muestra los seísmos registrados en España desde 1985 al 2008. Se ve un destacado incremento. Un posible motivo es que el número de seísmos en España haya crecido en esos años. Pero no es la úica explicación. Indique al menos otras 2 razones que pueden explicar el incremento. Prob I.6 Si queremos obtener datos de una población muy grande tomamos una muestra: unos pocos elementos de la población que esperamos nos permitan obtener un conocimiento adecuado de toda la población. Por ejemplo las encuesta de opinión son de sólo unos cientos o pocos miles de personas, o en un control de calidad se miden sólo unas docenas de productos fabricados cada día. Esto da lugar a la variación de muestreo: si hubiéramos escogido otros elementos, hubiéramos obtenido datos diferentes. Esta es una de las principales fuentes de incertidumbre en estadística. A continuación pueden ver los datos de cuatro muestras en forma de histogramas y diagramas de cajas. En la primera tienen la población completa de la cual obtenemos muestras. Las otras tres son muestras de 40 elementos. Dos están tomadas de la población, y la otra puede estar tomada de la misma población o puede haber sido tomada de otra población diferente. Indique si cree que las 3 están tomadas de la misma población o no, y si no, cuál es la que es de una población diferente. Expliquen su respuesta. Prob I.7 Si queremos obtener datos de una población muy grande tomamos una muestra: unos pocos elementos de la pobación que esperamos nos permitan obtener un conocimiento adecuado de toda la población. Por ejemplo las encuesta de opición son de sólo unos cientos o pocos miles de personas, o en un control de calidad se miden sólo unas docenas de productos fabricados cada día. Esto da lugar a la variación de muestreo: si hubiéramos escogido otros elementos, hubiéramos obtenido datos diferentes. Esta es una de las principales fuentes de incertidumbre en estadística. A continuación pueden ver los datos de cuatro muestras en forma de histogramas y diagramas de cajas. En la primera tienen la población completa de la cual obtenemos muestras. Las otras tres son dos muestras de 40 elementos tomados de esa misma población y otra es una muestra de 40 individuos tomada de otra población diferente. Indiquen cuál de las 3 creen es de la otra población. Expliquen su respuesta. Prob I.8 En todas las universidades españolas se hacen encuestas de satisfacción a los alumnos. En la UIB, como en muchas otras, la encuesta se hace en línea, solicitando a los alumnos que la rellenen en un plazo determinado hacia final de curso. ¿Es esta una buena manera de hacer una encuesta? Debe explicar los defectos del método y proponga formas de mejorarlo. Prob I.9 Quieren establecer si estudiar justo antes de ir a dormir es mejor que estudiar mucho antes de ir a dormir. Digan una buena y mala manera de conseguir una muestra. Expliquen cómo harían un experimento para determinar si la hipótesis del estudio es cierta. Prob I.10 Quieren establecer si el café ayuda a mantenerse alerta en las clases de primera hora de la mañana. Digan una buena y mala manera de conseguir una muestra. Expliquen cómo harían un experimento controlado para determinar si la hipótesis del estudio es cierta. Prob I.11 Explique algún error estadístico enorme que haya aparecido en la prensa. La explicación debe basarse en el curso y ser adecuado para los estudiantes de la asignatura. Puede basarse en informes ya existentes (por ejemplo en la web de Malaprensa), pero es imprescindible que lo “traduzca” a un lenguaje adecuado a la asignatura: si es demasiado coloquial, debe hacerlo más técnico. Si es demasiado técnico, debe rebajarlo (regla de oro: si hay alguna palabra o expresión que no entiende, no la use). Debe entregar un enlace a la noticia o noticias y su explicación. Prob I.12 Nicholas Nassim Taleb es un especialista en finanzas que ha escrito libros sobre probabilidad y estadística. En su cuenta de Twitter, ante la noticia de que un prestigioso financiero francés se iba a mudar a Estados Unidos comentó: “Lo que consigue así es bajar la media en los dos países”. Explique la “mala leche” de este comentario. Prob I.13 Usted coge el transporte hasta la universidad en la Plaza de España y se está preguntando si es más rápido coger el autobús o el metro. Diseñe un experimento para determinar si uno es más rápido que el otro. Debe establecer cuál es la población, cuál es la muestra de su experimento y cómo va a tomar los datos. Prob I.14 Indique la población y la muestra en los siguientes casos: Para saber la incidencia de una enfermedad en España se escoge el hospitales públicos “de referencia” de cada provincia y se cuentan cuántos de los que han ido a urgencias en una semana determinada tienen la enfermedad. Para determinar el peso de las naranjas de un huerto se escogen al azar un día determinado el 100 naranjas de las recogidas ese día. Para saber cuánta basura se genera en Mallorca, se pesa cuánta basura llega al vertedero de Son Reus en 17 días escogidos al azar de los del año. Para establecer el voltaje que entregan las fuentes de alimentación fabricadas, se escogen al azar 5 de cada remesa y se miden. Para determinar la nota de los alumnos de una asignatura, se miran todas las notas obtenidas por los alumnos matriculados un determinado año. Prob I.15 En la recordada serie cómica Yes, minister sobre el funcionamiento de un ministerio británico, se explica cómo conseguir el resultado deseado en una encuesta a base de escribir “astutamente” las preguntas. Miren el clip del video (en inglés: https://www.youtube.com/watch?v=G0ZZJXw4MTA, en catalán https://www.youtube.com/watch?v=6WfGOaxkFBs). Digamos que les encarga una encuesta de opinión sobre si los libros de texto en los colegios e institutos deberían ser gratuitos o no. Escriban dos listas de preguntas, una empujando hacia el sí, y otra empujando hacia el no. Prob I.16 Queremos estudiar la influencia de la dieta en una determinada enfermedad. Para ellos hacemos dos estudios. Para no complicar la explicación supondremos que los estudios son pequeñitos, pero se pueden hacer de tamaño adecuado. Para un estudio se escogen al azar dos pueblos: Vila del mar de abajo y Tira pal monte de arriba. Ambos pueblos tiene el mismo numero de habitantes. En Vila del mar se consumen 10.000 Kg de pescado al año, en Tira pal monte se consumen 3000 Kg de pescado al año. Mirando los historiales de los hospitales locales, en Vila del mar han contraído la enfermedad 450 personas durante el año y en Tira pa arriba lo han contraído 912 personas. Para el otro estudio escogemos al azar 100 personas de cada uno de los pueblos y se divide el consumo de pescado de estas 200 personas entre alto, medio y bajo. Entre los de consumo alto han contraído la enfermedad 21 personas, entre los de consumo medio lo han contraído 17, y entre los de consumo bajo lo han contraído 13. Los dos estudios parece que llegan a resultados que se contradicen. Con una muestra pequeña esto puede pasar, pero repito que simplemente estoy explicando el experimento usando una muestra pequeña: con una muestra suficientemente grande vemos el mismo efecto. Para intentar entender lo que pasa establezcan cuál es la población y la muestra en cada estudio. Aventuren alguna explicación de por qué los resultados son sólo aparentemente contradictorios. Prob I.17 Coja una moneda y tome 3 muestras de 16 lanzamientos. Dibújelos como diagramas de barras (puede usar R, pero no es obligatorio). Repita con 3 muestras de 32 lanzamientos. Coja un dado y tome 3 muestras de 36 lanzamientos. Dibújelos como diagramas de barras. Repita con 3 muestras de 72 lanzamientos. Es importante que no tome muestras de más. No repita porque una “sale mal”. A partir de los diagramas que ha obtenido, ¿cree que es factible determinar la forma del diagrama de una población a partir del de una muestra? Explique bien sus conclusiones (es lo más importante de este ejercicio). 15.2 Manejo de R y simulaciones Prob R.1 Supongamos una línea sobre la que tenemos 2 cargas, una de \\(+10\\) mC en la posición \\(-5\\) metros y otra de \\(-5\\) mC en la posición \\(+ 5\\) metros. Calcule el campo eléctrico creado por estas cargas en la línea que las une desde \\(-15\\) metros a \\(+15\\) metros. Como es costumbre, consideraremos positivo el si el campo está dirigido hacia la derecha. Dibuje la gráfica correspondiente. Debe entregar un fichero PDF con el guión de R y la gráfica obtenida. Prob R.2 Partimos del conjunto de datos samhda del paquete UsingR. Lean el help para saber qué datos hay, los nombres de las variables y la codificación de los niveles. Nos interesan dos variables cualitativas: el curso en el que están los alumnos (grade) y cuánto fuman (amt.smoke). Cree una tabla de contingencia de frecuencias absolutas con estas dos variables. Elimine los “no sabe/no contesta” (nivel 9 en grade y niveles 98 y 99 en amt.smoke). Cambie los nombres de las filas y columnas por algo más inteligible. Cree dos gráficas de barras agrupadas (no apiladas), de frecuencias relativas, una agrupada por curso y otra por cantidad fumada, de manera que cada agrupación sume 1. Use colores y leyenda. Debe mostrar el código de R utilizado y las dos gráficas. Prob R.3 Partimos del conjunto de datos Cars93 del paquete MASS (incluida en la distribución de R). Dibuje en azul el peso del coche (Weight) en función de su longitud (Length) para coches del tipo pequeño (Small). Calcule su recta de regresión y añádala, también en azul. Añada los puntos de los coches de la categoría furgoneta (Van) en rojo. Calcule su recta y añádala (en rojo). Nota: use los parámetros xlim y ylim para indicar los valores máximos y mínimos. Los valores por defecto que escoge R le van a dejar muchos puntos fuera del dibujo. Dibuje la gráfica adecuada (ya sea diagrama de cajas o de puntos) para mostrar la potencia (Horsepower) en función de la tracción (DriveTrain). La tracción puede ser delantera, trasera o a las cuatro ruedas. Considere que el número de cilindros (Cylinders) es una variable cualitativa. Dibuje el diagrama de barras de las frecuencias absolutas del número de cilindros en función del tipo de coche. Use barras agrupadas (no apiladas), agrupadas por número de cilindros y un color diferente por tipo. Elija colores que se contrasten, pero sean agradables. No se olvide de añadir la leyenda. Dibuje el diagrama de barras de las mismas variables, pero ahora con frecuencias relativas, apiladas y agrupadas por tipo y con un color diferente por número de cilindros. Elija colores que se contrasten, pero sean agradables. No se olvide de añadir la leyenda. Debe entregar el guión de R y las gráficas. Prob R.4 Partimos de una baraja. Como no nos importan los palos, lo puede crear en R con la instrucción baraja = rep(1:13, 4). Vamos a calcular la probabilidad de dos casos y simularlo después en R. Primer caso: Calcule la probabilidad de coger dos cartas de la baraja y obtener dos ases. Simule esto con R mil veces y cuente cuántas veces obtiene dos ases ¿Más o menos concuerda? Segundo caso: calcule la probabilidad de obtener dos cartas iguales. Simule esto con R mil veces y cuente cuántas veces obtiene dos ases dos cartas iguales. ¿Más o menos concuerda? Dibuje un diagrama de barras agrupado. Hay dos grupos, uno por caso y en cada grupo hay dos barras, una con el resultado teórico y otra con el de su simulación. Debe entregar sus cálculos,el guión de R, los resultados de su simulación y la gráfica. Prob R.5 Una distribución continua importante en muchos ámbitos es la distribución logística. Depende de 2 parámetros, \\(\\mu\\) y \\(s\\). Su función de densidad es \\[f(x; \\mu, s) = \\frac{e^{-(x-\\mu)/s}}{s(1 + e^{-(x-\\mu)/s})^2}\\] Dibuje en R las funciones de densidad para valores de \\(x\\) entre \\(-10\\) y \\(10\\) y cuatro casos para \\(\\mu = 0\\), \\(\\mu = 2\\) y \\(s = 1\\) y \\(s = 3\\). Use 4 colores diferentes. Aunque se sabe integrar esta función, calcule su función de distribución numéricamente: considere intervalos muy pequeños (0,01, por ejemplo) y suponga que el valor de la función de densidad es constante en cada intervalo. Así integrar es simplemente ir sumando las áreas de los rectángulos. Calcule los valores de la función de distribución para los mismos parámetros y dibuje las funciones de distribución. Use los mismos colores que para la función de densidad. Para tener una idea del error cometido al sumar, haga una segunda gráfica para el caso \\(\\mu = 0, s = 1\\), con los valores que ha calculado y los valores reales. Para los valores reales tanto puede buscar cuál es la expresión de la función acumulativa de distribución, o usar la función que viene incorporada en R. Muestre el script usado y las gráficas. Prob R.6 Cree una función en R, que muestre los valores mayores o menores de un vector. La función debe llamarse maxomin y tiene 3 parámetros: x: el vector n: el número de elementos a mostrar. Por defecto n = 5 max: valor booleano. Si vale TRUE (el valor por defecto) muestra los n valores mayores. Si es FALSE, muestra los n valores menores La función devuelve un vector de n posiciones con los n elementos mayores o menores del vector. La función sort() les puede ser útil. Hagan algo razonable si n es mayor que la longitud del vector. Debe entregar la definición en R de la función y una sesión breve en la que se demuestre su funcionamiento con 3 ejemplos de uso. Prob R.7 El diagrama que utilizamos para variables cualitativas es el diagrama de barras. Si le añadimos los intervalos de confianza, obtenemos las barras de error. Tenemos datos de color de ojos nos dice de 476 personas. De ellas, tenemos 64 con ojos azules, 87 con ojos verdes, 304 con ojos marrones y 21 con ojos negros. Calcule los intervalos de confianza con un nivel de confianza del 95% y dibuje las barras de error. Debe mostrar el guión de R y la gráfica obtenida. NOTA: Si busca por ahí seguro que encontrará una función de R que le dibuje las barras de error. No la use. Debe crear su propio diagrama con su propio código. Prob R.8 Un Anova requiere que tengamos los datos como dos columnas de un data frame, una con la variable numérica y otra con el factor. Si tenemos los datos como un conjunto de vectores hemos de crear primero el data frame. Cree una función llamada list2df() para hacerlo.La función tiene tres parámetros: x es una lista con los vectores. Una lista es una estructura de datos muy versátil donde cada elemento de la estructura puede ser cualquier cosa de cualquier longitud y no tienen por qué ser todos iguales. Se crea mediante la función list(). nom_niv es un vector con los nombres que se quiere dar a cada nivel del factor. Por defecto vale NULL. La longitud de nom_niv debe ser el mismo que el numero de elementos de la lista. Si no se dan los nombres asigne unos nombres adecuados por defecto. nom_var es un vector con los nombres de las variables. Su longitud es 2. Por defecto vale NULL. Si no se dan los nombres asigne “N” a la variable numérica y “Q” al factor La función devuelve un data frame con dos columnas con los valores debidamente emparejados. Debe entregar la definición de la función y algunos ejemplos de uso. Prob R.9 El objetivo es estudiar lo que afecta al cálculo del IC de medias el que la distribución de la población sea problemática. Para crear una población muy problemática y otra nada problemática use las siguientes instrucciones: pobl_P = c(rnorm(1000, 30, 2), rexp(500, 1), rnorm(5, 100, 3)) pobl_NP = rnorm(1000, 20, 2) Calcule las medias para cada población. Repita 200 veces: coja una muestra de tamaño 5 para cada población, calcule su intervalo de confianza de medias con un nivel de confianza del 90%. Puede usar su propia función si la ha hecho, o si no t.test()[[4]] le da el intervalo de confianza. mire para cada intervalo de confianza si la media de la población correspondiente está o no en el intervalo. Con un nivel de confianza de 0.9, tocaría haber unas 180 intervalos con la media en ella. ¿Es así para la población no problemática?¿Y para la problemática?¿Qué conclusión saca? Prob R.10 Un condensador cilíndrico consiste en dos cilindros conductores, uno dentro de otro, separados por un dieléctrico. Los radios de los cilindros interior y exterior son \\(R_{1}\\) y \\(R_{2}\\), y \\(L\\) es la longitud de los cilindros. Este condensador puede tener capacidad variable si metemos o sacamos el cilindro interior del exterior. La capacidad del condensador viene dado por la expresión \\[ C = \\frac{L}{2 k \\log \\frac{R_{2}}{R_{1}}}\\] donde log es el logaritmo natural o neperiano y \\(k\\) es una constante que depende del dieléctrico y que supondremos vale \\(2,3 \\cdot 10^5\\). Queremos que calculen con R cómo varía la capacidad del condensador en las siguientes condiciones: \\(R_{1} = 35\\) mm y \\(R_{2}\\) variando de 36 mm a 50 mm a incremento de 1 mm. \\(L = 55\\) mm. \\(R_{2} = 50\\) mm y \\(R_{2}\\) variando de 49 mm a 35 mm a decrementos de 1 mm. \\(L = 55\\) mm. \\(R_{1} = 35\\) mm y \\(R_{2} = 40\\) mm con \\(L\\) variando de 30 a 60 mm a incrementos de 3 mm. Escriba un guión (script) de R para calcular la capacidad en cada condición. Para cada condición queremos el resultado de dos maneras. La primera es numérica y debe ser un vector llamado “capacidad” que muestre la capacidad del condensador para cada valor de la variable y la segunda es una gráfica de la capacidad en función de la variable. Muestre en un documento PDF el script, los valores numéricos obtenidos y las gráficas. Si tuviera que construir un condensador cilíndrico, ¿cuál de las tres variables considera que es que hay que ir con más cuidado, la que un pequeño error de construcción puede dar lugar a variaciones mayores de capacidad? Prob R.11 R tiene una gran capacidad gráfica, sobre todo a través de su paquete ggplot2. Aprenda a hacer gráficas con este paquete y escriba un breve informe explicándolas. No pueden ser las gráficas ya conocidas (histogramas, diagrama de cajas, etc). Debe entregar un script de demostración y un breve informe explicativo. Prob R.12 Escriba una función en R para dibujar intervalos de confianza de proporciones. La función tiene los siguientes parámetros de entrada: exitos: el número de éxitos de la prueba n: el número de intentos nc: el nivel de confianza. Por defecto tiene el valor de 0.90 De salida dibuja el intervalo de confianza. Debe ser horizontal, y mostrar con un carácter adecuado (el “+”, por ejemplo) el valor de p-techo. Puede añadir un parámetro adicional, col para indicar el color en el que se ha de dibujar. Prob R.13 El t.test de R exige que se introduzca el vector de datos completos. Pero a veces solo tenemos la media muestral (\\(\\hat{\\mu}\\)), la desviación típica de la muestra (\\(\\hat{\\sigma}\\)) y el tamaño de la muestra. Cree una función de R con 6 parámetros de entrada mu_techo, s_techo, n, mu, alternative y conf.level y produzca como salida una lista con tres elementos: el error estándar, el p-valor y el intervalo de confianza. Compare su función con t.test: debería dar la misma salida (excepto el IC de alternativas de un lado). Prob R.14 La función chisq.test() de R da la advertencia “Chi-squared approximation may be incorrect” cuando alguno de los valores esperados es menor que 5. Lo malo es que en la matriz de observaciones tenemos las observaciones y no los valores esperados y a veces es difícil saber cuál es la celda que da problemas. Creen una función esperados.ji.cuad(obs, coord = TRUE) que calcule los valores esperados. El parámetro obs es la matriz de observaciones. El parámetro coord, que por defecto vale TRUE, nos indica cómo queremos la salida. Si es TRUE, nos da una lista de vectores de tres posiciones. Cada vector son las coordenadas de fila y columna del valor esperado problemático y su valor. Si es FALSE, entonces devuelve la matriz de valores esperados: una matriz del mismo tamaño que el de observaciones, pero con todos los valores esperados. Deben entregar el código de R con la función (escrita inteligiblemente y con comentarios) y dos ejemplos de uso. Uno es la matriz PeloOjos que se describe al final y otro lo eligen ustedes. En ambos ejemplos deben mostrar dos ejecuciones, uno con coord = TRUE y otro con coord = FALSE. Rubio = c(31, 25, 16, 4) Pelirrojo = c(0, 9, 11, 2) Castanyo = c(28, 48, 225, 10) Negro = c(5, 5, 52, 5) PeloOjos = rbind(Rubio, Pelirrojo, Castanyo, Negro) Prob R.15 Cree la función de R gresiduos(Reg, todos = FALSE) que recibe como parámetro el resultado de la función lm. Deben averiguar cómo extraer los residuos del parámetro de entrada. Una vez tengan los residuos su función debe producir algunos o todos del histograma, el stem, el diagrama de cajas y el stripchart de los residuos. Si el valor de todos es FALSE, la función dibuja el histograma y el diagrama de cajas si hay 30 residuos o más y el stem y stripchart si hay 29 o menos; si es TRUE, dibuja los cuatro gráficos independientemente del número de residuos. Deben entregar la función y varios ejemplos de uso. Prob R.16 Cree un videotutorial de R. Puede ser de cualquier paquete o función siempre que sea adecuado al curso sea una ampliación de algo explicado o en los tutoriales existentes o algo no explicado se entregue a tiempo (no entreguen a final de curso un tutorial de bucles, por ejemplo). Deben subir el video a YouTube y en la entrega hacer una breve exposición, añadir los ficheros pertinentes si los hay (datos, script…) e indicar el enlace. Prob R.17 Busque cómo añadir colores a los diagramas de R, al menos al histograma y diagrama de barras. Muestre algún ejemplo con colores adecuados, que no sean chillones y que armonicen bien. Debe entregar una breve explicación de cómo se añaden color a los diagramas que haya estudiado y un ejemplo para cada uno, con las instrucciones de R y el diagrama. Prob R.18 En R uno puede seleccionar parte de un vector indicando los índices, pero también lo puede hacer por condición. Partimos del conjunto de datos kid.weights del paquete UsingR. Cargue el paquete UsingR primero y escribiendo kid.weights podrá ver los datos. Verá que está formado por 4 vectores: age (la edad en meses), weight (el peso en libras), height (la altura en pulgadas) y gender (el sexo, M: masculino y F: femenino). Separe los 3 primeros vectores en variables independientes: edad = kid.weights$age peso = kid.weights$weight altura = kid.weights$height Convierta el peso a Kg y la altura a cm. Veamos cómo se escoge por condición: si queremos los pesos de los niños mayores de 5 años (60 meses) basta hacer peso[edad &gt;= 60]. Haga las siguientes gráficas: peso y altura para niños menores de 3 años (peso en el eje X) altura y peso para niños entre 3 y 5 años (altura en el eje X) edad y altura para niños que pesen menos de 20 Kg Debe entregar las instrucciones de R y las gráficas. Prob R.19 Partimos del conjunto de datos trees del paquete UsingR. Este conjunto de datos contiene tres variables: Girth (la circunferencia de cada árbol), Height (la altura) y Volume (el volumen). Cargue el paquete UsingR primero y tecleando “trees” podrá ver los datos. Busque en la ayuda para saber más (vaya a la pestaña “Help” y teclee “trees” en el cuadro). Queremos dividir los árboles en “grandes” y “pequeños”. Calcule la mediana de la altura y cree dos dataframes, uno con los árboles grandes (mayores o iguales a la mediana) y otro con los árboles pequeños. Calcule la media, mediana, cuartiles, desviación y dibuje las gráficas adecuadas de cada variable en cada uno de los dos dataframes. De las 6 variables, indique cuál es la más y la menos problemática. Explique su razonamiento. Prob R.20 Calcule la probabilidad de obtener 0 caras, 1 cara, 2 caras y 3 caras al tirar 3 monedas. Usando la función sample(), simule al menos 1000 veces el tirar las tres monedas y cuente cuántas veces le salen 0 caras, 1 cara, etc. Dibuje su resultado mediante un diagrama de barras, agrupadas según el número de caras. En cada grupo debe haber dos barras: una con el resultado teórico y otra con lo que le ha salido de la simulación. Prob R.21 Vamos a estudiar cómo la distribución de Poisson y la exponencial están relacionadas. Sea un proceso de llegada de objetos que siguen una distribución exponencial con una tasa de 3 objetos/minuto. Cree un vector de 3600 posiciones con los intervalos de tiempo entre llegadas usando rexp() y el parámetro adecuado. La función cumsum() le acumulará los intervalos, creando así una “película” de unas 20 horas con los momentos de llegada contados desde el inicio.Ahora cree a partir de esta “película”, otro vector que cuente cuántos objetos han llegado en el primer minuto, cuántos en el segundo, etc hasta acabar los objetos. Esta vector con cuántos han llegado en cada minuto debería seguir aproximadamente una distribución de Poisson. Para comprobarlo cree la tabla de contingencias de frecuencias relativas adecuada y dibuje un diagrama de barras agrupado (no apilado), con un grupo por valor de k y dos barras por grupo: la probabilidad para ese valor de k según Poisson y lo que ha conseguido en su simulación. Indique si le parece que su simulación da lugar a una distribución de Poisson o no. Debe entregar el guión de R adecuadamente comentado, la tabla, las gráficas y su opinión. Prob R.22 La calificación de la parte de entregas depende del número de ergios realizado, de la nota media de las entregas, de la mediana de las entregas y de la nota del proyecto: Calificación = Ergios \\(\\times\\) (0,75\\(\\times\\) Nota media de entregas + 0,25\\(\\times\\) Nota del proyecto) \\(\\times\\) Factor Donde el factor depende de la mediana: su valor es 0.010 si la mediana es 4 o inferior, 0,026 si la mediana es de 8 o superior y varía linealmente entre 4 y 8: Factor = 0,004 \\(\\times\\) Mediana - 0,006. Vamos a suponer que la nota media, mediana y la nota del proyecto son iguales, todas valen N. Supongamos que ha entregado un total de 21 ergios. Dibuje en R la curva resultante de la calificación en la parte de entregas en función de N, con N variando de 0 a 10. Añada las curvas para 30 y 40 ergios. Para añadir curvas a una dada se usa la función points(). Es decir, para la primera curva usa plot() y para las otras dos usa points(). Debe entregar las instrucciones usadas y la gráfica resultante. Prob R.23 Podemos crear distribuciones a mano con R creando un vector muy grande con los valores que queramos con las frecuencias que queramos. Por ejemplo la instrucción distr = rep(1:20, times = c(1000, 900, 800, 700, 600, 500, 400, 300, 200, 100, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)) nos crea una distribución de “triángulo invertido” como pueden ver haciendo un histograma sobre distr. Después con la función sample() podemos coger muestras aleatorias según esta distribución. Veamos que incluso con una distribución tan lejana a la normal, su media se aproxima a la normal. Coja 250 muestras de tamaño 4. Haga las medias. Mire su distribución (dibuje el histograma). Verá que se aproxima a la normal. Ahora vamos a duplicar el tamaño de dos maneras. La primera es duplicando el número de muestras. La segunda es duplicando el tamaño de cada muestra. Hágalo y dibuje los histogramas. ¿Cuál de las dos se acerca más a la normal?¿Por qué? Recuerde que son muestras aleatorias. Conviene repetir el experimento varias veces. Entregue el código de R, los histogramas de las medias y su explicación. Prob R.24 Partimos de la simulación explicada en el video Introducción empírica a los Intervalos de Confianza (tienen el guión de R en ICProp202.R). Allí el “90%” significaba que el 90% de las muestras obtenidas estaban dentro del intervalo. Vamos a comprobar otra cosa. Vamos a comprobar otra cosa. Creen una población con una proporción de unos desconocida, igual que en el video. Obtengan 1000 muestras de tamaño 100 y calculen la horquilla igual que en el video (aunque no tienen por qué obtener el mismo valor que en el video). Ahora cojan las 1000 proporciones que han obtenido en sus muestras y obtengan los 1000 intervalos de confianza, centrando la horquilla en la proporción de la muestra. Por ejemplo, si han obtenido una horquilla de 16% y sus tres primeras muestras son 0,45;0,53; y0,48, los tres intervalos son [0,37; 0,53], [0,45; 0,61] y [0,40; 0,56]. Cojan ahora el valor real de la proporción desconocida y calculen en qué porcentaje de los 1000 intervalos cae dentro. Es decir, qué porcentaje de los intervalos “ha acertado”. ¿Es cercano al 90%? Repita con n = 500 y n = 1000. Muestre su guión y sus resultados. Prob R.25 Una manera de ir entendiendo qué es eso de la aleatoriedad de parámetros y pruebas estadísticos es ver cómo se comportan en casos que sabemos lo que deben hacer. El p-valor es una variable aleatoria y vamos a ver qué pasa en casos conocidos. Partimos de la distribución normal de media 0 y desviación típica 1. Cogemos una muestra con rnorm() de 30 elementos y calculamos su p-valor con t.test() con H0: media = 0 y Ha: media \\(\\neq\\) 0, es decir, la hipótesis nula se cumple. Repetimos esto 10.000 veces y hacemos un histograma de los p-valores resultantes. Repetimos los histogramas con H0: media = 0.25 (la hipótesis nula no se cumple por un cuarto de la desviación típica), H0: media = 1 (la hipótesis nula no se cumple por una de la desviación típica) y H0: media = 2 (la hipótesis nula no se cumple por dos de la desviaciones típicas). Estudie los histogramas y explique lo que ve. Por ejemplo, cuál es la probabilidad (casos favorables/casos posibles) de que el p-valor sea menor que 0.05 o 0.01 en los tres casos. NOTA: Para extraer sólo una de las salidas de un t.test() (el p-valor en nuestro caso) hay que escribir t.test(…)[[n]]}. Diferentes valores de n nos da diferentes partes de la salida. Prob R.26 Queremos comparar las medias de dos muestras mediante contrastes de hipótesis e intervalos de confianza. Por cuestiones económicas queremos fijar el total de medidas a tomar en 40, pero no sabemos si coger 2 muestras de tamaño 20, una de tamaño 10 y otra de tamaño 30 o una de tamaño 5 y otra de tamaño 35. Haga pruebas con diferentes distribuciones de datos (normal, exponencial, poisson, binomial, uniforme u otras). Coja muestras aleatorias con diferencias de medias similares y establezca si de las tres posibilidades de tamaño de muestra indicadas hay una que permita diferenciar mejor que las otras. Debe indicar si hay una mejor o no, dar la evidencia que soporte su afirmación y especular sobre las razones teóricas que fundamentan su afirmación. Prob R.27 Una buena manera de aprender sobre regresiones es hacerlas al revés: se parte de una curva conocida, se crean muchos conjuntos de datos aleatorios sobre ella, se recalcula la regresión y se miran los resultados. Supongamos que sabemos que nuestros datos siguen la recta y = 2x + 3. Podemos simular un conjunto de 100 puntos con x entre, por ejemplo, 2 y 8 mediante las instrucciones x = runif(100, 2, 8) y = 2*x + 3 + rnorm(100, 0, 1.5) Después, con lm(y~x) obtenemos la recta de regresión que debe ser parecida a y = 2x+3. Haga al menos 100 simulaciones y pinte un conjunto de puntos (el primero será el más fácil de dibujar) y las 100 rectas de regresión calculadas. Pinte también la recta “buena” (si pinta las rectas de las regresiones en negro y la final pinta la recta buena en blanco, se verá bien). Debe entregar la gráfica resultante y su descripción del resultado. Prob R.28 Partimos del conjunto de datos Cars93 que está en el paquete MASS. Contiene datos de 93 coches. Ejecute Library(MASS) y ya lo tendrá disponible. La columna “Length” nos da la longitud del coche en pulgadas. Una pulgada son 2,54 cm. Pase la longitud a cm. Calcule con R la media, mediana, cuartiles y desviación típica de la longitud de los 93 coches. Dibuje con R los cuatro diagramas (histograma, cajas, tallo y hojas y stripchart) de la variable longitud. La columna “type” nos da el tipo del coche (compacto, deportivo, furgoneta…). Calcule con R la tabla de contingencia del tipo de los 93 coches. Dibuje con R el diagrama de barras correspondiente. Debe entregar las instrucciones de R, los resultados y los diagramas. Prob R.29 En el fichero mp3.csv (pestaña de recursos) tiene datos de más de 500 pistas de canciones codificadas en mp3. La columna Tamanyo es el tamaño (en bytes) de la pista. Es una variable numérica, pero la queremos pasar a factor con cuatro niveles: muy corta, corta, media y larga. Usando R determine cuál es la pista más corta (de menor tamaño) y la más larga (de mayor tamaño). Dividiremos los niveles en rangos iguales. Por ejemplo si la más corta es de 1000 bytes y la más larga es de 5000 bytes, los niveles quedarían definidos por muy corta: de 1000 a 1999; corta: de 2000 a 2999; media: de 3000 a 3999, y larga: de 4000 a 5000. Defina la variable cualitativa “longitud” con los cuatro niveles. Calcule los rangos de tamaño para cada nivel Cree un vector para cada pista asignándole el nivel que le corresponda Calcule la tabla de contingencia de la variable Cree el diagrama de barras correspondiente Todo esto debe hacerse con R. No puede hacer nada “a mano”. Le puede ser útil la función cut(). 15.3 Estadística Descriptiva Prob ED.1 Haga un estudio de problematicidad del conjunto de datos rivers. este es un conjunto de datos con la longitud (en millas) de los ríos principales de USA. Tecleando “rivers” podrá ver los datos.Haga las operaciones para calcular sus medidas de centralidad y dispersión, dibuje todas las gráficas adecuadas y establezca si los datos son nada, poco, algo o muy problemáticos. Debe entregar un fichero PDF con los datos, las gráficas y su análisis. Prob ED.2 Busque en periódicos nacionales (puede buscar por Internet) algún gráfico de quesitos que sea realmente malo. Redibújelo como diagrama de barras. Debe entregar un documento PDF con la referencia (periódico, fecha, nombre de la noticia y URL si la ha mirado en linea), el gráfico original, y el gráfico suyo. Explique para su gráfico concreto qué se ve mejor que en el del periódico. Prob ED.3 En R uno puede seleccionar parte de un vector indicando los índices, pero también lo puede hacer por condición. Partimos del conjunto de datos kid.weights del paquete UsingR (en la sección de Recursos tiene un documento que le explica cómo cargar paquetes). Cargue el paquete UsingR primero y escribiendo kid.weights podrá ver los datos. Verá que está formado por 4 vectores: age (la edad en meses), weight (el peso en libras), height (la altura en pulgadas) y gender (el sexo, M: masculino y F: femenino). Llamaremos infantes a los individuos independientemente de su sexo, niños a los de sexo masculino y niñas a las de sexo femenino. Cree un data frame llamado infante.pesos que es idéntico a kid.weights excepto que ha convertido el peso a Kg y la altura a cm. Cree un otro data frame con sólo los infantes de 3 años o más. A partir de estos datos de este último, dibuje un histograma y un diagrama de barras del peso de los niños dibuje una gráfica de altura y peso de estos infantes, (altura en el eje X). Cree otro data frame, a partir de infante.pesos, de infantes cuya altura es mayor o igual a 80 cm. Dibuje un diagrama de barras con el porcentaje de niños y niñas en este data frame. Debe entregar un PDF con las instrucciones usadas (sólo las instrucciones, no los resultados) y las gráficas obtenidas. Prob ED.4 El conjunto de datos EuStockMarkets de R tiene el valor diario de cierre de mercado desde 1991 a 1998 de los 4 índices bursátiles más importantes de Europa: DAX, SMI, CAC y FTSE. No es un data frame y manipularlo es un poco complejo, pero si ejecutan DAX = EuStockMarkets[,1] SMI = EuStockMarkets[,2] CAC = EuStockMarkets[,3] FTSE = EuStockMarkets[,4] tendrán en cuatro vectores de 1860 posiciones los 4 valores. Nos interesa estudiar la diferencia entre el valor de un día y el siguiente. Cree 4 vectores de 1859 posiciones donde aparezca en cada posición lo que ha subido (positivo) o bajado (negativo) el mercado porcentualmente ese día. Estos vectores deben llamarse DAXdifP, SMIdifP, CACdifP y FTSEdifP. Calcule la media, mediana, cuartiles y desviación típica de cada vector de diferencias y dibuje los histogramas correspondientes. Si las distribuciones de las diferencias fueran normales, cosa que se supone a menudo, el 68,3% de las observaciones deberían estar a menos de una desviación típica de la media, el 95,4% deberían estar a menos de dos desviaciones típicas de la media y el 99,7% de las observaciones deberían estar a menos de 3 desviaciones típicas de la media. Comprueben si es así para estos 4 índices. Deben entregar los resultados obtenidos (gráficas incluidas) y sus conclusiones. Prob ED.5 Creen dos vectores de datos, ambos con 200 valores. El primero debe ser unimodal y el segundo multimodal y debe verse claramente su modalidad en sendos histogramas, pero ambos deben resultar en diagramas de cajas prácticamente idénticos (idealmente, completamente idénticos). Deben explicar cómo han construido sus dos vectores y mostrar las gráficas. Prob ED.6 Queremos saber si los métodos de estudio en las diferentes carreras es similar o no. Observaremos el método de trabajo en 3 bibliotecas de la universidad: el de Anselm Turmeda y otras dos que ustedes elijan. Deben coger al menos 30 datos de cada biblioteca. La biblioteca es una variable cualitativa, el método de estudio es otra. Supondremos 4 niveles: Leer de libros Leer de apuntes Escribir (ya sea en los apuntes, en el ordenador o resolviendo problemas) Hablar (trabajo en equipo) Puede ser que alguien esté, por ejemplo, leyendo y escribiendo: deben ustedes decidir cuál es su actividad primaria. No se puede hablar en las bibliotecas, pero en todos los edificios hay zonas de trabajo en equipo. Consideren eso como parte de la biblioteca. Tomen la muestra lo mejor posible. Este es un ejercicio y a pesar de sus esfuerzos, su muestra no será representativa. Indique algunos de los motivos por los que la muestra no es de fiar. Creen las tablas de contingencia y gráficas adecuadas que describan lo mejor posible si los métodos de estudio son diferentes en los diferentes edificios de la universidad. Prob ED.7 El conjunto de datos MLBattend del paquete UsingR contiene información de las temporadas de baseball de USA. Los datos que nos interesan son “attendance” (espectadores), “franchise” (el equipo), “wins” (victorias) y “runs.scored” (carreras a favor). Nos vamos a centrar en 3 equipos: Los Angeles Dodgers (LA), Cleveland Indians (CLE) y St. Louis Cardinals (STL). Queremos saber si el número de espectadores depende más de las victorias o de si el equipo marca mucho (número de carreras a favor conseguidas). Para cada equipo dibuje la nube de puntos del número de espectadores en función del número de victorias. Calcule las rectas de regresión. Repita para número de espectadores en función de las carreras conseguidas. Del conjunto de sus gráficas, dé su opinión de la importancia de si es más importante el número de victorias o el número de carreras para conseguir que la gente venga al campo. Prob ED.8 En el fichero Halterofilia.csv tiene los resultados de los mundiales de halterofilia de hace unos años. Es un data frame con las siguientes variables: Peso: el peso del deportista Arrancada: lo que levantó en la modalidad de arrancada Dos Tiempos: lo que levantó en la modalidadde dos tiempos Total: la suma de los dos valores anteriores Categoría: categoría de peso del deportista (cuidado, hay dos “menos 69”, una masculina y otra femenina) Sexo: el sexo del deportista Creen dos nubes de puntos del levantamiento en modalidad de Arrancada en función del peso, uno para hombres y otro para mujeres. Creen dos diagramas de cajas, del levantamiento en modalidad de Dos tiempos en función de la categoría, uno para hombres y otro para mujeres. Creen dos diagramas de puntos (stripchart) del levantamiento total por Kg del peso del deportista en función de la categoría, uno para hombres y otro para mujeres (un valor de 1 significa que ha levantado tanto como pesa). Queremos determinar cuál es el mejor deportista masculino y el mejor deportista femenino en conjunto, no por categoría. Cree de alguna manera una fórmula que permita asignar un “peso levantado” a cada deportista en función de lo que ha levantado, su peso corporal, su categoría o lo que estime oportuno. Posiblemente la fórmula sea diferente para hombres y para mujeres. No hay una fórmula perfecta, por lo tanto decida qué criterios son importantes y explique cómo ha determinado la fórmula (la explicación es lo más importante). Úsela y cree la clasificación de los mejores halterófilos. Prob ED.9 Dado el siguiente histograma Indique un valor aproximado del rango (valor máximo y mínimo) de los datos.¿Cuántos datos están entre 3.5 y 5? Prob ED.10 Dado el siguiente diagrama de puntos: Indique, si se puede, las siguientes características de los datos: (a) Modalidad; (b) Simetría; (c) Media; (d) Mediana; (e) Rango; (f) Valores atípicos. Prob ED.11 Las siguientes cuatro gráficas corresponden a una muestra. Establezca la modalidad, simetría y presencia de valores atípicos en la muestra. Indique en qué gráfico se ve mejor cada cosa. Prob ED.12 Partimos del conjunto de datos Cars93, del paquete MASS. Son datos de 93 coches indicando entre otras cosas el tipo (compacto, deportivo, etc). Dibuje el diagrama de barras de frecuencias relativas de los tipos de coche en este conjunto de datos. Prob ED.13 En la siguiente tabla tiene el tamaño (en quilates) y el precio (en dólares) de 10 diamantes.Dibuje los datos en R como una nube de puntos. Tamaño Precio 0,23 326 0,26 337 0,31 552 0,42 820 0,51 670 0,65 730 0,72 800 0,80 970 0,93 1056 1,04 1803 Prob ED.14 En el conjunto de datos reaction.time del paquete UsingR, tienen los tiempos de reacción de un grupo de 60 personas algunas de las cuales estaban usando un teléfono móvil. Lean la página de ayuda para la descripcion de las variables. Dibuje el diagrama de barras de cada una de las variables cualitativas y todas las gráficas que sean adecuadas para cada una de las variables numéricas. ¿Son problemáticas las variables? Dibuje diagramas de cajas y de puntos (stripchart) del tiempo de reacción en función de la edad y del tiempo de reacción en función de si usaban o no el móvil. ¿Creen que el uso del móvil influye en el tiempo de reacción?¿Y la edad? Prob ED.15 El fichero bodim.csv (disponible en la pestaña de recursos) contiene datos de un estudio sobre la imagen que tienen de sí mismas mujeres de Nueva Zelanda. Las 246 mujeres tienen un índice de peso corporal similar. La columna “ethnicity” indica el origen étnico de la mujer; la columna “married” su estado civil (1: soltera, 2: casada, 3: separada, 4: viuda) y la columna “bodyim” la imagen que tiene de sí misma.“Right” quiere decir que se ve bien; “.ow” significa overweight, sobrepeso; “.uw” significa underweight, delgada; “slight” quiere decir ligero; “mod” representa moderado; “very” representa mucho.Por lo tanto “slight.uw” representa a una persona que se ve ligeramente delgada. Muestren un diagrama de barras con las imágenes que se tienen de sí mismas las 246 mujeres. Ahora hagan lo mismo agrupando por etnicidad primero y por estado civil después. Comente si la etnicidad o el estado civil influyen en la imagen que tienen de sí las mujeres neozelandesas. Prob ED.15 El dataframe iris viene incluida en la instalación de R. Teclee iris y le mostrará el conjunto. Haga un histograma de la columna Sepal.Length, un diagrama de cajas de la columna Sepal.Width, un diagrama de tallo y hojas (stem) de la columna Petal.Length y un stripchart de la columna Petal.Width. Prob ED.16 El conjunto de datos SAT del paquete UsingR da los resultados del examen SAT (una especie de selectividad) en los diferentes estados de USA. Dibuje la nube de puntos con el valor de la parte verbal (verbal) en el eje X y la parte matemática (math) en el eje Y. Prob ED.17 En el paquete UsingR tiene el conjunto de datos BushApproval, con la “nota” (approval) del presidente George W. Bush en diferentes momentos desde el año 2001 al 2004 y medida por diferentes organizaciones (who). Dibuje el diagrama de cajas de las calificaciones en función de la organización. Las calificaciones de la U. de Pennsylvania (upenn) son claramente diferentes de las demás. Dé un motivo razonable de por qué. Prob ED.18 El conjunto de datos samhda del paquete UsingR contiene información sobre los hábitos de salud de niños en edad escolar en USA. Nos interesan dos columnas, curso (grade) y número de días en lo que se ha fumado en el último mes (amt.smoke). Ambas variables son cualitativas. Los niveles de grade son 1 (6º), 2 (8º), 3 (10º) y 9 (no se sabe), mientras que los niveles de la amt.smoke son 1 (todos los días), 2 (de 20 a 29 días), 3 (de 10 a 19), 4 (6 a 9), 5 (3 a 5), 6 (1 ó 2), 7 (ningún día) y 98 y 99 (no se sabe o datos inconsistentes). Queremos saber si varía el hábito de fumar con el curso. Creen una tabla de contingencia de frecuencias absolutas de estas dos variables. Eliminen de la tabla los valores sin información (9, 98 y 99). Creen tres tablas de frecuencias relativas: una en la que el conjunto suma 1, otra en la que las columans suman 1 y la tercera en la que las filas suman 1. A partir de estas tablas indique si hay una diferencia o no. Prob ED.19 Partimos del conjunto de datos Cars93 del paquete MASS (está incluido en la distribución de R). Queremos estudiar la relación que hay entre el tipo de coche y el número de cilindros. Sospechamos que los coche de 4 cilindros son los más abundantes en todos los tipos. Para establecer esto queremos dibujar un diagrama de barras. ¿Cuál sería la más adecuada? Dibújela y extraiga conclusiones. Prob ED.20 En el fichero notparc.csv tiene las notas de un examen parcial. La puntuación del examen podía ir de 0 a 58 puntos. Pueden ver que hay dos modelos de examen y nos interesa saber si hay diferencias de calificaciones entre los dos modelos. Estudie la problematicidad del conjunto de las notas y de las notas de cada modelo. Prob ED.21 El conjunto de datos stud.recs del paquete UsingR contiene datos de los SAT (una especie de selectividad que hacen en EEUU). La columna sat.v contiene la calificación de la parte verbal y sat.m contiene la calificación de la parte matemática de 160 exámenes. Estudie la problematicidad de los datos. Prob ED.22 Dado el diagrama de tallo y hojas: The decimal point is 1 digit(s) to the right of the | 4 | 26779 6 | 788 8 | 679119 10 | 04444912344499 12 | 01366758 14 | 34558 16 | 84 18 | 22289 20 | 04 22 | 24 | 4 Estime el valor de la mediana y los cuartiles. ¿La distribución es unimodal o bimodal? Prob ED.23 Haga un estudio de problematicidad del conjunto de datos trees del paquete UsingR. Este conjunto de datos contiene tres variables: Girth (el diámetro de cada árbol), Height (la altura) y Volume (el volumen). Haga todas las operaciones y gráficas de la forma explicada en el tutorial para cada una de las variables y establezca lo problemáticos que son. No olvide de justificar sus respuestas. Prob ED.24 El conjunto de datos WorldPhones muestra el número de teléfonos en el mundo dividido por zonas geográficas. Ejecute las instrucciones barplot(WorldPhones, beside = T, legend.text = T) barplot(t(WorldPhones), beside = T, legend.text = T). La función t() transpone una matriz o data frame. Explique lo que se vé en ambos gráficos. Prob ED.25 Use los datos del fichero D3.csv que están en Campus Extens. Cree una tabla de contingencia con las variables “Raza” y “Constitucion”. En cada celda debe haber el número de personas de una determinada raza y constitución. Cree ahora otras dos tablas con los porcentajes, una de manera que las filas sumen 100 y otra de manera que las columnas sumen 100. Responda a las siguientes preguntas: ¿Las personas de raza negra, tienen alguna constitución dominante?¿Las personas de constitución mesomorfa, pertenecen prioritariamente a una raza concreta? Prob ED.26 El conjunto de datos Cars93 del paquete MASS contiene datos de 93 coches. Haga un diagrama de barras del número de cilindros de los coches (Cylinder). ¿Cuál es el número de cilindros más frecuente? ¿Y menos? Prob ED.27 El conjunto de datos UScereal del paquete MASS contiene datos de 65 marcas de cereal que se venden en USA. Una de las columnas es mfr, el fabricante, y otra es shelf, la estantería en la que colocan el cereal en un determinado supermercado (1 en la de abajo, 2 en la del medio, 3 en la superior). Cree las tres tablas de datos (total suma 1, filas suman 1, columnas suman 1) con las proporciones de marcas por fabricante y estantería. Prob ED.28 En el conjunto de datos Cars93, dibuje en R los diagramas de cajas y de puntos (stripchart) de las potencias de los coches en funcion del tipo. Prob ED.30 Partimos del conjunto de datos kid.weights en el paquete UsingR. Las alturas de los niños están en pulgadas y los pesos de los niños están en libras. Cree un nuevo dataframe con las alturas en cm y los pesos en Kg. Dibuje los pesos en función de las alturas sólo para los niños. Hágalo en color azul. Añada los de las niñas en color rojo. Añada las dos rectas de regresión en los colores respectivos. ¿Considera que el sexo del infante influye en su peso o sólo influye la altura? Prob ED.31 En el conjunto de datos reaction.time del paquete UsingR, tienen los tiempos de reacción de un grupo de 60 personas algunas de las cuales estaban usando un teléfono móvil. Lean la página de ayuda para la descripcion de las variables. Dibuje diagramas de cajas y de puntos (stripchart) del tiempo de reacción en función del sexo y del tiempo de reacción en función de si usaban o no el móvil. ¿Creen que el uso del móvil influye en el tiempo de reacción?¿Y el sexo? Prob ED.32 Pregunte a al menos 10 personas su dirección (o indicaciones suficientes de su lugar de residencia) y el tiempo medio que necesitan para llegar a la UIB. A través de Google Maps (o similar) mida la distancia desde la residencia a la UIB en linea recta. Dibuje una nube de puntos (scatterplot) con la distancia en el eje X y el tiempo en el eje Y. Explique si hay correlación entre la distancia y el tiempo. Si tiene sentido, calcule la recta de regresión e indique cuánto tiempo se necesita para recorrer cada Km adicional de distancia a la UIB. Pueden dividir los tiempos según el medio de locomoción. Prob ED.33 El conjunto de datos MLBattend del paquete UsingR contiene información de las temporadas de baseball de USA. Los datos que nos interesan son “attendance” (espectadores), “franchise” (el equipo), “league” (la liga. Hay dos, la nacional y la americana), “division” (la division Este, Central u Oeste), “wins” (victorias) y “runs.scored” (carreras a favor). Dibuje diagramas de cajas con los espectadores por equipo, por liga y por división. Dibuje un diagrama de puntos (stripchart) de los espectadores por año (recuerde que el año es un factor. El año 0 es el 2000). Dibuje una nube de puntos de los espectadores en función del número de victorias. Use un color y símbolo diferente para cada liga. Para la liga Nacional, dibuje una nube de puntos de los espectadores en función de las carreras a favor. Use un color y símbolo diferentes para cada división. Del conjunto de sus gráficas, dé su opinión del número de espectadores que van a ver los partidos de baseball. Prob ED.34 Haga un estudio de problematicidad del conjunto de datos aid del paquete UsingR. A pesar del aspecto que tiene, es un vector numérico y puede hacer todas las operaciones y gráficas. Haga las operaciones para calcular sus medidas de centralidad y dispersión, dibuje todas las gráficas adecuadas y establezca si los datos son nada, poco, algo o muy problemáticos. Debe entregar un fichero PDF con los datos, las gráficas y su análisis. Prob ED.36 Si usamos demasiados pocos valores para hacer un histograma sabemos que puede tomar una forma que depende de, por ejemplo, la anchura de las barras o dónde se cogen los límites de las barras. Vamos a explorar esto un poco. La instrucción de R rnorm(n) devuelve un vector que es una secuencia aleatoria de n valores que siguen una distribución normal (campana de Gauss) centrada en el 0 y con desviación típica 1. Si hacemos un histograma con este vector, debería salir siempre algo parecido a una campana de Gauss. Empiece con n = 20. Cada vez que ejecute rnorm(20) le dará una secuencia distinta y por lo tanto un histograma algo diferente. Obtenga 10 vectores y los 10 histogramas (se puede hacer todo junto con hist(rnorm(20))). ¿Se puede identificar una campana de Gauss en todos ellos?¿En la mayoría? Repita con n = 50, n = 100, n = 200, n = 500 y n = 1000. ¿A partir de qué valor de n podemos considerar que el histograma representa adecuadamente y de forma consistente una campana de Gauss? Muestre el “mejor caso” y “peor caso” de histograma para cada valor de n. Prob ED.37 El conjunto de datos “islands” de R contiene los tamaños en miles de millas cuadradas de muchas islas. Estudie si los datos son problemáticos. Elimine los continentes y vuelva a hacer el análisis. Prob ED.38 Partimos del conjunto de datos Cars93 que está en el paquete MASS. Contiene datos de 93 coches. Ejecute Library(MASS) y ya lo tendrá disponible. La columna “Horsepower” nos da la potencia del coche. Calcule la media, mediana, cuartiles y desviación típica de la potencia de los 93 coches. Dibuje los cuatro diagramas (histograma, cajas, tallo y hojas y stripchart) La columna “type” nos da el tipo del coche (compacto, deportivo, furgoneta…). Calcule la tabla de contingencia del tipo de los 93 coches. Prob ED.40 El conjunto de datos Animals del paquete MASS contiene el peso del cuerpo (body) y del cerebro (brain) de 28 especies de animales terrestres. Nos interesa saber si el peso del cerebro está correlacionado con el peso del cuerpo. Dibuje una nube de puntos con estas dos variables, haga algo con los valores atípicos y decida si la correlación existe o no. Prob ED.41 Algunos datos numéricos pueden ser considerados cualitativos. Partimos del conjunto de datos Cars 93 del paquete de R MASS (con la instrucción library(MASS) los tendrá accesibles. Consideramos la variable cualitativa “Type” que es el tipo del coche (deportivo, pequeño, compacto, grande, etc) y “Cylinder” que es el número de cilindros, y que vamos a considerar cualitativo. Calcule las 4 tablas de contingencia de estas dos variables: las frecuencias absolutas, las proporciones en las que el total suma 1, las proporciones en las que las columnas suman 1 y las proporciones en las que las filas suman 1. Muestre las 4 tablas y responda a las siguientes preguntas. Indique para cada respuesta de qué tabla ha obtenido los datos. ¿Qué proporción de coches medianos (Midsize) tiene 4 cilindros? ¿Cuántos modelos de coches deportivos tienen 6 o más cilindros? ¿Qué proporción de coches de 8 cilindros son grandes (Large)? ¿Qué proporción de coches tiene 6 cilindros? Prob ED.42 Partimos del conjunto de datos trees del paquete UsingR. Este conjunto de datos contiene tres variables: Girth (la circunferencia de cada árbol), Height (la altura) y Volume (el volumen). Cargue el paquete UsingR primero y tecleando “trees” podrá ver los datos. Busque en la ayuda para saber más (vaya a la pestaña “Help” y teclee “trees” en el cuadro). Queremos dividir los árboles en “grandes” y “pequeños”. Calcule la mediana de la altura y cree dos dataframes, uno con los árboles grandes (mayores o iguales a la mediana) y otro con los árboles pequeños. Calcule la media, mediana, cuartiles, desviación y dibuje las gráficas adecuadas de cada variable en cada uno de los dos dataframes. De las 6 variables, indique cuál es la más y la menos problemática. Explique su razonamiento. Prob ED.43 La tasa de mortalidad normalizada indica cuánta gente ha muerto en un año por cada 1000 personas. En general se miden tasas según exposición: por cada 1000 personas que han estado expuestas a alguna cosa, cuántas han muerto. La tabla que se muestra a continuación son datos de muertos según exposición al tabaco y según la causa de muerte: Leemos en la tabla, por ejemplo, que por cada 1000 personas que no fumaban, 0.07 personas han muerto en un año por cáncer de pulmón. La mortalidad ¿es una variable numérica o cualitativa? La columna de fumadores está desglosada en tres, según la cantidad de tabaco que fumaban. ¿Por qué la suma de las tres filas por cantidad no suma lo mismo que la fila conjunta de todos los fumadores?¿Por qué la fila “Todas las muertes” sí que suma en cambio las celdas del resto de la columna? Nos interesa crear un gráfico que nos permita comparar las tasas de mortalidad según exposición.No queremos que aparezca la columna de fumadores, ya que preferimos las tasas desglosadas. Elijan el gráfico más adecuado y créenlo. 15.4 Probabilidad y variables aleatórias Prob Pr.1 Partimos de la siguiente tabla de contingencias del color de pelo y de ojos de un conjunto de personas: Pelo Azul Verde Marrón Rubio 8 9 8 Castaño 7 12 54 Negro 1 2 14 Calculemos probabilidades según dos formas de muestreo diferentes. - Escogemos 2 personas (diferentes) de nuestra muestra. ¿Cuál es la probabilidad de que ambas tengan pelo negro? Escogemos una persona y después otra (existe la posibilidad de que sea la misma). ¿Cuál es la probabilidad de que ambas tengan pelo negro? Escogemos 5 personas (diferentes) de nuestra muestra. ¿Cuál es la probabilidad de que la mayoría sean castaños de ojos verdes? Escogemos 5 personas, una tras otra (existe la posibilidad de repetir). ¿Cuál es la probabilidad de que la mayoría sean castaños de ojos verdes? Prob Pr.2 Miren el video (en inglés) de Persi Diaconis sobre las probabilidades al lanzar una moneda https://www.youtube.com/watch?v=Obg7JPd6cmw. Les puede interesar ver los otros dos videos de esta serie: https://www.youtube.com/watch?v=AYnJv68T3MM y https://www.youtube.com/watch?v=9RKKoXw7wJw aunque no es necesario para esta tarea. Diaconis explica que al rotar una moneda sobre una mesa (en vez de tirarla al aire) la probabilidad de cara o cruz depende de la moneda y puede ser muy distinta al 50%. Coja 4 monedas, “rótelas” al menos 100 veces cada una y muestre sus resultados. Procure que sean 4 monedas de características diferentes (canto rayado o no, tamaño, nuevas o gastadas, etc) ¿Concuerdan sus resultados con lo que dice el video? Prob Pr.3 Uno de los dispositivos más usados para mostrar números es el visualizador 7 segmentos como el de la figura: Supongamos que pudiéramos tener un segmento roto, sólo uno. Con un segmento roto, dependiendo del número que se esté representado podemos tener una de 3 posibilidades: lo que se ve es un valor inválido cuando no representa número alguno, un valor válido incorrecto, cuando representa un valor válido, pero que no es el número que se quiere representar, o un valor correcto, cuando se está representando el número que queremos representar. Por ejemplo, si el que está roto es el segmento G, si se quiere representar el número 4 tendríamos un valor inválido, si queremos representar el 8, tenemos un valor válido incorrecto (se ve un 0) y si se quiere representar un 7, tenemos un valor correcto. Sea p la probabilidad de que haya un segmento roto, y 1-p la probabilidad de que todos funcionen (suponemos imposible que haya 2 o más segmentos rotos). La probabilidad de ruptura entre los 7 segmentos es la misma, es decir que hay una probabilidad de p/7 de que esté roto A, p/7 de que esté roto B, etc. Suponemos también que todos los números se representan con la misma probabilidad (por ejemplo, el dígito de las unidades de los minutos de un reloj digital). En un momento dado miramos el visualizador. ¿Cuál es la probabilidad de que represente un valor válido incorrecto?¿Cuál es la probabilidad de que represente un valor correcto? Hay un segmento roto. ¿Cuál es la probabilidad de ver un valor válido?¿Y un valor correcto? Miramos el visualizador y vemos un valor válido, pero no sabemos si correcto. ¿Cuál es la probabilidad de que sea correcto?¿Cuál es la probabilidad de que no haya ningún segmento roto? Prob Pr.4 Supongamos que en nuestra población la altura de los jóvenes sigue una distribución normal de media 1,76 m y desviación típica 7,2 cm. ¿Cuál es la probabilidad de escoger a alguien de más de 1,85 m? ¿Cuál es la probabilidad de escoger a 10 personas y que 7 o más midan más de 1,85 m? Prob Pr.5 Calcule la función de masa de lanzar dos dados. Introdúzcala en R como un vector. Calcule en R la función acumulativa de distribución. Debe ser otro vector de la misma longitud. Utilizando estos vectores calcule las siguientes probabilidades: Probabilidad de sacar menos de un 4 Probabilidad de sacar más de un 6 Probabilidad de sacar entre 3 y 8 (ambos inclusive) Debe calcular cada probabilidad dos veces: una usando la función de masa y otra usando la función de densidad. Le recomiendo que aprenda a usar las funciones sum() y cumsum(). NOTA: La función acumulativa de distribución la debe calcular usando únicamente instrucciones de R. Es decir, no puede calcular nada a mano y después introducir valores en R. Les aseguro que es muy fácil. Prob Pr.6 Coja todos los partidos de una liga concreta (Liga Española 1ª o 2ª división, alguna liga extranjera) en una temporada y anote la cantidad de goles que se ha marcado en cada partido (goles totales, no por equipo). Estos serán nuestros datos de partida. Sabiendo el número total de goles y el número de partidos, sabemos el número medio de goles por partido. Ahora compare la distribución real (cuántos partidos con 0 goles, cuántos con 1, etc) con lo que se obtiene con una distribución de Poisson. Mediante una tabla y un diagrama de barras compare los resultados y determine si cree que los goles por partido siguen una distribución de Poisson o no. Prob Pr.7 Deduzcan la expresión general de la desviación típica: Dadas dos variables aleatórias X e Y y tres constantes a, b y c, entonces \\[sd(aX ± bY ± c) = \\sqrt{a^2 sd(X)^2 + b^2 sd(Y)^2}\\] Deben mostrar la deducción completa. Prob Pr.8 Sea X una variable aleatoria que sigue una distribución normal de parámetros \\(\\mu = 2\\) y \\(\\sigma = 3\\). Sea Y una variable aleatoria que sigue una distribución de Poisson, de parámetro \\(\\lambda = 2,7\\). Sean las constantes \\(a = \\sqrt{2}, b = \\pi, c = 1\\). Calcule las esperanzas y desviaciones típicas de \\(V1 = aX - bY -c;\\quad V2 = ax + cY;\\quad V3 = X - X + bY\\). Para comprobar sus cálculos hagamos una simulación: genere con R conjuntos de 100.000 valores de X e Y y cree las variables aleatorias V1, V2 y V3 (para V3 deberá generar dos conjuntos para X y uno para Y). Dibuje los histogramas de V1, V2 y V3 y calcule los valores de la media y la desviación típica de estos conjuntos de 100.000 valores. Compruebe que efectivamente sus cálculos teóricos y la simulación da resultados parecidos. (Si no los da es que una de las dos está mal). Prob Pr.9 Lean los datos del fichero colorPeloOjos.csv (pestaña de recursos). Creen la tabla de frecuencias absolutas y respondan a estas preguntas: Dentro de la muestra, ¿Cuál es la probabilidad de tener ojos verdes? ¿Cuál es la probabilidad de tener pelo rubio? ¿Cuál es la probabilidad de que o los ojos o el pelo sea marrón-castaño? ¿Cuál es la probabilidad de tener ojos verdes y pelo castaño? ¿Cuál es la probabilidad de que uno de pelo negro tenga ojos verdes? ¿Cuál es la probabilidad de que uno de ojos marrones tenga pelo rubio? Prob Pr.10 Seguimos con el conjunto de datos reaction.time ya usado. Esta es nuestra evidencia para el cálculo de todas las probabilidades que se solicitan. Sea MD la mediana de todos los tiempos de reacción. ¿Cuál es la probabilidad de que el tiempo de reacción de una persona esté por debajo de MD? (Ni se les ocurra hacer cálculo alguno para responder esto) ¿Cuál es la probabilidad de que una persona que usa el móvil reaccione en un tiempo inferior a MD? ¿Cuál es la probabilidad de que una persona en la categoría de edad 16-24 reaccione en un tiempo inferior a MD? Si una persona reacciona en un tiempo inferior a MD ¿cuál es la probabilidad de que no estuviera usando el móvil? Si un hombre que está usando el móvil reacciona en un tiempo superior a MD ¿cuál es la probabilidad de que reaccione en un tiempo mayor o igualque 1,5? Indique las instrucciones de R usadas para cada uno de los cálculos. Prob Pr.11 Dos variables aleatorias A y B se definen como independientes si Prob(A y B) = P(A)\\(\\cdot\\)P(B). Partimos de la tabla de color de pelo y ojos detallado en el fichero colorPeloOjos.csv. Consideramos que los pelirrojos son “rubios subidos” y juntamos los pelirrojos a los rubios.También consideramos que los ojos negros son realmente “marrones oscuros” y juntamos los de ojos negos a los de marrones. Nos queda pues una tabla de \\(3\\times 3\\). Para las 9 combinaciones resultantes calculen P(A)\\(\\cdot\\)P(B) (P(Rubio)\\(\\cdot\\)P(Azules), etc). Creen un diagrama de barras agrupado. Cada grupo es una combinación de color de pelo y ojos y en cada grupo hay dos barras, Prob(A y B) y P(A)\\(\\cdot\\)P(B). A partir de este diagrama indiquen si les parece que el color de ojos y de pelo son variables aleatorias independientes o no. Prob Pr.12 Dada la función de densidad \\(f(x) = 0.1\\,e^{-0,1 x}\\) calcule Prob[\\(2 &lt; X &lt; 4\\)], Prob[\\(X \\geq 1\\)]. Prob Pr.13 Dada la siguiente función de densidad \\[f(x) = \\left\\{ \\begin{array}{ll} 0.54\\,(1 + x - x^{2}) &amp; \\mbox{ si } -0.62 \\leq x &lt; 1.62\\\\ 0 &amp; \\mbox{ en cualquier otro caso } \\end{array}\\right.\\] calcule Prob[\\(X &lt; 0\\)], Prob[\\(-0.5 &lt; X \\leq 0.5\\)]. Prob Pr.14 Dada la siguiente función de distribución \\[F(x) = \\left\\{ \\begin{array}{ll} 0 &amp; \\mbox{ si } x &lt; 0\\\\ \\sin(1.13 \\log(x+1)) &amp; \\mbox{ si } 0 \\leq x &lt; 3\\\\ 1 &amp; \\mbox{ si } x &gt; 3 \\end{array}\\right.\\] calcule \\(P[X &lt; 0.7]\\), \\(P[0.7 &lt; X \\leq 2.2]\\) y \\(P[X \\geq 2.2]\\). Prob Pr.15 Dada la siguiente función de distribución \\[F(x) = \\left\\{ \\begin{array}{ll} 0 &amp; \\mbox{ si } x &lt; 0\\\\ e^{0.16 x}-1 &amp; \\mbox{ si } 0 &lt; x \\leq 3\\\\ 0.128 x + 0.232 &amp; \\mbox{ si } 3 &lt; x \\leq 6\\\\ 1 &amp; \\mbox{ si } x &gt; 1\\\\ \\end{array}\\right.\\] calcule \\(P[X \\geq 2]\\) y \\(P[1 &lt; X &lt; 5]\\) Prob Pr.16 Dada la siguiente función de densidad: k f(k) 1 0.22 2 0.05 3 0.21 4 0.11 5 0.09 6 0.08 7 0.13 8 0.05 9 0.06 calcule Prob[\\(X \\leq 5\\)] y Prob[\\(X = 4\\)]. Prob Pr.17 Dada la siguiente función de densidad: k f(k) 2 0.07 3 0.15 4 0.19 5 0.26 6 0.11 7 0.04 8 0.18 calcule Prob[\\(X \\geq 4\\)] y Prob[\\(2 &lt; X \\leq 7\\)]. Prob Pr.18 Calcule usando la siguiente función de distribución k F(k) 0 0.08 1 0.12 2 0.18 3 0.29 4 0.38 5 0.57 6 0.64 7 0.79 8 1.00 calcule \\(P[X &lt; 5]\\) y \\(P[2 &lt; X \\leq 6]\\). Prob Pr.19 Usando la siguiente función de distribución k F(k) 2 0.26 3 0.35 4 0.48 5 0.59 6 0.72 7 0.78 8 0.85 9 1.00 calcule Prob[X \\(=\\) 5] y Prob[3 \\(&lt;\\) X \\(\\leq\\) 8]. Prob Pr.20 En mi trabajo tengo que procesar el histórico de los últimos 50 años de fechas de reparación de máquinas. ¿Cuál es la probabilidad de que la próxima fecha coincida en día y mes con mi cumpleaños?¿En dia?¿En més? (suponga que todos los meses son de 30 días) ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.21 La distribución del espacio de pierna que necesita una persona en un avión es de 69,3 cm con una desviación típica de 1,7 cm. Si una compañía tiene un espacio de piernas en sus asientos de 72 cm ¿Qué porcentaje de personas van a estar apretadas? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.22 Tengo un taller de reparación rápida de móviles y de media tengo que cambiar 0,7 pantallas por semana. No me queda ninguna y tengo que hacer mi pedido semanal. ¿Cuántas pantallas tengo que pedir si quiero que la probabilidad de quedarme sin pantallas al final de la semana sea menor que 5%? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.23 Una centralita telefónica necesita exactamente 250 ms para gestionar una llamada y mientras la gestiona debe rechazar cualquier otra llamada que llegue. Llegan llamadas a una tasa de 3 por segundo.¿Cuál es la probabilidad de que una llamada sea rechazada? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.24 La probabilidad de que un bolígrafo de un lugar público funcione es del 63%. En el mostrador de una consellería hay 3 bolígrafos. ¿Cuál es la probabilidad de que pruebe 2 y ambos escriban?¿Y de que no escriba ninguno de los dos? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.25 La probabilidad de que un cable esté defectuoso es de 0.3%. Tengo un circuito con 37 cables que no funciona. He traído dos cables de repuesto (que seguro que están bien) ¿Cuál es la probabilidad de que no sea un problema de cables?¿Cuál es la probabilidad de que no me basten los que he traído? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.26 El diámetro de una clavija es de 4,5 mm con una desviación típica de 0,12 mm. Mido el agujero donde tiene que entrar la clavija y su diámetro es de 4,59 mm. ¿Cuál es la probabilidad de que la clavija entre en este agujero? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.27 En una empresa de fabricacion de cable eléctrico ven que de media hay 167 pequeños defectos en cada rollo de 1250 m. de cable. De estos grandes rollos crean rollos más pequeños de 20 m. Si en el rollo no hay ningún defecto es de clase A, si hay entre 1 y 3 es de clase B, si entre 4 y 6 es de clase C y si tiene 7 o más se desecha. ¿Cuál es la probabilidad de que un rollo sea de clase A, de clase B, de clase C o haya que desecharlo? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.28 El diámetro de una arandela tiene media 10 mm y desviación típica 0,07 mm. La tolerancia es de ±0,12 mm. ¿Qué porcentaje de arandelas está dentro de esta tolerancia? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.29 Existen dados de más de 6 caras. Partimos de un dado de 12 caras con números del 1 al 12. ¿Cuál es la probabilidad que de las próximas 12 tiradas obtengamos menos de 4 números primos? ¿Exactamente 2 números primos? ¿Más de 6 números primos? (Recuerde que el 1 no es primo) ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.30 Llegamos a un semáforo y está en rojo. Sabemos que este semáforo está en rojo exactamente 23 segundos. ¿Cuál es la probabilidad de que se ponga verde en menos de 5 segundos? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.31 De tanto en cuanto una centralita se desconecta durante 4,6 segundos para realizar diagnóstico y mantenimiento. Si la centralita recibe de media 10,3 llamadas por minuto ¿Cuál es la probabilidad de que en un periodo de mantenimiento ninguna llamada quede rechazada por este motivo?¿Y si recibe de media 17,3 llamadas por minuto? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.32 En un sorteo de lotería un número de cada 10 recibe el reintegro. ¿Cuál es la probabilidad de que en tres sorteos consecutivos obtenga el reintegro al menos una vez?¿Nunca? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.33 Mi ordenador falla y necesita reiniciarse 1,7 veces por mes.¿Cuál es la probabilidad de que funcione 2 semanas seguidas sin fallo?¿Y menos de 1 semana? (Suponemos que un mes equivale a 4 semanas) ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.34 La temperatura de salida del aire acondicionado es de media 4,3ºC, con una desviación típica de 0,55ºC. En un control de calidad he inspeccionado 12 unidades. ¿Cuál es la probabilidad de que ninguna tenga una temperatura de salida superior a 5ºC? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.35 Sé que hay 6 colores de chocolatinas en los paquetes de M&amp;M. En fábrica se fabrican exactamente 1/6 de cada color, después se mezclan bien y se meten 42 chocolatinas en cada bolsa. Esto hace que de media haya 1/6 de cada color en cada bolsa, pero cada bolsa es distinta. Mi amigo Jorge y yo hemos comprado una bolsa. Él sabe que mi color favorito es el verde y para fastidiar ha cogido exactamente 5 verdes. ¿Cuál es la probabilidad de que en el resto del paquete haya al menos otras 4 verdes?¿Que no quede ninguna? ¿Tipo de distribución y parámetros? ¿Qué probabilidades hemos de calcular? Instrucciones de R para calcular las probabilidades. Prob Pr.36 Tenemos una variable aleatoria con la siguiente función de masa: k f(k) 3 0.08 4 0.12 5 0.08 6 0.20 7 0.24 8 0.16 9 0.08 10 0.04 Calcule su esperanza y desviación típicas. Prob Pr.37 En https://loteriadelnino.laverdad.es tiene la lista de premios de la lotería de niño de 2020. Calculen la media y desviación típica de los premios. Prob Pr.38 Un tornillo pesa de media 2,3 g y tiene una desviación típica de 0,2 g. La caja donde vamos a meter 100 tornillos pesa exactamente 8,5 g. ¿Cuál es la media y la desviación típica de una caja de tornillos llena? Prob Pr.39 Tenemos un extraño robot que cada vez que avanza un paso, retrocede un pasito. Los pasos hacia adelante tienen una longitud media de 50 cm y una desviación típica de 8 cm, los pasitos hacia atrás tienen una media de 25 cm y una desviación típica de 4 cm. Después de dar 100 pasos hacia adeleante, con sus 100 pasitos atrás, de media ¿cuánto ha avanzado el robot?¿Cuál es la desviación típica? Prob Pr.40 La densidad del oro es de 19,3 g/cm\\(^3\\). Pesamos un conjunto de pepitas y el peso medio es de 188 g con una desviación típica de 37 g. ¿Cuál es la media y la desviación típica del volumen de las pepitas? Prob Pr.41 Me gusta vender cosas por internet. El precio de venta medio es de 23,74€, con una desvación típica de 9,32€. Por cada compra el sitio de intenet se lleva 0.25€ (fijos). Del resto, he de pagar un 20% a Hacienda. ¿De media, cuánto se lleva Hacienda por venta?¿Cuál es la desviación típica?¿Cuánto me llevo yo?¿Cuál es la desviación típica? Prob Pr.42 En Ruritania vemos que los hombres, con zapatos puestos, miden de media 175,2 cm con una desviación típica de 8,3 cm. No hemos podido medirlos descalzos (tiene unas manías muy raras), pero sí hemos podido medir la altura de los tacones de los zapatos: de media 4,3 cm con una desviación típica de 0,7 cm. ¿Cuál es la altura media de los hombres de Ruritania descalzos?¿Y su desviación típica? Prob Pr.43 En un proceso de fabricación tenemos un hueco donde hemos de colocar una barra. El hueco tiene una longitud media de 25 cm con una desviación típica de 0,3 cm. Las barras tiene una longitud media de 24 cm con una desviación típica de 0,15 cm. Hemos de centrar las barras en los huecos. De media, ¿qué holgura nos queda a cada lado?¿Cuál es la desviación típica de estas holguras? Prob Pr.44 Lean los datos del fichero colorPeloOjos.csv (pestaña de recursos). Creen la tabla de frecuencias absolutas y respondan a estas preguntas: Dentro de la muestra ¿Cuál es la probabilidad de tener ojos negros? ¿Cuál es la probabilidad de tener ojos castaños? ¿Cuál es la probabilidad de tener ojos verdes y pelo castaño? ¿Cuál es la probabilidad de que uno de pelo castaño tenga ojos verdes? ¿Cuál es la probabilidad de que uno de ojos verdes tenga pelo castaño? Prob Pr.45 Para hacer un transformador se apilan 112 láminas de acero oxidado. El grosor de las láminas sigue una distribución normal de media 732 micras con una desviación típica de 53 micras. ¿Cuál es la media y la desviación típica del grosor del bloque de 112 láminas? Una característica específica de la distribución normal es que la suma o resta de variables aleatorias que siguen una distribución normal también siguen una distribución normal. Las especificaciones del transformador obligan que la anchura del bloque de láminas esté entre 81 mm y 83 mm. ¿Cuál es la probabilidad de que un bloque no cumpla especificaciones? Si el problema es que es demasiado estrecho, simplemente se añaden más láminas, pero si es demasiado ancho hay que deshacer el bloque. ¿Qué porcentaje de los rechazados hay que deshacer? Prob Pr.46 El conjunto de datos faithful es parte de la distribución estándar de R. Para cada erupción del geiser Old Faithful, mide su duración en minutos y el tiempo que ha pasado desde la anterior erupción. Estudie la problematicidad de cada variable y la nube del puntos de ambas. Conteste a las siguientes preguntas: ¿Cuál es la probabilidad de que pasen entre 50 y 60 minutos entre erupciones? ¿Cuál es la probabilidad de que una erupción dure menos de 3 minutos?¿Y más de 4? Me dicen que la erupción anterior pasó hace 55 minutos. ¿Cuál es la probabilidad de que tenga que esperar menos de 30 minutos para la próxima erupción?¿Cuál es la probabilidad de que dure más de 4,5 minutos? Dada a problematicidad de las variables, ¿cuál cree que es la fiabilidad de estas predicciones? Prob Pr.47 El conjunto de datos cars es parte de la distribución estándar de R. Están indicados los datos de unas pruebas de frenado de hace casi 100 años. Tiene dos variables, speed, con la velocidad del coche en millas por hora, y dist, con la distancia de frenado en pies. Conviertan los datos a Km/h y metros. A pesar del tiempo que ha pasado, vamos a suponer que esta muestra es una representación fidedigna de toda la población de coches actual. Estudien la problematicidad de cada variable. Dibujen la nube de puntos con la velocidad en el eje X. Indiquen si los datos son nada, poco, bastante o muy problemáticos. Si la distancia de frenado en un accidente fue de al menos 20 metros, ¿cuál es la probabilidad de que el coche fuera a más de 30 Km/h? Si voy a menos 20 Km/h, ¿cuál es la probabilidad de que frene en menos de 7 metros? Veo unas huellas de frenado ya viejas, puedo medir 18 metros, pero el resto se ha difuminado y no puedo medir más. ¿Cuál es la probabilidad de que sean de al menos 26 metros?¿Y de menos de 22 metros? Prob Pr.48 En una distribución binomial, con \\(n = 15\\) y \\(p = 0.2\\), ¿cuál es la probabilidad de tener exactamente 6 “aciertos”?¿Y de tener más de 9? Prob Pr.49 Tenemos una variable aleatoria C que sigue una distribución exponencial con parámetro \\(\\lambda = 7.3\\), ¿Cuál es la probabilidad que \\(C &lt; 0.5\\)?¿Y que \\(C &gt; 0.1\\)? Prob Pr.50 En Español el tamaño de una palabra es de 4,94 letras, con una desviación típica de 3,06 letras. ¿Cuál es la longitud media (en caracteres) y la desviación típica de una frase de 10 palabras? No olvide considerar los blancos. Supondremos que no hay signos de puntuación. Prob Pr.51 En un aparcamiento en hora punta el 5% de las plazas están libres. Desde mi coche yo puedo ver 36 plazas. ¿Cuál es la probabilidad de que ninguno esté libre?¿De que haya sólo uno libre? En otro aparcamiento tienen esas luces verdes y rojas que me permiten saber si la plaza está libre. Ahora puedo ver el estado de 120 plazas desde mi coche, pero tengo dos coches delante que también están buscando aparcamiento. ¿Cuál es la probabilidad de que pueda aparcar en mi zona de visión? Prob Pr.52 Tengo en unas piezas con huecos de exactamente 35 mm y para rellenar estos hueco tengo regletas cuya longitud sigue una distribución normal de media 36 mm y desviación típica 1,3 mm. ¿Cuál es la probabilidad de que una regleta escogida al azar quepa en el hueco? La caja con las regletas está en otro piso y es una lata ir a por ellas. Tengo que rellenar los huecos de 5 piezas y cojo 8 regletas. ¿Cuál es la probabilidad de que no tenga que volver a por más? Prob Pr.53 En una centralita se reciben llamadas telefónicas de media cada 2,5 minutos. Cada llamada se contesta en exactamente 1,8 minutos. ¿Cuál es la probabilidad de recibir una segunda llamada mientras se está completando la primera? Prob Pr.54 Un equipo de baloncesto tiene un porcentaje de acierto en tiros libres del 81%. En un partido tira 18 tiros libres. ¿Cuál es la probabilidad de encestar los 18?¿Cuál es la probabilidad de encestar al menos 10? Prob Pr.55 El nivel de glucosa en sangre en ayunas de una persona sana es de \\(\\mu = 5,31\\) mmol/l con una desviación típica de \\(\\sigma = 0,58\\) mmol/l. Se pretende usar este nivel como prueba preliminar de diabetes y se establece que una persona con un nivel de glucosa en sangre mayor o igual a 6,5 mmol/l se considerará enferma de diabetes. ¿Qué porcentaje de gente sana se diagnosticará incorrectamente como diabética? Prob Pr.56 El 21% de los circuitos que me han enviado son defectuosos. He cogido 16 circuitos. ¿Cuál es la probabilidad de que ninguno sea defectuoso?¿Qué más de 6 lo sean? Prob Pr.57 La temperatura de salida del aire acondicionado es de media \\(4,3^{\\mathrm{o}}\\)C, con una desviación típica de \\(0,55^{\\mathrm{o}}\\)C. ¿Cuál es la probabilidad de que esté entre \\(4,0^{\\mathrm{o}}\\)C y \\(5,0^{\\mathrm{o}}\\)C?¿Y de que esté por encima de \\(6,5^{\\mathrm{o}}\\)C Prob Pr.58 En un centro de reparación llegan de media 3 aparatos averiados en garantía por semana. ¿Cuál es la probabilidad de que en una semana lleguen exactamente 6? Prob Pr.59 El peso de unas bolas de acero está entre 103 y 107 gramos. ¿El 25% de bolas más pesadas pesan más que cuánto? Prob Pr.60 A una central de reservas en línea llegan de media 3,2 peticiones por minuto. Acaba de llegar una petición. ¿Cuál es la probabilidad de que la próxima llegue en entre 10 y 15 segundos? Prob Pr.61 En una bolsa hay 1500 tuercas de las cuales 620 son de diámetro estrecho y el resto de diámetro ancho. Necesito 12 tuercas anchas. Saco 20 tuercas. ¿Cuál es la probabilidad de que voy a tener que sacar más tuercas? Prob Pr.62 Una prueba de diagnóstico es una prueba que quiere indicar si un objeto tiene una característica (la prueba da positivo) o no la tiene (la prueba da negativo). En medicina, típicamente el diagnóstico es para saber si se tiene o no una enfermedad. Pero los diagnósticos fallan y uno puede dar positivo y no tener la enfermedad y dar negativo a pesar de tenerla. Se llama sensibilidad de una prueba de diagnóstico a la probabilidad de que alguien con la enfermedad dé positivo; se llama especificidad de la prueba a la probabilidad de que alguien que no tiene la enfermedad dé negativo. Una buena prueba tiene una alta sensibilidad y especificidad. Estamos intentando usar la medida de glucosa en sangre como una manera simple de hacer un diagnóstico de diabetes. Sabemos que para una persona sana, el nivel de diabetes sigue una distribución normal con media de 5,31 mmol/l con una desviación típica de 0,58 mmol/l. Para una persona enferma de diabetes también sigue una distribución normal de media 11,74 mmol/l y desviación típica 3,50 mmol/l. La prueba sería escoger un nivel de glucosa en sangre. Si una persona supera este nivel se le diagnostica como diabético y si no lo supera se le diagnostica como sano. Estamos intentando encontrar el nivel óptimo para esta prueba. Consideremos niveles de 3,5 mmol/l a 10 mmol/l con incrementos de 0,5 mmol/l. Cree una tabla con una fila por nivel. En cada fila está el nivel, la probabilidad de que una persona sana esté por debajo del nivel y la probabilidad de que una persona con diabetes esté por debajo del nivel. Cree otra tabla con una fila por nivel. En cada fila está el nivel, la sensibilidad para este nivel y la especificidad para este nivel. Consideramos como punto de partida el nivel en el que la suma de sensibilidad y especificidad es máximo. ¿Cuál sería el nivel para el diagnóstico?¿Cuál es su sensibilidad?¿Y su especificidad? Prob Pr.63 Estamos estudiando el efecto de un fármaco para bajar la tensión sanguínea. Sabemos que de media el fármaco baja la tensión sistólica (la “máxima”) en 17 mmHg, con una desviación típica de 8 mmHg. Una persona hipertensa tiene una tensión sistólica de 165 mmHg. ¿Cuál es la probabilidad que el fármaco la baje a menos de 140 mmHg?¿Y de que se quede a más de 150 mmHg? Prob Pr.64 Soy el administrador de un sitio web. El sitio está configurado de manera que si llegan menos de 120 peticiones de acceso por minuto se pueden servir con una buena calidad de servicio, si son entre 120 y 150, se pueden servir con una calidad mediocre y si son más de 150, la calidad de servicio es mala. De media llegan 115 peticiones de servicio por minuto. ¿Qué porcentaje de minutos tienen buena calidad de servicio?¿Mediocre?¿Mala? Prob Pr.65 En una fábrica tenemos 3 cadenas de montaje: la cadena A que produce 1000 piezas al día y de las cuales el 1.6% son defectuosas, la cadena B que produce 2300 piezas al día y de las cuales el 0.3% son defectuosas y la cadena C que produce 7500 piezas al día y de las cuales el 0.08% son defectuosas. Nos traen una pieza defectuosa. ¿Cuál es la probabilidad de que sea de la cadena A?¿Y de la B?¿Y de la C? Prob Pr.66 Tenemos un sistema de calefacción y la temperatura sigue una distribución normal con media la temperatura que marca el termostato y queremos ajustar la desviación típica. Queremos que la probabilidad de que esté a más de 1.5\\(^{\\mathrm{o}}\\)C de la temperatura marcada por el termostato sea menor que 0.10. ¿Cuál es la desviación típica máxima que podemos tener? Por tener un margen de seguridad establecemos la desviación típica un 10% menor que la calculada. ¿Cuál es la probabilidad de que la temperatura sea mayor que 1.5\\(^{\\mathrm{o}}\\)C por encima de la temperatura del termostato?¿Y menor que 0.7\\(^{\\mathrm{o}}\\)C por debajo? Prob Pr.67 Tenemos una distribución continua de probabilidad con función de densidad \\[f(x) = \\left\\{\\begin{array}{ll} 0 &amp; \\mbox{ si } x &lt; 0\\\\ 0,5 x &amp; \\mbox{ si } 0 \\leq x \\leq 2\\\\ 0 &amp; \\mbox{ si } x &gt; 2 \\end{array}\\right.\\] y función de distribución \\[F(x) = \\left\\{\\begin{array}{ll} 0 &amp; \\mbox{ si } x &lt; 0\\\\ 0,25 x^2 &amp; \\mbox{ si } 0 \\leq x \\leq 2\\\\ 1 &amp; \\mbox{ si } x &gt; 2 \\end{array}\\right.\\] Calcule \\(\\mbox{Prob}[x \\leq 0.25]\\), \\(\\mbox{Prob}[0.3 \\leq x &lt; 1.4]\\), \\(\\mbox{Prob}[x &gt; 1.6]\\). Al menos una debe calcularla integrando la función de densidad. Prob Pr.68 Tenemos dos variables aleatorias \\(X\\) e \\(Y\\) y sabemos de sus distribuciones que \\(E[X] = 12.2\\), \\(E[Y] = 3.5\\) y las desviaciones típicas son de 1,8 y 0,60 respectivamente. Creamos dos variables aleatorias nuevas \\(Z = X - 3Y\\) y \\(T = 5X + 2.5Y\\). Calcule las esperanzas y desviaciones típicas de \\(Z\\) y \\(T\\). Prob Pr.69 Tenemos un sistema de diagnóstico para unos circuitos. En caso de que una máquina se estropee, pasamos el sistema de diagnóstico sobre el circuito para saber si es el “culpable” de la avería. Si el circuito está averiado, el diagnóstico de avería da positivo (indica que hay una avería) el 98% de las veces; si el circuito no está averiado, la prueba de diagnóstico da negativo (indica que el circuito es correcto) el 99% de las veces. Como vemos, a veces el diagnóstico se equivoca con falsos positivos (indica que est´averiado cuando no lo está) y falsos negativos (indica que está bien, cuando hay avería). Sabemos que ante una avería de la máquina, la probabilidad de que el circuito esté averiado es del 26%. Suponga que tenemos 1000 máquinas averiadas y pasamos el diagnóstico a los 1000 circuitos. Rellene la siguiente tabla: Prueba Averiado No averiado Total Positivo Negativo Total A partir de los valores de la tabla, calcule la probabilidad de que un circuito cuyo diagnóstico ha dado positivo está realmente averiado y la probabilidad de que un circuito que ha tenido un diagnóstico negativo realmente sea correcto. Prob Pr.70 Un problema típico de probabilidad es el llamado problema de Monty Hall. Está basado en un concurso televisivo americano. Tenemos 3 puertas. Tras una puerta está un coche y tras las otras dos, calabazas. El presentador, Monty Hall, le deja elegir una puerta. Después, abre una de las otras dos y aparece una calabaza. Finalmente, le permite cambiar de puerta si quiere. Demuestre que si Monty Hall abre una puerta tras la que sabe que hay una calabaza, nos conviene cambiar de puerta. Demuestre que si Monty Hall abre una puerta al azar (ha habido suerte y no ha salido el coche), nos es indiferente cambiar de puerta o no. Prob Pr.71 En un partido de tenis la probabilidad de que gane un punto el que tiene el servicio es de 0.56. ¿Cuál es la probabilidad de que gane un juego sin llegar al deuce? ¿Y de que lo haga el jugador que está al resto? (Para ganar sin llegar al deuce se deben ganar 4 puntos antes de que su contrincante gane 3) Prob Pr.72 Para que encestar un tiro libre sea una distribución binomial, la probabilidad de encestar un tiro libre debe ser independiente de los demás, pero pudiera ser que no lo sea: por ejemplo quizá si se acierta el primero haya una mayor probabilidad de acertar el segundo. Vamos a empezar por determinar si la probabilidad de acertar el primer tiro libre de un par es diferente de la probabilidad de acertar el segundo. Para obtener datos puede ir a ESPN y en la información de un partido (mejor los de la NBA que los universitarios) vaya a la pestaña de play-by-play. Para ser más eficiente, escoja partidos en los que se hayan tirado muchos tiros libres (lo verá en el box-score). Tome datos del primer tiro de cada par y del segundo tiro de cada par. Calcule las probabilidades y mire si son muy diferentes. De momento determíne “a ojo” si la diferencia es “grnde” o “pequeña” (más adelante veremos herramientas estadísticas para determinar esto). Prob Pr.73 Vean el video https://www.youtube.com/watch?time_continue=1&amp;v=zzKGnuvX6IQ En él se muestra un conjunto de 4 dados que llamaremos A, B, C y D. Si jugamos A contra B, A tiene mayor probabilidad de ganar una partida; si jugamos B contra C, B tiene mayor probabilidad de ganar; si jugamos C contra D, C tiene mayor probabilidad, pero si jugamos D contra A, D tiene mayor probabilidad de ganar. Es decir, A gana a B que gana a C que gana a D que gana a A. Estos dados no son transitivos (recordemos que la propiedad transitiva es la que dice que si A &gt; B y B &gt; C, entonces A &gt; C) Esto no es sólo un juego. Supongamos que cada dado es un medicamento para una enfermedad y que las 6 caras son 6 características de la población que ayudan o impiden el buen funcionamiento del medicamento. Las características pueden ser edad, tendencia genética a la hipertensión, características de alimentación, etc. El número de la cara es lo bien que va el medicamento X para alguien con esas características. Un 6 es que va muy bien (cura rápido y con pocos efectos secundarios) y un 1 es que va muy mal. Puede ser que a una persona el medicamento A vaya mejor que el B, a otra le vaya mejor el B que el C, a otra el C que el D y a otra el D que el A. Las interacciones son impredecibles y al final lo que le va a pasar al enfermo se puede modelar tirando estos dados. ¿Qué juego conocido tiene estas características? Explique algún otro caso cotidiano donde se dé esta intransitividad. Prob Pr.74 Supongamos una clase con 50 alumnos y supongamos también que la probabilidad de que el cumpleaños de un alumno caiga en un día determinado es equiprobable y que es independiente del de los demás (no hay gemelos). Suponemos también que hay 365 días en el año. Entonces Escogemos un día al azar. ¿Cuál es la probabilidad de que un alumno cumpla años ese día?¿Cuál es la probabilidad de que exactamente dos alumnos cumplan años ese día? Escogemos un alumno al azar. ¿Cuál es la probabilidad de que otro alumno cumpla años el mismo día? ¿Cuál es la probabilidad de que dos o más alumnos compartan cumpleaños? 15.5 Razonamiento estadístico. 15.5.1 Intervalos de confianza Prob RE.1 Mire el video Introducción empírica a los Intervalos de Confianza. Para responder a estas preguntas no es necesario hacer cálculo alguno, sino haber entendido los conceptos básico. Responda brevemente a todas las preguntas. Debe indicar no sólo la opción que escoge, sino sobre todo el por qué. Sin explicaciones su respuesta no vale nada. En el video sólo se calculó para el porcentaje del 90%, pero si aumento el porcentaje de muestras que incluye la horquilla La anchura de la horquilla aumenta La anchura de la horquilla disminuye La anchura de la horquilla no cambia Tengo dos encuestas de intención de voto hecho el mismo día. Para un partido uno da un IC de [34%, 40%] con una horquilla para el 90% y otro da [36%, 42%] con una horquilla para el 95%. Lo más probable es que proporción desconocida real esté Entre 36% y 40% (la intersección) Entre el 34% y 40% Entre el 36% y 42% Miro la proporción de personas que han pasado el sarampión y me ha salido una cierta horquilla. Si sólo miro los hombres de mi muestra La horquilla es más ancha La horquilla es más estrecha Tanto puede ser más ancha como más estrecha. Prob RE.2 Queremos contar monedas de 2€ simplemente apilándolas: como cada moneda tiene un grosor de 2,20 mm, si tenemos un medidor con una precisión de 0,5 mm, no debería haber problemas para contar cualquier número de monedas simplemente apilándolas y midiendo. Hacemos algunas pruebas preliminares y vemos que sí que hay un problema: debido a desgastes, suciedad, etc, el grosor es variable. Medimos muchas monedas y llegamos a la conclusión que el grosor medio sí que es 2,20 mm, pero tiene una desviación típica de 0,09 mm. Nuestro medidor de longitudes tiene una precisión de 0,5 mm, es decir que puede distinguir entre 220,3 y 220,9 mm, pero no entre 220,3 y 220,7 mm. Si queremos que la posibilidad de equivocarnos contando sea menor que el 1%, ¿cuál es el número máximo de monedas que puedo medir? Prob RE.3 En un IC de proporciones el error estándar, y por lo tanto la anchura del intervalo, depende del valor de \\(\\hat{\\theta}\\). Queremos hacer una encuesta y asegurar una cierta anchura del intervalo, pero si depende de \\(\\hat{\\theta}\\), no podemos saber cuántas personas hemos de encuestar antes de hacer la encuesta. Para resolver este problema se coge el peor caso: el valor de \\(\\hat{\\theta}\\) que nos da el intervalo más ancho. Calcule qué valor de \\(\\hat{\\theta}\\) maximiza el error estándar. Preferiblemente hágalo analíticamente; en todo caso hágalo numéricamente o gráficamente. Para este peor caso de \\(\\hat{\\theta}\\) calcule el número mínimo de encuestas que debo realizar si quiero que la anchura de mi IC sea del 9% o menos (equivalentemente, [\\(\\theta- 0.045;\\; \\theta + 0.045\\)] ) con un nivel de confianza del 90%. Repita si el nivel de confianza es del 95%. Prob RE.4 En el problema ED.6 se obtuvieron datos de métodos de estudio de al menos 90 personas. Había 4 niveles: Leer de libros Leer de apuntes Escribir (ya sea en los apuntes, en el ordenador o resolviendo problemas) Hablar (trabajo en equipo) Los resultados obtenidos en un estudio fueron Método Turmeda Cifre Hostelería Jovellanos Orfila Escribir 25 34 3 11 8 L. Apuntes 5 28 0 14 7 L. Libro 2 2 0 4 3 Hablar 1 1 0 1 0 Si el valor de \\(\\hat{\\theta}\\) no es demasiado extremo, calcule el intervalo de confianza de los cuatro métodos de estudio en conjunto y por biblioteca. Dibuje en una gráfica los intervalos de confianza de métodos globales. No hace falta que usen R para este dibujo. A partir de sus cálculos y gráficas, ¿considera que hay suficiente evidencia para decir que hay diferencias en la proporción que usa cada método de estudio? Prob RE.5 Coja algún objeto cotidiano que pueda medir con suficiente precisión: el diámetro de una naranja, el peso de un peluche, la longitud de un paraguas, lo que usted quiera. Debe medir un conjunto suficiente de objetos. Estudie su problematicidad (si es más problemático de lo que pensaba, quizá necesite medir más). Calcule su media y el intervalo de confianza de la media. Las medidas deben tomarse con fiabilidad y precisión. Fiabilidad significa que si los midiera otra persona con el mismo método obtendría los mismos valores; precisión significa que nos podemos fiar del último dígito: por ejemplo, si dice que el peso es 0,27 Kg quiere decir que no es 0,28 Kg ni 0,26 Kg, pero no sabemos si es 0,273 Kg o 0, 276 Kg. La precisión debe ser suficiente para observar la variabilidad de los objetos. Muestre su estudio de problematicidad y justifique que tiene suficientes datos. Muestre sus cálculos del intervalo de confianza. Prob RE.6 El objetivo es estudiar lo que afecta al cálculo del IC de medias el que la distribución de la población sea problemática. Para crear una población muy problemática y otra nada problemática use las siguientes instrucciones: pobl_P = c(rnorm(1000, 30, 2), rexp(500, 1), rnorm(5, 100, 3)) pobl_NP = rnorm(1000, 20, 2) Calcule las medias para cada población. Después repita 200 veces: coja una muestra de tamaño 6 para cada población, calcule su intervalo de confianza de medias con un nivel de confianza del 92%. Puede crear una función para calcularlo, aunque no es imprescindible. No puede usar funciones ya existentes en R. mire para cada intervalo de confianza si la media de la población correspondiente está o no en el intervalo. Con un nivel de confianza de 0.92, tocaría haber unos 184 intervalos con la media en ella. ¿Es así para la población no problemática?¿Y para la problemática? Vuelva a repetir con muestras de tamaño 30. ¿Hay 184 intervalos con la media en ella para la población no problemática?¿Y para la problemática? Escriba un párrafo conclusiones de sus resultados. Debe entregar su guión de R, el resumen de sus resultados (sólo un resumen) y su conclusión. Puede añadir gráficos si le parece que ayudan a ver mejor las cosas. Prob RE.7 Queremos saber si en los 80 el baloncesto era más ofensivo que en la actualidad. Como muestra vamos a coger los partidos de las finales de conferencia y de la final de la NBA de 1985 y del año pasado. Consideraremos como variable el número total de puntos en cada partido, sumando los puntos de ambos equipos. Estudie la problematicidad de los datos. Si lo cree necesario, añada los partidos de las semifinales de conferencia (añadir datos si no es necesario es un error penalizable). Aunque sólo sea problemático uno de los dos conjuntos de datos, si añade las semifinales, debe hacerlo a ambos conjuntos. Calcule el IC de la media para cada año y el IC de la diferencia de medias (puede usar la función t.test() de R). Decida si la evidencia que tiene le permite decir si hay una diferencia o no en el número de puntos marcados entonces y ahora. Prob RE.8 Hemos mejorado la producción de una pieza. El objetivo es reducir el porcentaje de fallos en una cierta prueba en 3 puntos porcentuales (por ejemplo de 12% a 9%) y reducir el peso en 30 gramos. En el fichero P15.csv tiene los datos de 500 piezas, 250 del proceso original y 250 del nuevo proceso, con el peso de cada pieza y si ha fallado o no. Estudie la problematicidad de las variables “Peso” y “Fallo”, tanto en conjunto como para cada método de producción. Calcule y dibuje los intervalos de confianza de peso medio y proporción de fallos para cada método de producción. Los IC de proporciones los puede dibujar si quiere como barras de error. Para los de medias puede usar la función t.test(), para los de proporciones utilice el método explicado en los documentos y video (no use prop.test()) Calcule los IC de diferencias de medias y proporciones (en este caso sí debe usar prop.test()). A partir de todas las pruebas hechas decida si se ha conseguido o no el objetivo. Su respuesta debe ser un “sí” o un “no” seguido de las matizaciones que deban hacerse. Prob RE.9 El fichero Alturas2013.csv contiene datos recogidos durante 3 cursos académicos sobre la altura de los alumnos, sus padres y sus madres. Contiene 6 variables: Talla: la talla del alumno, TallaP y TallaM: las tallas de su padre y su madre respectivamente; Sexo: el sexo del alumno; Duplicado: si el dato está duplicado (repetidores que introdujeron sus datos más de una vez), y Curso: el curso en el que se recogió la información. Vamos a utilizar este fichero para comparar las alturas de las personas de esta generación respecto a las personas de la generación anterior. Empecemos con la lectura del fichero. No están todos los datos de todas las personas: verán que hay varios NA. Elimine todas las filas en las que haya un NA. La función complete.cases() sirve para esto: “DF = DF[complete.cases(DF),]” le dejará sólo los casos sin NA. Comparemos primero las alturas de los hombres de esta generación y la anterior. No podemos coger las variables Talla y TallaP de los alumnos masculinos y compararlos pues estaríamos comparando hijos con sus propios padres y eso no es independiente. Lo que haremos es dividir los 162 individuos en dos grupos de 81 y compararemos los hijos de un grupo con los padres del otro. Haremos la división al azar con sample(). Para que todos obtengan exactamente la misma división “fijamos” la secuencia aleatoria con set.seed(). Las instrucciones a utilizar son set.seed(135) Hijos = sample(1:162, 81) Padres = (1:162)[-Hijos] Ahora “Hijos” contiene los índices del data frame que usaremos para leer las tallas de los alumnos y “Padres” contiene los demás índices, que usaremos para obtener las tallas de los padres. Con esto, ya podemos comparar. Estudie la problematicidad de las variables “Talla” y “TallaP”, para cada muestra (no en conjunto). Calcule y dibuje los intervalos de confianza de la talla media de hijos y de padres. Calcule también el intervalo de confianza de la diferencia de medias. Puede usar t.test() para todo. A partir de estos intervalos de confianza, indique si la altura de esta generación es o no más alta que la de la generación anterior. Si lo es, indique por cuánto (con la confianza debida). Valore la seguridad con la que puede hacer sus afirmaciones sus afirmaciones en función de la problematicidad, calidad y tamaño de la muestra, resultados obtenidos, etc. A continuación vamos a comparar las alturas de las mujeres. El problema aquí es diferente: hay muy pocas alumnas. Lo que haremos es comparar la altura de las alumnas con las de las madres de los alumnos hombres: así evitamos el problema de la dependencia de valores. Estudie la problematicidad de las variables “Talla” y “TallaM”, para cada muestra (no en conjunto). Calcule y dibuje los intervalos de confianza de la talla media de hijas y de madres. Calcule también el intervalo de confianza de la diferencia de medias. Puede usar t.test() para todo. A partir de estos intervalos de confianza, indique si la altura de esta generación es o no más alta que la de la generación anterior. Si lo es, indique por cuánto (con la confianza debida). Valore la seguridad con la que puede hacer sus afirmaciones sus afirmaciones en función de la problematicidad, calidad y tamaño de la muestra, resultados obtenidos, etc. Prob RE.10 Habíamos estudiado desde el punto de vista de la estadística descriptiva el tiempo de reacción de personas en función de sexo, edad y si estaban utilizando el móvil. Los datos de partida están en el conjunto de datos reaction.time en el paquete UsingR. Vamos a continuar el estudio calculando los intervalos de confianza. Estudie la problematicidad de los datos para poder valorar la fiabilidad de los intervalos de confianza obtenidos Calcule 6 intervalos de confianza de la media de tiempos de reacción: dos en función del sexo de la persona; dos en función de la edad de la persona, y dos en función de si la persona usaba móvil o no Dibuje esos 6 intervalos de confianza en una sola gráfica. Son variables numéricas: no use barras de error, sino segmentos. No son 6 segmentos, sino 3 pares de segmentos: la separación entre pares debe ser mayor que la separación entre los segmentos de cada par. Añada texto en la gráfica misma para marcar la variable de cada par (Sexo, Edad y Móvil) y el nivel dentro de cada par (“M” y “F” para sexo; “J” y “A” (Joven y adulto) para edad;“Sí” y “No” para móvil). No es difícil de hacer con la función text(): http://www.sthda.com/english/wiki/add-text-to-a-plot-in-r-software Calcule los 3 intervalos de confianza de la diferencia. Cree un gráfico con los 3 intervalos y añada el texto. A partir de estos intervalos de confianza indique si alguna de estas tres variables influye en el tiempo de reacción. Si más de una lo hace, indique cuál. Valore la seguridad que tiene en su afirmación. Prob RE.11 Estamos cansados de los malditos selfies, creemos que hay demasiados.Entramos en Instagram y de alguna manera cogemos una buena muestra de 250 fotos, de las cuales 84 son selfies.¿Cuál es el error estándar?Con un nivel deconfianza de 97%, ¿cuál es el intervalo de confianza de la proporción de selfies? Prob RE.12 Dos amigos nos hemos puesto a mirar la proporción de coches rojos en nuestros barrios. En mi barrio, de 174 coches, 49 son rojos. En el suyo, de 459 coches, 135 son rojos. Calcule los errores estándar y los dos intervalos de confianza para un nivel de confianza del 95%. Repita para un nivel de confianza del 92%. Prob RE.13 Muchas veces las encuestas cogen muestras de tamaño 1000. Si suponemos una proporción muestral del 50%, ¿cuál es la anchura de la horquilla si el nivel de confianza es del 95%? Prob RE.14 Según el contrato el porcentaje aceptable de componentes defectuosos de un proveedor es de 12%. En la última remesa que nos ha llegado hemos cogido una muestra de 128 componentes y 17 han sido defectuosos. Calcule los intervalos de confianza para niveles de confianza del 85%, 90% y 95%. ¿Está el 12% dentro de los intervalos? Prob RE.15 Hemos medido la temperatura de un circuito integrado y hemos obtenido los valores 45, 50, 51, 47, 43, 52, 49, 55, 48 Calcule \\(\\hat{\\mu}\\), el error estándar y los intervalos de confianza de medias para niveles de confianza del 85%, 90% y 95%. Prob RE.16 El conjunto de datos morley, disponible en la distribución base de R contiene datos de medidas de la velocidad de la luz de un experimento hecho en 1879. Fueron 5 experimentos (variable Expt con valores de 1 a 5) y en cada uno se tomaron 20 medidas de la velocidad de la luz. El valor medido está en la variable Speed y es de \\(299\\,000\\) Km/seg más lo que sale en esa variable (es decir, si aparece un 850 quiere decir que la velocidad medida fue de \\(299\\,850\\) Km/seg; si aparece 1070, la velocidad medida fue de \\(300\\,070\\) Km/seg). Considérelo un único experimento con 100 medidas y calcule el error estándar y la velocidad media con un nivel de confianza del 99%. Prob RE.17 El conjunto de datos ToothGrowth, disponible en la distribución base de R contiene datos del crecimiento de dientes en cobayas. Hay tres variables. La primera es len, la longitud del diente. La segunda es supp, que indica el suplemento vitáminico que ha tomado la cobaya. Puede ser zumo de naranja (OJ) pastillas de vitamina C (VC). La tercera variable es dose, la dosis (0,5; 1,0 o 2,0), en miligramos por día. Podemos mirar conjuntamente estas dos variables y considerar que hay 6 posibles niveles según el tratamiento y dosis. Calcule el intervalo de confianza de la media de la longitud de los dientes de las cobayas para cada uno de los 6 niveles con un nivel de confianza del 95%. Prob RE.18 Queremos comparar los resultados de la función prop.test() de R y el método explicado en los documentos y videos. Calcule el IC de proporciones con el método manual si tenemos 288 éxitos de 414 intentos. Repita si tenemos 16 éxitos de 23 intentos. Ambos casos tienen el mismo \\(\\hat{\\theta}\\) pero diferente valor de \\(n\\). Calcule ambos intervalos de confianza con prop.test(). Compare los resultados con ambos métodos. Prob RE.19 Ahora queremos comparar los resultados de usar t.test() y el método explicado en los documentos y videos. Calcule los intervalos de confianza de las medias para los valores 6.63, 3.22, 4.14, 2.31, 4.63, 3.33, 1.50, 8.70, 0.23, 4.21 Debería obtener exactamente los mismos resultados. Prob RE.20 Tenemos transistores de dos fabricantes y que deberían ser equivalentes. Tomamos una muestra de 8 transistores de cada fabricante y medimos la ganancia. Los resultados son: Fabricante 1 Fabricante 2 112 113 111 120 122 118 113 118 111 118 117 120 115 122 114 119 Usando la función t.test() de R calcule el IC de la diferencia. ¿Son indistinguibles? Prob RE.21 En un proceso obtenemos 187 “aciertos” de 302 intentos. Calcule \\(\\hat{\\theta}\\) y el error estandar. Prob RE.22 Tengo una distribución normal, centrado en 0.229 y con desviación típica 0.0224. ¿Qué intervalo, centrado en el mismo punto que la distribución, da un 90% de probabilidades de que un valor cogido al azar esté en él? Repita para una probabilidad de 0.97. Prob RE.23 En un proyecto en el que estamos trabajando vamos a calcular 8 intervalos de confianza. Queremos una probabilidad de 0.75 de que el valor real esté dentro de todos los intervalos. ¿Qué nivel de confianza mínimo necesitamos? Generalice su estudio para el caso que tengo \\(n\\) intervalos de confianza y quiero una probabilidad \\(P\\) de que el valor real esté dentro de todos los intervalos. Prob RE.24 En un control de calidad hemos visto que 175 de 206 productos cumplen con todas las especificaciones. Calcule con el método explicado en clase la proporción muestral (\\(\\hat{\\theta}\\)), el error estándar y el intervalo de confianza para niveles de confianza de 0.87, 0.92 y 0.96. Prob RE.25 Hemos medido la ganancia de un conjunto de 8 transistores y hemos obtenido una ganancia media de 112, con una desviación típica de 9. Calcule el error estándar y el intervalo de confianza de la ganancia media para un nivel de confianza del 95%. Prob RE.26 En el fichero notparc.csv tiene las notas de un examen parcial. La puntuación del examen podía ir de 0 a 58 puntos. Pueden ver que hay dos modelos de examen y nos interesa saber si hay diferenciasde calificaciones entre los dos modelos. Empecemos por mirar las medias. Calcule el intervalo de confianza de las medias de cada modelo y el intervalo de confianza de la diferencia de las medias. Use la función de R t.test() sólo para calcular el IC de la diferencia. Otra manera de comparar los modelos es viendo si el porcentaje de aprobados es diferente. Calcule el porcentaje de aprobados de cada modelo usando el método visto en clase (no use prop.test()). Calcule después el intervalo de confianza de la diferencia usando prop.test(). Estudien las medias entre los dos modelos y los porcentajes de aprobados. Calculen los intervalos de confianza adecuados. A partir de los resultados obtenidos, indiquen si los dos modelos se pueden considerar o no de igual dificultad. Deben dar una respuesta (sí o no), explicar su razonamiento en función de sus resultados y matizarla con la seguridad que tienen en su afirmación. No olviden tener en cuenta la problematicidad de los datos. Prob RE.27 El lunes 14 de marzo apareció en el ABC una encuesta que augura una subida del PSOE en el estimación electoral. En una encuesta de febrero el PP obtenía el 27,9% de los votos, el PSOE el 20,8%, Podemos el 21,4% y Ciudadamos el 14,9%, mientras que en la de marzo el PP obtenía el 28,2% de los votos, el PSOE el 24,2%, Podemos el 18,7% y Ciudadamos el 14,1%. No aparece la ficha técnica de la encuesta (un error del periódico) por lo que no sabemos a cuánta gente se entrevistó ni los intervalos de confianza. Supongamos que se entrevistaron a 800 personas (un número bastante habitual). ¿Cuáles son los márgenes de confianza con un nivel de confianza del 95%?¿Podemos decir que ha habido una variación en la intención de voto en alguno de los 4 partidos? Prob RE.28 Al hacer una encuesta (o tomar una muestra), unos de los problemas principales es el tamaño de la muestra. Supongamos que queremos un intervalo de confianza de \\(\\pm 7.5%\\) con un nivel de confianza del 90%. ¿Cuál debe ser el tamaño de la muestra? Si tiene que hacer suposiciones, póngase en el peor caso. Prob RE.29 En una fábrica de componentes hay dos líneas de producción. En una 143 de 500 pasan el control de calidad. En la otra 86 de 270 lo hacen. Calcule el intervalo de confianza de la diferencia de proporciones. Prob RE.30 En unas bodegas medimos la concentración de azúcar de un camión de uva que nos acaba de llegar. Tomamos una muestra de 8 medidas con los valores 2.3, 2.8, 3.1, 2.7, 2.4, 2.5, 2.7, 2.9. Calcule el intervalo de confianza de la concentración media de azúcar de la uva del camión. Prob RE.31 En un experimento para estudiar el efecto del formato sobre las encuestas Childers y Ferrell compararon el porcentaje de personas que respondieron a un cuestionario impreso en una hoja a dos caras y el mismo cuestionario pero impreso en dos hojas separadas. Enviaron el cuestionario de una sola hoja a una muestra de 220 personas y se lo devolvieron completado 80 personas. Enviaron la versión en 2 hojas a otras 220 personas. ¿Cuántas respuestas deberían obtener para obtener un intervalo de confianza de la diferencia que no contenga el 0? Suponga un nivel de confianza del 95%. Prob RE.32 Estamos comparando la robustez ante excesos de tensión de dos componentes. Para medirla sometemos al componente a una tensión un 50% mayor que la especificada y medimos el tiempo que pasa hasta que deja de funcionar (se “quema”). Las medidas (en minutos) son las siguientes: Componente 1 Componente 2 13.6 18.4 12.0 9.2 11.8 15.9 7.2 17.7 10.7 18.4 7.5 16.2 17.6 12.0 12.3 15.2 9.5 14.6 Dibuje los puntos y el intervalo de confianza de la media de tiempo de quema de cada componente. ¿Cuál es el intervalo de confianza de la diferencia de medias?¿Diría que hay una diferencia entre la robustez de los componentes o las diferencias observadas pueden ser simplemente variación de la muestra? Prob RE.33 En su conferencia, Josu Mezo protesta de las noticias de prensa que usan de encuestas pero que no reconocen la existencia del intervalo de confianza. Escoja un periódico, el que usted quiera. Escoja las 10 noticias más recientes que obtengan datos de encuestas. Lea las noticias y responda a las siguientes preguntas: ¿En cuántas encuestas aparece la ficha técnica (número de encuestados, fechas en las que se realizó, intervalos de confianza, etc)? Puede que la ficha aparezca en el gráfico o que en la noticia haya un enlace a ella. ¿En cuántas noticias se reconoce que existe un intervalo de confianza (o una horquilla como a menudo lo llaman)? ¿En cuántas noticias se usa el valor de \\(\\hat{\\theta}\\) como si fuera \\(\\theta\\), es decir, sin tener en cuenta la incertidumbre inherente al muestreo? ¿En cuántos hay un error en la noticia debido a esto? Debe entregar los datos bibliográficos de las noticias (bastan las URL si están en linea), las respuestas a las preguntas (que son 4 números), 4 o 5 ejemplos relevantes de errores y una valoración suya final. Prob RE.34 Los tiros libres del baloncesto son una buena fuente de estudio: está el tirador, la canasta y nadie más. No importa si el equipo es mejor o peor, si el contrario defiende mejor o peor. Vamos a comparar tiradores de tiros libres en competiciones diferentes. Escoja al menos 4 ligas diferentes. Un ejemplo podría ser ACB, NBA, LF1 y WNBA (o ACB, LEB Oro, LEB Plata y algún otro). Es imprescindible que tenga la información necesaria en las estadísticas: tiros libres lanzados y anotados (el porcentaje solo no basta). Calcule los intervalos de confianza del mejor tirador de cada liga (use prop.test() no lo calcule a mano) y los intervalos de confianza de las diferencias. Muestre los datos, los intervalos de confianza y sus conclusiones sobre los resultados. Prob RE.35 Vamos a considerar las 3 muestras siguientes de una variable cualitativa. En la primera hemos obtenido 28 “éxitos” de 50 intentos, en la segunda, 42 “éxitos” de 75 intentos y en la tercera, 112 “éxitos” de 200 intentos (la proporción es la misma siempre). Calcule los intervalos de confianza (con el método mostrado en clase, no con prop.test) para niveles de confianza de 0.85, 0.95 y 0.99 (un total de 9 IC). Muestre los intervalos numéricamente y gráficamente (no es necesario que las gráficas las haga con R). Prob RE.36 He estado observando en el campus que de 84 alumnos (41 de ellos chicos) sólo 38 llevaban reloj en la pulsera (17 de ellos chicos). Calcule los intervalos de confianza con nivel de confianza de 85%, 90% y 95% de la proporción de chicos, chicas y alumnos que llevan pulsera (un total de 9 intervalos). Prob RE.37 Cree una función de R para crear los intervalos de confianza de proporciones. La función tiene 4 parámetros de entrada con estos nombres: par: que puede ser el número de “éxitos”, o la proporción medida (\\(\\hat{\\theta}\\)) en función del valor de exitos n: el número de intentos nc: el nivel de confianza. Por defecto tiene el valor de 0.90 exitos: indica si el primer parámetro es el número de aciertos o \\(\\hat{\\theta}\\). Por defecto vale TRUE (el primer parámetro es el número de aciertos) La función devuelve una lista con tres elementos: el primero es un vector de dos posiciones: los límites inferior y superior del intervalo de confianza, el segundo es un vector de una posición: la proporción medida, y el tercero es el error estándar. Para crear la lista con los 3 vectores necesitan la función list(v1, v2, v3). Utilice la función para calcular estos dos intervalos: 37 aciertos de 84 intentos con un nivel de confianza del 95% \\(\\hat{\\theta}\\) de 0.479 con 3215 intentos y un nivel de confianza del 90% Debe entregar la definición de la función y la sesión de R en donde se usa para calcular estos dos intervalos. Prob RE.38 Tomamos una muestra de baterías de teléfonos móviles y consideramos que la carga es adecuada si el nivel de carga es mayor que el 70%. De los 84 teléfonos de la muestra 21 tienen una carga superior al 70%. ¿Cuál es el Intervalo de Confianza de la proporción de móviles con una carga adecuada si el nivel de confianza es del 85%?¿Y si es del 95%? Prob RE.39 Vamos a hacer una encuesta y queremos que la horquilla sea de \\(\\pm 4%\\) con un nivel de confianza del 90%. Suponga que \\(\\hat{\\theta} = 60%\\). ¿A cuántas personas debemos preguntar?¿Y si \\(\\hat{\\theta} = 28%\\)? Normalmente no sabemos \\(\\hat{\\theta}\\) antes de hacer la encuesta. Lo que se suele hacer es coger el “peor” caso, es decir, el que hace el intervalo más ancho. ¿Cuál es el peor caso? Prob RE.40 Nunca nos debemos olvidar que hay una probabilidad no nula de que el valor de \\(\\theta\\) esté fuera del intervalo. Supongamos que en un proyecto hemos de calcular muchos intervalos de confianza y que el nivel de confianza es del 95% en todos ellos. Si he acabado calculando 8 intervalos ¿cuál es la probabilidad de que en uno o más casos el valor de \\(\\theta\\) esté fuera del intervalo? 15.5.2 Contrastes de hipótesis Prob RE.41 El fichero CuatroTramp2020.xlsx, en la pestaña de recursos, tiene los resultados del Torneo de los Cuatro Tampolines, de saltos de esquí de 2020. Muestra los 318 saltos válidos que se hicieron. Tiene 4 variables: Distancia: la distancia del salto del esquiador (en metros) Ronda: la ronda del salto (hay dos rondas en cada competición, los 30 mejores de la primera pasan a la segunda ronda) Trampolin: el nombre del trampolin (hay 4, naturalmente) K: el punto de cálculo (en metros) Cada trampolín tiene sus características: unos son más largos, otros más cortos. El valor K da una idea de esto. Supongamos que el objetivo es que los saltadores de media salten K metros. Para el conjunto de los 4 trampolines, miren si esto es cierto. Hay una dificultad que deben sortear: cada trampolín tiene su valor de K. Hay al menos dos maneras de hacerlo. Indiquen cómo sortean esta dificultad, la hipótesis nula, la alternativa y el p-valor obtenido. Prob RE.42 En los últimos 5 años, de 414 alumnos que han cursado la asignatura, 288 han aprobado. El objetivo es que apruebe el 75% de los alumnos. Obtenga los resultados relavantes con la función prop.test(). Haga el razonamiento estadístico correspondiente. Prob RE.43 Quiero comprarme un programa capaz de leer textos. Uso la versión gratuita de un programa que asegura que lee bien el 85% de las palabras. Lo pruebo y si efectivamente reconoce al menos un 85% de las palabras lo compraré. Si no, no. Pongo un texto de 276 palabras y reconoce adecuadamente 243 palabras. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es o no consistente con la hipótesis nula. Prob RE.44 Estamos diseñando un refrigerador de circuitos y queremos compararlo con el de la competencia. Nos conformamos si refrigera al menos igual de bien. Cogemos 20 circuitos típicos y ponemos nuestro refrigerador (RN) en 10 y el de la competencia (RC) en otros 10 y medimos las temperaturas. Son RN: 56.8, 57.1, 56.3, 57.9, 57.4, 58.1, 58.5, 59.4, 56.0, 59.2 RC: 62.0, 57.2, 58.9, 59.4, 57.6, 58.6, 61.3, 58.6, 59.5, 61.8 Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.45 Nos interesa saber si los debates televisados influyen en la intención de voto. Comparamos las intenciones de voto antes y después de un debate televisado entre dos candidatos. Antes del debate 214 de 500 encuestados prefirieron al candidato A. Después del debate, 201 de 435 encuestados prefirieron al candidato A. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.46 Hemos cambiado la maquinaria de la cadena de producción de nuestra fábrica, que esperamos funcione mejor que la que teníamos. En una prueba comparamos el número de aparatos que necesitan retoques por no cumplir especificaciones. Con la vieja el 14.3% de los aparatos necesitaban retoques. Hacemos una prueba con la nueva y de 512 aparatos fabricados, 53 necesitan retoques. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.47 Una de las primeras maneras de medir la velocidad de la luz consistió en hacer que un rayo de luz fuera a un espejo muy lejano y vuelta y mediante unos engranajes medir cuánto tiempo tardaba en ir y volver. En un experimento de Simon Newcomb en 1822, el espejo estaba a 3721 metros de distancia y obtuvo los siguientes valores de tiempo (en \\(\\mu s\\)): 24.824, 24.828, 24.837, 24.832, 24.820, 24.825, 24.825, 24.836, 24.836, 24.821, 24.828, 24.826, 24.832, 24.828, 24.826, 24.830, 24.836, 24.829, 24.830, 24.822. La velocidad de la luz en el aire es es \\(299\\,705\\,543\\)~m/s. Queremos saber si midió bien. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.48 Hemos creado un nuevo sistema de climatización de un edificio. En la encuesta que pasamos con el sistema antiguo 36 de 52 personas se declararon a gusto con la temperatura. Con el nuevo sistema 58 de 81 entrevistados se declaran a gusto. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.49 Estamos comparando dos controladores de potencia para saber si la eficiencia de ambos es igual o no. Los consumos medidos (en Kw\\(\\cdot\\)h) de un controlador son 0.80, 0.79, 0.91, 0.67, 0.77, 0.61, 0.69, 0.99, 0.98, 0.73, 0.95, 0.71, 0.86 y del otro 0.62, 1.01, 0.99, 0.66, 0.64, 0.88, 0.78, 0.76, 0.51, 0.57, 0.62, 0.71, 0.59. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.50 Nos dicen que tras hacer un poco de ejercicio la memoria mejora (el corazón bombea más sangre, el cerebro recibe más oxígeno, etc.). Diseñamos una prueba de memoria que consiste en recordar objetos que aparecen en una pantalla de ordenador. Cogemos 10 personas, que denominaremos P1, P2, …, P10) y les hacemos la prueba de memoria en reposo y tras ejercicio (son las mismas personas en ambos casos). Los resultados son Individuo Reposo Tras ejercicio P1 5 6 P2 8 8 P3 7 6 P4 5 8 P5 6 7 P6 8 10 P7 4 5 P8 9 7 P9 7 7 P10 6 8 Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es o no consistente con la hipótesis nula. Prob RE.51 Según el contrato el porcentaje aceptable de componentes defectuosos de un proveedor es del 12%. En la última remesa que nos ha llegado hemos cogido una muestra de 95 componentes y 11 han sido defectuosos. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.52 Un compañero nos dice que es capaz de leer mentes. Para comprobarlo, vamos mirando cartas de una baraja y le pedimos que lea en nuestra mente de qué palo es la carta. Leemos 104 caras y e indica el palo correctamente 29 veces. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.53 Según las especificaciones, la temperatura de un circuito en plena carga debe ser de 65.0\\(^{\\mathrm{o}}\\)C. Cogemos 10 circuitos, los ponemos a plena carga y medimos las temperaturas. Los valores obtenidos son: 66.7, 65.1, 66.2, 65.9, 66.7, 66.7, 66.3, 65.4, 64.7, 66.2 Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.54 Estamos calibrando un amperímetro. Comparamos lo que lee el aparato con intensidades calibradas y que podemos considerar exactas. Los errores obtenidos son \\[-0.03;\\; 0.2;\\; 0.13;\\; 0.41;\\; -0.06;\\; 0.39;\\; 0.24;\\; -0.05;\\; 0.14;\\; 0.22\\] Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.55 Estamos comparando dos cadenas de producción del mismo producto. En particular estamos comparando el número de aparatos que necesitan retocar por no cumplir especificaciones. En la cadena A, de 230 aparatos fabricados, 38 necesitan retoques. En la cadena B, de 242 aparatos fabricados, 53 necesitan retoques. Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.56 Estamos estudiando si un aditivo para la gasolina aumenta la potencia del coche. Para ello medimos el tiempo para acelerar de 0 Km/h a 100 Km/h primero sin aditivo, y después con. Lo hacemos 8 veces sin y otras 8 con. Los resultados son: Sin: 7.8, 6.9, 7.2, 8.8, 7.7, 7.7, 7.4, 8.0 Con: 7.1, 7.7, 7.6, 7.4, 6.4, 7.1, 6.9, 6.8 Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.57 Partimos de los datos del conjunto de datos notparc.csv (en pestaña de recursos). Hay dos modelos de examen y es necesario un 29 para aprobar. Mirando las proporciones de aprobados de ambos modelos, ¿es un modelo de examen más difícil que el otro? Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es o no consistente con la hipótesis nula. Prob RE.58 Partimos de los datos del conjunto de datos notparc.csv (en pestaña de recursos). Hay dos modelos de examen y es necesario un 29 para aprobar. Mirando las notas medias de ambos modelos, ¿es un modelo de examen más difícil que el otro? Enuncie la hipótesis nula, la alternativa, calcule el p-valor correspondiente e indique si le parece que el resultado obtenido es ono consistente con la hipótesis nula. Prob RE.59 En el problema RE.9, a partir de los datos del fichero Alturas2013.csv, se comparaba las alturas de alumnos y alumnas con sus padres y madres respectivamente. Comentábamos entonces que la altura de una persona no es independiente de la de su padre o hijo.Por lo tanto si comparamos las alturas de los padres y los hijos directamente estamos violando la exigencia de independencia de los datos. Una forma de resolver este problema es calcular qué porcentaje de alumnos son más altos que sus padres.Así podemos usar todos los datos y no mitad y mitad, ya que estamos comparando pares padre-hijo y los pares sí que son independientes. Además, podemos juntar chicos y chicas. Establezca la hipótesis nula y la alternativa.Calcule la proporción de alumnos que son más altos que sus padres, el intervalo de confianzay el p-valor. NOTA: Un problema que podemos tener es que haya muchos alumnos con la misma altura que sus padres. Compruebe si es así y si lo es, resuélvalo de alguna manera. Prob RE.60 (Continuación de problema RE.59) Otra forma de abordar la cuestión es ver cuánto más alto es de media un hijo que su padre. Otra vez,podemos usar todos los datos y no mitad y mitad, ya que estamos comparando pares padre-hijo y los pares sí que son independientes. Aquí sí que conviene separar otra vez entre chicos y chicas, puees las diferencias pueden ser diferentes en un caso y en otro. Establezca la hipótesis nula y la alternativa.Calcule la media de la diferencia de alturas (Alumnos - Padres), el intervalo de confianza y el p-valor. Repita con las alumnas y madres. Prob RE.61 Para tener la calificación energética A+ un horno debe consumir menos de 1,5Kw\\(\\cdot\\)h en un periodo de 2 horas a 170\\(^{\\mathrm{o}}\\)C. Se escogen al azar 10 hornos de un fabricante, se mide su consumo y los resultados son 1.8, 1.7, 1.2, 1.4, 1.3, 1.9, 1.9, 1.8, 1.4, 1.6 Indique las hipótesis nula y alternativa y calcule el p-valor. Prob RE.62 Existe la teoría de que el color del coche está correlacionado con la cantidad de accidentes en la que está involucrado. Una compañía de seguros quiere comprobar si es así, coge una muestra de 500 coches rojos y ve que 87 han estado involucrado en accidentes, mientras que de una muestra de 500 coches blancos, 76 han estado involucrado en accidentes. Indique las hipótesis nula y alternativa y calcule el p-valor. Prob RE.63 Según el contrato el porcentaje aceptable de componentes defectuosos de un proveedor es de 12%. En la última remesa que nos ha llegado hemos cogido una muestra de 37 componentes y 6 han sido defectuosos. Calcule el intervalo de confianza, escriba la hipótesis nula y la alternativa y calcule el p-valor. Prob RE.64 Según las leyes de la herencia, el 35% de una cierta población de insectos debería tener las alas oscuras. En una población de 712 individuos, 244 tienen las alas negras. Calcule el estadístico \\(t_{0}\\) y el p-valor dada la hipótesis nula \\(\\theta_{0} = 0.35\\) y la alternativa de que es distinto. Prob RE.65 El data frame normtemp del paquete UsingR contiene datos sobre la temperatura de 130 personas sanas. La temperatura está en grados Fahrenheit y la temperatura considerada normal (el correspondiente a nuestros 37.0 ºC) es de 98.6ºF. Calcule el intervalo de confianza, escriba la hipótesis nula y la alternativa y calcule el p-valor. A partir de sus cálculos responda: ¿es razonable nuestra definición de fiebre como el tener 37ºC o más? Prob RE.66 Según nuestras especificaciones el grosor de un circuito impreso es de 3.25 mm. En una inspección hemos medido 20 circuitos y nos ha dado una media de 3.28 mm con una desviación típica de 0.023 mm. La hipótesis alternativa es de que el grosor es mayor. Calcule el estadístico \\(t_{0}\\) y el p-valor. 15.5.3 Razonamiento estadístico complejo Prob RE.67 Supongamos que tenemos un proceso de fabricación de jarras. Medimos el peso de las jarras y obtenemos lo siguiente: 7.89, 7.91, 7.95, 8.25, 8.47, 8.65, 8.82, 9.15, 9.29, 9.36, 9.45, 9.48, 9.54, 9.69, 10.39, 10.61, 10.66, 11.20, 11.81, 11.99, 12.27, 12.29, 12.98, 13.94, 14.84 Pueden ver que sigue aproximadamente una distribución normal. Calculando \\(\\hat{mu}\\) y \\(\\hat{\\sigma}\\) podemos modelar estos datos mediante una distribución normal con media \\(\\hat{mu}\\) y desviación típica \\(\\hat{\\sigma}\\). Esto nos permite predecir cosas: por ejemplo, que hay una cierta probabilidad de tener una jarra con un peso menor que 3; o hay una cierta probabilidad de tener una jarra con un peso entre 5.3 y 6.1. Pero sabemos que hay una incertidumbre en la media (y en la desviación, pero en estos momentos lo dejamos fijo). Veamos como influye esta incertidumbre en nuestra capacidad de predicción. Calculen el IC de la media. Sea \\(\\mu_\\min\\) el extremo inferior del IC y \\(\\mu_\\max\\) el otro. Indique cuanto mayor porcentualmente es \\(\\mu_\\max\\) respecto a \\(\\mu_\\min\\). Coja el intervalo [\\(\\mu_\\min - 3\\cdot \\hat{\\sigma},\\; \\mu_\\max + 3\\cdot \\hat{\\sigma}\\)]. Divida este intervalo en 10 subintervalos de la misma longitud. Para cada subintervalo calcule dos probabilidades: la de tener un peso de jarra dentro de él suponiendo que la media es \\(\\mu_\\min\\) y lo mismo con \\(\\mu_\\max\\). Esto nos indica la incertidumbre predictiva dentro de ese intervalo. Para cada subintervalo, calcule cuánto mayor porcentualmente es la probabilidad mayor respecto a la menor. Ponga todo en una tabla adecuada y dé su opinión de la incertidumbre predictiva del modelo. Prob RE.68 El conjunto de datos UCBAdmissions son datos reales de admisión de alumnos a la Universidad de California, Berkeley. Se indica para cada una de 6 facultades (Departments) el número de hombres y mujeres que fueron admitidos y rechazados. Compare la proporción de hombres admitidos y mujeres admitidas en el total acumulado. Calcule el p-valor y el IC. ¿Se puede decir que hay diferencia?¿A favor de quién? Compare la proporción de hombres admitidos y mujeres admitidas para cada uno de las 6 facultades. Calcule el p-valor y el IC. ¿Se puede decir que hay diferencia?¿A favor de quién? Lea la entrada de la Wikipedia de la Paradoja de Simpson. Explique los resultados obtenidos. Prob RE.69 Partimos de las alturas de alumnos y sus padres que encontrarán en el fichero Alturas2013.csv (pestaña de lecturas obligatorias). Queremos comparar las alturas de los hombres actuales con los de hace una generación. Para ello comparamos las alturas de los alumnos con los de sus padres. El problema es que los datos deben ser independientes y la altura de un hijo no es independiente de la de su padre. Para ello vamos a dividir al azar a los alumnos en dos grupos iguales y de un grupo cogeremos las alturas de los alumnos y del otro la de sus padres. Extraiga del fichero todos los datos completos de alumnos varones que no sean duplicados. Mediante sample() escoja la mitad de los datos. De esta mitad cogeremos las alturas de los alumnos y de la otra cogeremos la de los padres. Compruebe que los datos son poco o nada problemáticos y calcule los intervalos de confianza de medias de cada uno y el intervalo de confianza de la diferencia. Como hemos separado al azar, repita los cálculos varias veces para ver si hay variación. Debe entregar el script usado, los resultados relevantes y sus conclusiones. Prob RE.70 Un error muy habitual es pensar que el p-valor indica la probabilidad de que H0 sea cierto. Para ver que no es así hagamos los siguientes cálculos. Cogemos 21 monedas. Sea pc la proporción de caras y estas monedas van desde totalmente trucada hacia cruz (pc = 0) a totalmente trucada hacia cara (pc = 1) a cualquier valor intermedio en incrementos de 0.05. Es decir, las proporciones de cara de las 21 monedas sonpc = 0, pc = 0.05, pc = 0.1, pc = 0.15, etc. Supongamos que tiramos las monedas 20 veces. Es una binomial y podemos calcular para cada moneda la probabilidad de que salgan 0 caras, 1 cara, …, 20 caras. Podemos crear una matriz, donde cada fila representa una moneda y cada columna un resultado (0 caras, 1 cara…). Los principios de las tres primeras filas serían: 1.0000, 0.0000, 0.0000… 0.3585, 0.3774, 0.1887, 0.0596, 0.0133, … 0.1216, 0.2702, 0.2852, 0.1901, 0.0898, … Cada fila nos da una idea de la probabilidad de obtener un resultado en función de la pc de la moneda. Esto está relacionado con el p-valor. En cambio, cada columna nos da una idea de la probabilidad de cuál es la moneda en función del resultado obtenido. Esto está relacionado con la probabilidad de que la hipótesis nula sea cierta. Nótese que he dicho “da una idea”. Por ejemplo las columnas no suman 1 y no pueden ser probabilidades. Cree dos matrices, una en la que podamos leer la probabilidad de obtener un resultado en función de la moneda y otra en la que se pueda leer la probabilidad de tener una moneda en función del resultado. Dibuje una única gráfica con las probabilidades de tener cada resultado (0 cara, 1 cara, etc) para las monedas de pc = 0, pc = 0.3, pc = 0.5 y pc = 0.8. Como la variable es discreta, debe ser un diagrama de barras agrupado. Dibuje una única gráfica con las probabilidades del valor de pc para los resultados 3 caras, 8 caras, 10 caras, 15 caras y 20 caras. Como pc es continua (aunque aquí sólo hemos cogido 21 valores), dibújelo como líneas (nubes de puntos con type = “l”). Debe entregar su guión, las dos gráficas y comentarios adecuados. Prob RE.71 Veamos lo buenos que son dos métodos simples de predicción de partidos de fútbol. Para simplificar eliminamos los empates y en vez de ganar/perder tenemos resultado positivo/resultado negativo. Para el equipo de casa el único resultado positivo es ganar, para el de fuera, tanto empatar como ganar son resultados positivos.Las dos estrategias simples son: Estrategia 1: obtiene resultado positivo aquel que tiene más puntos en la clasificación en el momento de jugarse el partido. En caso de tener los mismo puntos, el resultado positivo es para el equipo de casa. Estrategia 2: obtiene resultado positivo aquel cuyo cociente Goles favor/goles contra es mayor en el momento de jugarse el partido. En caso de empate, se lo damos al de casa. Consideramos sólo las jornadas 24, 25, 26 y 27 de la Liga Santander de este año, para un total de 40 partidos. Los resultados están disponibles, pero desgraciadamente la clasificación por jornada, parece que no (o al menos yo no lo he encontrado): tendrán que recrearlas yendo para atrás desde la jornada 27. Calculen, usando prop.test() los intervalos de confianza y los p-valores. Determine si una estrategia es mejor que la otra y si alguna de las dos es mejor que el azar. Escriba claramente las hipótesis nulas, alternativas, los p-valores obtenidos y su interpretación de los resultados. No use sólo el p-valor para la interpretación. Prob RE.72 El objetivo de la estadística es poder hacer predicciones. Por ejemplo, el objetivo de una encuesta de investigación de mercado es saber cuánta gente esta dispuesta a comprar un producto a un cierto precio. Supongamos que tenemos una encuesta de 800 personas. En esta encuesta 178 indican que comprarían un producto. Usamos esta encuesta para predecir el stock que debo tener en el almacén de un producto perecedero. Hago un pedido cada semana y al final de la semana debo tirar todo lo que sobre. Si el pedido es grande, tendré que tirar mucho, pero si es pequeño, me quedaré sin antes del final de la semana y quedo mal ante los clientes. Decido calcular dos valores extremos y a partir de ellos, decidir. El valor superior es comprar suficiente para que la probabilidad de quedarme sin producto al final de la semana sea menor que el 2%. El valor inferior es que de media deba tirar a final de la semana el 5% del pedido. El número de clientes que viene cada semana es muy constante: 1150 personas. El que compren o no el producto se puede considerar una binomial. Hagan el contraste de hipótesis correspondiente con prop.test() y calculen el intervalo de confianza (nivel de confianza del 95%). Partiendo de \\(\\hat{\\theta}\\), calculen los valores superior e inferior del pedido semanal que debo hacer. Si compro el valor inferior, ¿cuál es la probabilidad de que me quede sin producto al final de la semana? Si compro el valor superior, ¿qué porcentaje del pedido deberé tirar de media al final de la semana? Considerando el intervalo de confianza, calcule el valor superior e inferior del pedido suponiendo que la proporción de clientes que lo compran es algún valor desconocido, pero dentro del intervalo. Si compro el valor inferior, ¿cuál es la probabilidad de que me quede sin producto al final de la semana? Si compro el valor superior, ¿qué porcentaje del pedido deberé tirar de media al final de la semana? Prob RE.73 El conjunto de datos stud.recs del paquete UsingR contiene datos de los SAT (una especie de selectividad que hacen en EEUU). La columna sat.v contiene la calificación de la parte verbal y sat.m contiene la calificación de la parte matemática de 160 exámenes. Los exámenes están diseñados para que la calificación media de cada parte sea de 500. Para ver si están bien diseñados, calcule los intervalos de confianza adecuados y haga los contrastes de hipótesis corresondientes. Siempre existe el temor de que la parte matemática es más difícil. Vamos a hacer dos pruebas. En la primera, veamos el porcentaje de alumnos que han sacado mejor o igual nota en la parte verbal. Calcule el intervalo de confianza adecuado y haga el contraste de hipótesis corresondiente. La segunda prueba es mirar la media de la diferencia entre la nota de cada parte para cada alumno. Esto se puede hacer de dos maneras: restando y despues haciendo un t-test del vector o introduciendo los dos vectores en t.test() e indicando “paired = TRUE”. Hágalo de las dos maneras y compruebe que da el mismo valor. Calcule el intervalo de confianza adecuado y haga el contraste de hipótesis corresondiente. Prob RE.74 Hemos creado una nueva rueda para bicicleta y queremos saber si es mejor que las ruedas convencionales. Para ello hemos cogido a 60 ciclistas, les hemos hecho rodar 10 minutos con la rueda convencional (grupo de control) y otros 10 minutos con la nueva rueda (grupo tratamiento 1). Hemos recogido la distancia recorrida en ese tiempo y lo hemos metido en una tabla. Ahora queremos analizarlo. Haga un estudio de estadística descriptiva de los datos. Hacemos tres estudios inferenciales. Empiece por establecer la hipótesis nulas y alternativas para los tres estudios. Supondremos los niveles de confianza del 95%. Empecemos por la diferencia de medias. Escriba la hipótesis nula, la alternativa y calcule el p-valor y el intervalo de confianza. Sigamos por la proporción de ciclistas que se benefician con la nueva rueda. Escriba la hipótesis nula, la alternativa y calcule el p-valor y el intervalo de confianza. Acabemos con la media de las diferencias de distancias.Escriba la hipótesis nula, la alternativa y calcule el p-valor y el intervalo de confianza. Cree una tabla con los IC y los p-valores para las tres pruebas. Con la tabla, las gráficas de estadística descriptiva y su sentido común, haga un análisis de las nuevas ruedas. Prob RE.75 Los datos para las preguntas siguientes están en metro_res.csv y metro_vol.csv. Los puede descargar del Aula Digital. Queremos comprar unos multímetros digitales para nuestra empresa. Tenemos dos candidatos: el modelo A y el B. Decidimos probarlos para ver si hay diferencia entre ellos. Hemos tomado 10 medidas sobre 5 resistencias calibradas (total de 50 medidas con cada modelo) y sobre 5 voltajes calibrados (otras 50 con cada modelo), para un total de 200 medidas. Haga un estudio de estadística descriptiva de los datos. Hacemos tres estudios inferenciales. Empiece por establecer la hipótesis nula y alternativa para los tres estudios. Supondremos los niveles de confianza del 95%. Puede usar las funciones de R t.test() y prop.test(). El error porcentual es el tanto por ciento de la diferencia en valor absoluto entre el valor medido y el real. Por ejemplo una medida de 199 sobre un valor real de 200 es un error porcentual de 0,5%. Vamos a empezar por comparar los errores medios porcentuales de ambos modelos en las medidas de resistencias, de voltajes y conjunto. Calcule los p-valores y los intervalos de confianza. Seguimos comparando la proporción de medidas de cada modelo que son “suficientemente buenas”. Vamos a considerar que si el error porcentual es menor que 0.7% es “suficientemente buena”. Compare las proporciones de ambos modelos para voltajes, resistencias y conjunto. Calcule los p-valores y los intervalos de confianza. Acabamos comparando las proporciones de medidas qeu son “realmente malas”. Consideramos que una medida “realmente mala” es una cuyo error porcentual es mayor que 2%. Compare las proporciones de ambos modelos para voltajes, resistencias y conjunto. Calcule los p-valores y los intervalos de confianza. Prob RE.76 La web Five-thirtyEight tiene una página interactiva que calcula p-valores a partir de datos de economía americana y de quién está al mando. Se pueden escoger muchas variaciones en ambos casos. Por ejemplo se puede escoger como indicador económico la inflación, el PIB, la tasa de empleo o los índices de bolsa y en el gobierno si consideramos el presidente, gobernadores, congreso (representatives) o senado. Hay algún otro parámetro adicional. Busque una combinación de entradas que sólo a partir del p-valor “demuestre” que los Demócratas son buenos para la economía. Busque otra combinación que “demuestre” que los Demócratas son malos para la economía. Busque una combinación de entradas que “demuestre” que los Republicanos son buenos para la economía. Busque otra combinación que “demuestre” que los Republicanos son malos para la economía. Explique lo que ha hecho (le puede ser útil leer el artículo relacionada con esta página: Science isn’t broken. 15.6 Anova Prob A.1 Imagine que es un guionista para el desaparecido programa “Cazadores de mitos” (Mythbusters en ingles). El objetivo del programa es, dado un mito urbano, crear un experimento y a partir de los resultados obtenidos, decidir si queda confirmado, es posible o queda cazado. Si no ha visto el programa, hay episodios en YouTube. El objetivo de esta tarea es que proponga un experimento que necesite un Anova como parte estadística, y que sea adecuado para el programa. Debe indicar el mito, proponer el experimento y indicar el Anova que habría que hacer para determinar si es confirmado, posible o cazado. Se valorará especialmente la parte “televisiva”: que el experimento sea espectacular, entretenido, curioso, divertido… Prob A.2 Partimos del fichero CuatroTrampolines.xlsx disponible en la pestaña de recursos. Este fichero contiene todos lo saltos del torneo de cuatro trampolines de este invierno pasado. Contiene 4 variables: Distancia: la distancia saltada por el saltador Ronda: en cada competición hay dos rondas. 50 saltan en la primera ronda; los 30 mejores saltan una segunda vez Trampolín: el nombre del trampolín. Hay 4, naturalmente. K: Como cada trampolín es distinto hay un valor llamado “K” que caracteriza la “longitud básica” del trampolín. Lo primero que queremos saber es si este valor K está bien puesto. Debería pasar que los saltos en los 4 trampolines, respecto de K fueran iguales. Hay dos maneras de hacerlo: Restar K de cada salto. Así, si K = 120 un salto de 120 m se convertiría en un salto de 0 m; un salto de 118 metros, en uno de -2 metros; uno de 131 m, en un salto de 11 m. Dividir entre K. Con K = 125, un salto de 125 metros se convierte en un salto de 1,000; Uno de 121 m se convierte en uno de 0,968; uno de 137 m, en uno de 1,096. Para cada uno de las dos maneras, mire primero si se puede considerar que los datos son normales en cada trampolín (independiente de la ronda). Si son razonablemente normales, calcule el ANOVA para saber si el salto medio teniendo en cuenta la K es el mismo en los 4 trampolines. Indique cuál es H0, Ha, el p-valor y su conclusión. Si con un método le sale que sí y con el otro que no, establezca qué método es mejor para nuestros fines. Una segunda pregunta es si realmente hay diferencia entre los saltadores de la primera ronda y de la segunda, o si es más una cuestión de suerte el pasar a la segunda ronda. Compare la longitud media de todos los saltadores de la primera ronda y todos los saltadores de la segunda ronda. Puede usar un t-test. Si ha concluido que sólo hay un método bueno para tener en cuenta la K, use ese. Si no, use ambos. Escriba H0, Ha, el p-valor y su conclusión. Prob A.3 En un estudio se midió el efecto de cuatro metodos de comprensión lectora.Los datos los tiene en lectura.txt (pestaña de recursos). El método Map consiste en realizar un mapa conceptual durante la lectura. El método Scan consiste en realizar dos lecturas: primero una rápida para coger las ideas principales y después una lenta para profundizar. Both es hacer ambas cosas: dos lecturas y un mapa conceptual. Neither es el grupo de control, en el que no usan ninguno de los métodos. Se realizaron dos medidas de comprensión lectora una antes de enseñarles uno de los métodos y otros después. La columna increase muestra la diferencia (después – antes). ¿Qué sentido tiene incluir el método Neither? Haga un estudio, lo más completo que pueda, y establezca si los datos de este estudio sugieren que hay métodos que son mejores que otros. Prob A.4 A partir del conjunto de datos Cars93 (del paquete UsingR) determinen, usando la prueba ANOVA y los intervalos de confianza con TukeyHSD, si la potencia media de los coches de una determinada categoría son todos iguales o no. Si el resultado es que no, decidan si hay tipos de coche con la misma potencia media o no. Prob A.5 Usaremos unos datos (inventados) del nivel de colesterol en función de 6 dietas: Mediterránea, Vegetariana, Hiper protéica, Paleo, la de la clínica Mayo y el grupo de control que no ha hecho dieta alguna. Queremos saber si hay correlación entre la dieta y el nivel de colesterol. En particular queremos saber qué dieta es mejor para bajar el nivel de colesterol. Descarguen los datos del Aula Digital y léanlos en su sesión de R. Están en el fichero Dietas.csv. Tiene dos variables, una llamada Colesterol, que es numérica y otra llamada Dieta, que es cualitativa. Hay 15 personas por dieta. Determine si los niveles de colesterol para cada dieta pueden considerarse normales o no. Si hay una que no lo es, elimínela. Si hay varias, tendríamos que parar ya (y utilizar otros métodos), pero continuaremos de todas formas, pero teniendo en cuenta que la fiabilidad de la prueba será baja. Calcule la media y la desviación estándar del nivel de colesterol de cada dieta. Realice un boxplot del colesterol en función de la dieta. A partir de los realizado en el paso 2, decida qué función de Anova va a utilizar. Realice el Anova. Apunte la hipótesis nula, la alternativa, el valor de F y el p-valor. A partir de las medias calculadas, el boxplot y el resultado del Anova, decida si se puede considerar que las medias de colesterol para todas las dietas son iguales o no. A partir de su estudio de problematicidad y de si los datos se pueden o no considerar normales, atribuya una fiabilidad a los cálculos (de poco fiable a muy fiable). A partir del boxplot y las medias calculadas, elimine uno a uno las dietas que cree que se salen del conjunto y que hacen que no se puedan considerar iguales las medias. Siga hasta que considere que las medias son indistinguibles. Mire las desviaciones típicas del conjunto que le queda.¿Se pueden considerar iguales? Si la respuesta es sí, calcule mediante la función TukeyHSD los intervalos de confianza. Si la respuesta es no, mire el nivel de confianza necesario para que el nivel de confianza conjunto sea del 95% y calcule los intervalos de confianza de cada nivel (puede usar la función t-test). Dibújelos en una sola gráfica. ¿Corroboran los IC su idea de que las medias de estas dietas no pueden considerarse distintos? Escriba sus conclusiones sobre al influencia de estas dietas en los niveles de colesterol. Prob A.6 Una empresa de material para ciclismo deportivo ha creado un sistema de bielas asimétricas para mejorar el rendimiento del ciclista. Quieren comparar su sistema con los platos redondos normales y con los platos ovalados (otro método de mejora de eficiencia) que comercializa otra marca. Hicieron el siguiente experimento: Asignaron de forma aleatória 45 ciclistas a 3 grupos diferentes. Les hicieron pedalear sobre rodillos en una bicicleta normal el equivalente a 10 Km y les midieron los tiempos (t_base). Después, durante 15 días todos los ciclistas entrenaban durante una hora: el grupo de control sobre bicicletas normales, el grupo “ovalado” sobre bicicletas con plato ovalado y el grupo “asimétrico” sobre el sistema de bielas asimetricas. Tras los 15 días les hicieron otra prueba otra vez sobre 10 Km (t_experim) cada uno con el sistema sobre el que habían entrenado. Los datos se encuentran en ExpPlatos.csv Hay razones para creer que los valores de los tiempos son aproximadamente normales. De todos modos mírelos por si se desviasen mucho (recuerde que son sólo 15 datos por tiempo y grupo). Lo primero que queremos establecer es si los grupos están bien formados, con ciclistas de capacidades similares. Realice un ANOVA sobre los tiempos de base de los 3 grupos. No se olvide de mirar las desviaciones típicas para determinar qué ANOVA hace. Lo segundo que queremos establecer es si hay diferencia en el tiempo experimental. Realice un ANOVA con los tiempos experimentales. Si se pueden considerar que las desviaciones típicas son iguales, calcule también los intervalos de confianza con la función TukeyHSD. Si no, calcúlelos con un nivel de confianza adecuado para que haya un 95% de probabilidades que todas las medias reales estén en los intervalos. Lo tercero es mirar si ha habido mejoría entre los tiempos de cada ciclista en cada uno de los grupos. Calcule la mejor ade tiempo, t_experim – t_base, en los 3 grupos (un tiempo negativo es una mejora). Realice el ANOVA adecuado de la mejora de tiempo. Si se pueden considerar que las desviaciones típicas son iguales, calcule también los intervalos de confianza con la función TukeyHSD. Si no, calcúlelos con un nivel de confianza adecuado para que haya un 95% de probabilidades que todas las medias reales estén en los intervalos. Prob A.7 En un estudio se midió el efecto de cuatro vacunas contra la tos ferina. Tiene los datos en tosferina.txt. WCV es una vacuna muy utilizada, APV es una vacuna experimental y DAPV es esta misma vacuna, pero con una dosis mayor. El dato numérico es la concentración de anticuerpos (una medida de la eficacia de la vacuna) un mes después de vacunado. Miren los datos y eliminen el error. Realicen un ANOVA sobre los datos. Escriban la hipótesis nula, la alternativa, el valor del estadístico F y el p-valor. Prob A.8 El conjunto de datos PlantGrowth del paquete MASS tiene datos del rendimiento (medido en peso seco) de plantas cultivadas sin tratamiento (ctrl) y con dos tratamientos distintos (trt1 y trt2). Queremos saber si los tratamientos son mejores que el control, y si ambos son mejores, si hay diferencia entre ellas. Compare los tres tratamientos mediante un ANOVA. ¿Es mejor cualquier tratamiento que no tratar?¿Es un tratamiento mejor que el otro? Prob A.9 El data frame mtcars contiene información de 32 coches de 1974. El consumo está medido en millas por galón (mpg), las millas que ser pueden recorrer con un galón USA de combustible (los galones en Canadá y UK son algo mayores que en USA). Cree un data frame con tres columnas: consumo (en la medida europea de litros/100 Km), cilindros (el número de cilindros) y transmisión (“A” para automático y “M” para manual). Considere el numero de cilindros como un factor. Estudie si coches con diferente número de cilindros consumen de media valores diferentes, y lo mismo para los dos tipos de transmisión. Prob A.10 A la hora de hacer un ANOVA queremos a menudo saber las medias y desviaciones típicas de la variable numérica para cada nivel del factor. Para facilitar este proceso, cree una función llamada MyD(). Los parámetros de entrada son: x: el data frame con los datos cols = c(1,2): un vector de dos posiciones con las columnas donde están la variable numérica y el factor. Por defecto la variable numérica está en la columna 1 y el factor en la columna 2. Fíjense que el vector tiene un orden: no es lo mismo c(1,2) que c(2,1) Como salida nos da un lista con tres vectores. El primer vector son los niveles, tal y como los da la función levels() aplacada a la columna de factor. El segundo vector son las medias y el tercero son las desviaciones típicas. El orden de estos dos vectores es el mismo que el de niveles, es decir, que la primera media es la correspondiente al nivel que aparece primero en el vector de niveles, y así sucesivamente. Debe entregar un script con la definición del vector y dos o tres ejemplos de uso. 15.7 Ji-cuadrado ProbJ.1 Los números que han salido en los 2698 sorteos de la primitiva celebrados hasta el momento son: Número Veces | Número Veces | Número Veces 1 335 | 18 311 | 34 319 2 316 | 19 320 | 35 339 3 350 | 20 300 | 36 333 4 323 | 21 324 | 37 338 5 345 | 22 339 | 38 334 6 345 | 23 349 | 39 361 7 332 | 24 308 | 40 363 8 302 | 25 321 | 41 326 9 331 | 26 323 | 42 345 10 337 | 27 329 | 43 326 11 329 | 28 315 | 44 313 12 320 | 29 344 | 45 328 13 322 | 30 340 | 46 354 14 334 | 31 325 | 47 323 15 337 | 32 318 | 48 362 16 324 | 33 319 | 49 343 17 330 ¿Es un sorteo limpio? ProbJ.2 Hicks y Bautista estudiaron la relación entre roncar y tener pesadillas. Pasaron una encuesta a 199 personas y obtuvieron los siguientes resultados de la frecuencia de pesadillas: Tipo Nunca Casi nunca Ocasional Frecuente Siempre No roncador 22 45 35 7 4 Roncador 16 31 27 10 2 ¿Hay diferencia en la frecuencia de tener pesadillas entre los roncadores y los que no roncan? ProbJ.3 En una encuesta se preguntó a conductores si habían estado involucrados en algún accidente durante el año anterior, y si había sido grave o leve. Los resultados del tipo de accidente, tabulados por grupos de edades, son los siguientes: Edad Ninguno Leve Grave Menor que 18 67 10 8 \\(18 - 25\\) 42 6 9 \\(26 - 40\\) 75 8 7 \\(40 - 65\\) 56 4 6 Mayor que 65 57 15 1 Queremos saber si las dos variables son independientes. Indique el tipo de prueba de \\(\\chi^2\\) que debe usarse, la hipótesis nula, la alternativa, el valor del estadístico y el p-valor. Hay un problema de fiabilidad del estadístico. Indique cómo cree que debería resolverse en este caso. ProbJ.4 Cuando Intel sacó su procesador Pentium lo vendió en dos especificaciones: el P120 (120 MHz) y el P80 (80 MHz). No es que fabricara dos tipos diferentes de procesadores. Sólo fabricaba uno, pero si en el control de calidad era capaz de fucionar a 120 MHz lo vendían como P120, si no era capaz de funcionar a 120 MHz pero sí a 80 MHz lo vendían (más barato) como P80, y si no, lo tiraban. Y esto pasa en muchos productos: hay un único proceso de fabricación pero en función de si cumplen o no ciertas especificaciones se venden de una manera u otra (por ejemplo bajo una marca secundaria). En una fábrica de multímetros digitales tenemos dos líneas de montaje, L1 y L2. La línea L2 es más moderna y produce más circuitos incluso funcionando menos horas y se está estudiando si conviene renovar la linea L1. En la línea L1 se trabaja las 24 horas con tres turnos, T1, T2 y T3, mientras que en la línea L2 se trabaja sólo en dos turnos, T1 y T2. Fíjese que el turno 1 de la línea 1 no es el mismo que el turno 1 de la línea 2. Además en función de si cumplen cuatro conjuntos de pruebas, llamadas A, B, C y D, se venden de bajo una marca u otra. Para cumplir los contratos con sus compradores, un 19% de su producción debe satifacer el conjunto de pruebas A, el 33% debe satisfacer el B, el 24% debe satisfacer el C, el 20% debe satisfacer el D y el resto se desechan. A cada multimetro sólo se le pasan los conjuntos en algún orden hasta que pase uno de ellos, pero los conjuntos de pruebas son independientes. Por ejemplo, un multímetro podría cumplir los conjuntos A y D, pero no las B y C. En el fichero MD.csv (pestaña de recursos) tiene los datos necesarios de un día de producción de la fábrica. Hay 4 variables: ID (identificador del multímetro), Linea, Turno y Resultado. El resultado puede ser uno de 5: A, B, C, D y O según si satisface el conjunto de pruebas A, B, C, D o ninguno. Compruebe si la fábrica en conjunto cumple los porcentajes de los 5 niveles. Un segundo estudio es para comparar las dos líneas de producción. Queremos saber si las distribuciones de piezas que cumplen los conjuntos de pruebas es el mismo en ambas líneas o no. Compruebe si las distribuciones de porcentajes de ambas líneas cumplen con los indicados y si difieren entre sí. El tercer estudio es entre los turnos de trabajo. Se ha rumoreado que hay algún turno que no trabaja tan bien como los demás. Compruebe si las distribuciones de calidad dependen o no del turno de trabajo. En función de sus estudios sobre la calidad de producción en su conjunto, la comparación de las dos lineas y los turnos de trabajo, dé indicaciones a la dirección de la empresa para que pueda tomar las decisiones oportunas. Las indicaciones deben ser razonadas y basadas en los datos y sus resultados. En sus indicaciones debe tener en cuenta que las cuestiones laborales son conflictivas y cambiar una línea de producción es caro. Sus indicaciones no deben ser del estilo «Despida a los de T1 de L1, que son unos vagos.» sino «Los del turno T3 cumplen los mínimos de calidad, los del T2 los exceden mientras que los del T1 están muy por detrás. Es urgente realizar alguna actuación con los del T1. Convendría estudiar más a fondo los motivos del éxito del T2 para ver si se pueden trasladar a los otros turnos.» Prob J.5 Una manera de codificar un texto es usando un código de sustitución simple: cada letra se sustituye por otra a lo largo del texto. Por ejemplo si las ‘e’ se convierten en ‘j’ y las ‘n’ en ‘t’, entonces ‘en’ se convierte en ‘jt’. Estos códigos son fáciles de romper si sabe el idioma de partida: el carácter que más veces aparece en el texto cifrado debe ser el carácter más frecuente de ese idioma, el segundo que más aparece el segundo más frecuente y así sucesivamente. Pero este método es complicado de usar si no se sabe el idioma de partida. Una manera de averiguar el idioma es comparar la frecuencia con la que aparecen los caracteres con las frecuencias de caracteres de cada idioma. Si el texto no es muy largo, sólo compararemos los 10 caracteres que aparecen con más frecuencia. Sabemos que el texto siguiente está en Inglés, Francés, Español, Italiano o Alemán. Haga un estudio estadístico para determinar en qué idioma está. jxyi yi weydw je ru q fhubycydqho ydluijywqjyed ydje jxu selyt dkcruhi ruydw fhuiudjut xekhbo je jxu mehbt jxyi jefys xqi jqaud cu temd q tqjq hqrryj xebu qdt mybb ru qd edweydw ydluijywqjyed, qi y xqlu cqdo gkuijyedi jxqj hucqyd kdqdimuhut fuhxqfi huqtuhi adembutwuqrbu yd iksx qhuqi sqd fhelytu jxuyh ydiywxj vyhijbo y mqdj je ucfxqiypu jxqj selyt yi q huqb lyhki qdt jxqj yj yi uifusyqbbo je jxu ubtuhbo qdt jxeiu myjx kdtuhboydw xuqbjx sedtyjyedi tqdwuheki qdt qbb jee evjud tuqtbo xemuluh jxu cyi bqrubydw ev tqjq jxqj yi weydw ed yd jxu cutyq yi qijekdtydw ulud veh edu kiut je iksx jxydwi ulud muriyjui mxeiu veski yd tyiiucydqjydw selyt hubqjut ijqjyijysi xqlu ruud cyi bqrubydw juhci qdt dej fhelytydw fhefuh huvuhudsui veh jxuyh tqjq yd jxu ki jxuhu yi de hugkyhucudj veh bqrehqjeho huikbji sedvyhcydw jxqj jxuhu mqi qd qsjylu selyt ydvusjyed yd qd unfyhut fqjyudj yd ehtuh je hufehj jxu sqkiu ev tuqjx qi selyt fuh jxu sts i dqjyedqb lyjqb ijqjyijysi ioijuc selyt qbuhj de cqhsx ixekbt selyt ru hufehjut ed jxu tuqjx suhjyvysqju edbo myjx q sedvyhcut juij selyt ixekbt ru hufehjut ed jxu tuqjx suhjyvysqju veh qbb tusutudji mxuhu jxu tyiuqiu sqkiut eh yi qiikcut je xqlu sqkiut eh sedjhyrkjut je tuqjx jxu juhc sedvyhcut tuqjxi qi kiut yd cutyq evjud cuqdi qj ceij jxqj q tuqjx yd jxu efydyed ev jxu suhjyvyuh jxu edu mxe vybbut ekj jxu tuqjx suhjyvysqju iecujycui q tesjeh mqi qjjhyrkjqrbu je selyt ulud yv jxuhu mqi q hugkyhucudj veh q bqr sedvyhcqjyed jxqj jxuhu mqi qd ydvusjyed qj jxu jycu ev jxu fqjyudji tucyiu qiiywdydw jxu fhenycqju sqkiu ev tuqjx yi evjud tyvvyskbj ulud yd jxu ruij ev jycui kdbyau tujuhcydydw mxujxuh q fuhied xqi tyut jxuhu yi unjudiylu zktwcudj ydleblut yd qisuhjqydydw q sqkiu ev tuqjx qbedw myjx xeifyjqb rybbydw ijqjucudji oek sqd vybu fefkbqh jubulyiyed thqcqi byau whuoi qdqjeco xekiu uh qdt siy kdtuh jxu sqjuweho ev vysjyed edbo q icqbb fuhsudjqwu ev tuqjxi qhu vhec erlyeki sqkiui iksx ydzkhyui vhec jhqvvys sebbyiyedi jxu cqzehyjo ev tuqjxi esskh yd ubtuhbo ydtylytkqbi ceij ev jxeiu ydtylytkqbi xqlu ckbjyfbu kdtuhboydw xuqbjx yiikui, qdt jxu sqkiu i ev tuqjx yi kikqbbo jxu suhjyvyuhi ruij wkuii ceij tuqjxi qhu duluh qkjefiyut rkj ulud myjx qd qkjefio yji evjud zkij q utksqjut efydyed qi je mxqj jxu sqkiu ev tuqjx mqi ebt fuefbu mxud jxuo rusecu vhqyb, zkij tyu yji zkij q vqsj ev byvu qdt yj sqd ru q veebi uhhqdt jhoydw je qishyru q sqkiu ev tuqjx yd jxeiu sqiui yd dkhiydw sqhu vqsybyjyui jxu cutyqd byvu unfusjqdso ev huiytudji sqd ru ixesaydwbo ixehj q ijkto vekdt jxqj jxu cutyqd byvu unfusjqdso qvjuh qtcyjjqdsu mqi q cuhu cedjxi vhec jxqj edu sqd ikhcyiu jxqj jxu edu ouqh cehjqbyjo hqju veh huiytudji qvjuh ruydw qtcyjjut je q dkhiydw xecu yi qffhenycqjubo qwqyd jxqj yi yd dehcqb jycui huifyhqjeho lyhkiui xqlu ruud myjx xkcqdaydt veh judi ev jxekiqdti ev ouqhi uluho ouqh qhekdt jxu ruwyddydw ev jxu ouqh yd sekdjhyui yd jxu dehjxuhd xucyifxuhu jxuhu yi q ifyau yd huifyhqjeho hubqjut ybbduii qdt tuqjx cehu qsskhqjubo q fbej ev qbb sqkiu cehjqbyjo vebbemi q iydkieytqb fqjjuhd myjx jxu fuqa duqh jxu ruwyddydw ev jxu ouqh qdt jxu jhekwx yd jxu ikccuh jxu tuqjx hqju qj jxu fuqa yi kikqbbo qrekj xywxuh jxqd jxu tuqjx hqju qj jxu jhekwx yd jxu ikccuh jxu juhci unsuii tuqjxi eh unsuii cehjqbyjo qhu cehu qsskhqjubo juhcut cehjqbyjo tyifbqsucudj jxekwx kdsecvehjqrbu veh ceij je fedtuh yj yi qd kdqleytqrbu vqsj ev byvu jxqj mu qbb mybb tyu jxki yd huqbyjo jxuhu yi de iksx jxydw qi qd unsuii tuqjx fuh iu zkij qd uqhbo tuqjx fuh myayfutyq Prob J.6 Si tiramos dos dados, las probabilidades de sacar 2, 3, 4 etc. son valores fáciles de calcular y que se muestran en la tabla. Tiramos dos dados 110 veces y obtenemos los resultados que también se muestran en la tabla. Calcule el valor de \\(\\chi_{0}^{2}\\) y el p-valor (por el método visto en clase. No use chisq.test()) \\(k\\) Probabilidad Datos 2 1/36 1 3 1/18 6 4 1/12 12 5 1/9 17 6 5/36 21 7 1/6 16 8 5/36 11 9 1/9 13 10 1/12 7 11 1/18 4 12 1/36 2 Prob J.7 Les encargan realizar un control de calidad en una fábrica que fabrica transformadores. Esta fábrica tiene 4 lineas de montaje y fabrica en las cuatro lineas unos 1000 transformadores al día. Los datos de la fabricación de un día concreto está en el fichero Taller9.csv. La primera columna es un identificador, la segunda nos da el peso del transformador, la tercera el estado de especificaciones, es decir, si cumple todas las especificaciones y la cuarta la linea de montaje de la que ha salido. Para realizar su estudio primero va a estudiar la producción de la fábrica en conjunto. Para ello comprueba una serie de medidas. Según las especificaciones, los transformadores deberían pesar 748.3 gramos y no debería haber más de un 10% que se separaran más de 15 gramos del peso especificado. A partir de lo que puede inferir de su muestra, ¿se cumple? Los objetivos de producción establecen que al menos el 70% de los transformadores fabricados debe cumplir todas las especificaciones (OK), un máximo de un 15% debe necesitar retoques leves (L), un máximo de un 10% puede requerir reparaciones medias (M) y un máximo de un 5% se rechazan (R). A partir de lo que puede inferir de su muestra, ¿se cumple? En segundo lugar quiere saber si las cuatro lineas funcionan igual de bien. Para ello, a partir de los datos del fichero considere si se puede inferir que las 4 lineas producen el mismo número de tranformadores los pesos medios y el porcentaje de transformadores que se desvían más de lo especificado es la misma para las cuatro lineas las proporciones de transformadores para los cuatro niveles de estado son las mismas para las cuatro lineas. Prob J.8 En una fábrica de circuitos tenemos dos líneas de montaje, L1 y L2. La línea L2 es más moderna y produce más circuitos incluso funcionando menos horas y se está estudiando si conviene renovar la linea L1. En la línea L1 se trabaja las 24 horas con tres turnos, T1, T2 y T3, mientras que en la línea L2 se trabaja sólo en dos turnos, T1 y T2. Como parte del estudio se investiga la calidad de los circuitos fabricados. Hay 4 niveles de calidad en una inspección: OK (el circuito ha pasado la inspección), A (el circuito ha necesitado algunos ajustes), R (el circuito ha necesitado que se rehaga una parte) y D (ha habido que deshechar el circuito). Los datos de una inspección de calidad están en circ.csv, con 4 variables: ID (identificador del circuito), Linea, Turno y Resultado. Lo primero que queremos hacer es estudiar la producción de la fábrica en conjunto. El comité de calidad ha detallado que para los 4 niveles de inspección los porcentajes aceptables deben ser OK: 60%, A: 20%, R: 12% y D: 8%. Compruebe si es así. Un segundo estudio es comparar las dos líneas. Queremos saber si una tiene más problemas de calidad que la otra. Compruebe si las distribuciones de porcentajes de ambas líneas cumplen con los indicados por el comité de calidad y si difieren entre sí. El tercer estudio es entre los turnos de trabajo. Se ha rumoreado que hay algún turno que no trabaja tan bien como las demás. Compruebe si las distribuciones de calidad dependen o no del turno de trabajo. Prob J.10 El escritor Enrique Jardiel Poncela tiene un relato (Un marido sin vocación) en la que no hay ni una sola “e”. También tiene otro (Un chófer nuevo) sin una sola “a”. En sine.txt y sina.txt tiene las dos piezas ya “limpias” (sin mayúsculas, acentos, signos de puntuación). Compare mediante pruebas de Ji-cuadrado las características de los textos. Algunas de las preguntas que puede responder: ¿Varía la frecuencia del total de vocales entre ambos textos? ¿La distribución de las otras tres vocales es igual en ambos textos? ¿Y de las consonantes más habituales? No se contente con estas tres preguntas. Piense en alguna más y haga la prueba correspondiente. Prob J.10 Vamos a ver que el p-valor no basta para sacar conclusiones. Supongamos una variable cualitativa con 6 niveles equiprobables (por ejemplo, un dado). Creen dos conjuntos de 120 observaciones. Ambos deben dar un p-valor de 0.06 con una prueba de ji-cuadrado de bondad de ajuste. Construyan uno de los conjuntos para que se asemeje bastante a nuestra hipótesis nula (todas las proporciones son iguales) y construya el otro para que sean claramente diferentes (hay más de una manera de hacerlo). Deben indicarme los dos conjuntos de observaciones, mostrar que el p-valor en ambos es 0.6 (idealmente es exactamente el mismo p-valor en ambos casos) y mediante un diagrama de barras mostrar el que se podría considerar equiprobable y el que no. Prob J.11 Estos son datos sobre frecuencias de tipos sanguíneos tomados de un banco de sangre en Colombia: Tipo Cantidad 0+ 2653 A+ 1230 B+ 107 AB+ 69 0- 241 A- 127 B- 33 AB- 15 Y estos de un banco de sangre en Noruega Tipo Cantidad 0+ 1713 A+ 2056 B+ 343 AB+ 171 0- 302 A- 363 B- 60 AB- 30 ¿Es el tipo sanguíneo (0, A, B, AB) independiente del factor Rh (+, -)? ¿Hay la misma frecuencia de tipos en todos los países?¿Y de factor Rh? 15.8 Regresión Lineal Prob RL.1 Se sabe que el ritmo cardíaco máximo (RCM) de una persona decrece con la edad. Una fórmula popular es que RCM = 220 - Edad. Se han tomado datos del RCM de gente de varias edades: Age 18 23 25 35 65 54 34 56 72 19 23 42 18 39 37 RCM 202 186 187 180 156 169 174 172 153 199 193 174 198 183 178 Queremos usar estos datos para saber si la fórmula puede ser correcta. Haga una regresión lineal suponiendo que sigue una recta. Calcule el intervalo de confianza de la pendiente El summary nos da directamente el valor de t para el caso de H0: pendiente = 0. ¿Cuál sería el valor de t para H0: pendiente = -1? Haga un t-test para H0: pendiente = -1, Ha: pendiente ≠ -1. ¿Cuál es el p-valor? Haga otro t-test para H0: intercept = 220, Ha: intercept ≠ 220. ¿Cuál es el p-valor? A partir de los resultados obtenidos, indique si cree que estos datos avalan la fórmula o no. Prob RL.2 En el conjunto de datos Rubber, del paquete MASS, tiene datos de la degradación de neumáticos en función de su dureza. Vea el Help para más detalles. Haga la regresión de la degradación en función de la dureza suponiendo una recta. Prediga el rango de degradaciones para neumáticos de dureza 60, 65 y 80. Prediga el intervalo de la degradación media para neumáticos de dureza 50, 60 y 70. Prob RL.3 En el conjunto de datos Rubber, del paquete MASS (incluido en la instalación básica de R), tiene datos de la degradación de neumáticos en función de su dureza. Vea el Help para más detalles. Haga la regresión suponiendo una recta. Diagnostique si es adecuado usar una recta para esta regresión. Si lo es, prediga, indicando los IC adecuados, la pérdida de neumáticos de durezas 52, 65 y 78 en un Km. Prediga la pérdida, con los IC adecuados, de estos tres neumáticos tras recorrer 250 Km. Prob RL.4 En una excursión a lo alto de una montaña se tomó la temperatura y la altitud en diferentes momentos. Los datos son los siguientes Altura Temperatura 7 18.9 87 18.1 172 17.5 251 16.9 322 16.7 430 16.0 508 15.2 595 15.2 640 14.9 725 13.4 Se sabe que la temperatura del aire se reduce al ascender. Suponga que la relación es lineal. Dibuje la gráfica de los puntos, calcule la recta de regresión y añádala a la gráfica. Interprete los dos coeficientes, los p-valores y el coeficiente de correlación \\(R^{2}\\). Indique alguna posible influencia otra que la altura que puede influir en la temperatura medida. Prob RL.5 En buena lógica, un coche debe pesar más cuanto más largo es. La relación puede ser lineal, pero también puede ser cuadrática (cuanto más largo, más ancho y ambos influyen en el peso). Coja el conjunto de datos Cars93 del paquete MASS que hemos usado en el pasado. Considere que el peso del coche es la variable dependiente y la longitud es la variable independiente. Calcule primero la regresión suponiendo que la relación es lineal, después que es cuadrática. Interprete los dos coeficientes, los p-valores y el coeficiente de correlación \\(R^{2}\\). ¿Qué opina que es más adecuado usar, una relación lineal o cuadrática? Prob RL.6 En el documento sobre cálculo de regresiones se muestra que en Nicaragua el número de teléfonos por 100 habitantes creció aproximadamente un 25% al año entre 1991 y 2006. Tiene los datos en telefonos.csv. Ahora bien, el parámetro \\(b\\) usado para hacer el cálculo tiene su intervalo de confianza. Calcule, con un nivel de confianza del 95%, el intervalo de confianza del crecimiento porcentual anual de los teléfonos en Nicaragua. Prob RL.7 Un crecimiento (o decrecimiento) exponencial aparece como una curva en una gráfica “normal” (o lineal-lineal) pero aparece como una recta en una gráfica semilogarítmica (lineal-logarítmica). Si miramos el crecimiento de los teléfonos, disponible en telefonos.csv, vemos que tanto en Finlandia como en España tuvimos entre 1975 y 1995 un crecimiento exponencial del número de teléfonos por cada 100 habitantes. ¿Cuál de los dos países tuvo un crecimiento mayor?¿De cuánto fue el crecimiento en cada uno? Prob RL.8 En la clase de regresión lineal se hizo un estudio de crecimiento en el número de teléfonos por países. Tiene los datos en telefonos.csv. Vimos que en China no hay ninguna región clara de crecimiento exponencial (la gráfica semilogarítmica no es una recta) mientras que en Nicaragua hay dos épocas de crecimiento exponencial diferentes (antes de 1990 y después de 1990). Mire los datos de Nicaragua, España y Finlandia. Determine en cuáles de ellos es razonable suponer una época de al menos 10 años de crecimiento exponencial. Si hay varias épocas, escoja la más larga de cada país. ¿Se puede decir que en uno de los países hubo un mayor crecimiento que en los demás?¿De cuánto fue? No olvide usar intervalos de confianza al hacer la comparación. Prob RL.9 El conjunto de datos SAT del paquete UsingR contiene datos de educación en USA en 1997. Para cada uno de los 50 estados muestra El gasto medio por alumno (expend) El número medio de alumnos por profesor (ratio) El salario medio del profesor (salary) El porcentaje de alumnos que se examinaron del SAT, una especie de selectividad, (perc). Este examen está dividido en dos partes, verbal y math, que podemos traducir como “letras” y “ciencias”. La nota media de la parte de letras (verbal) La nota media de la parte de ciencias (math) La nota media total (suma de las dos) (total) El objetivo de este taller es estudiar la influencia de acciones económicas estatales en la educación. Las acciones que consideraremos son las del conjunto de datos: gasto medio, salario medio del profesor y el número medio de alumnos por profesor (este último tiene una componente económica y otra pedagógica). Los resultados educativos van a ser las calificaciones del SAT. EL SAT, siendo sólo un número, no puede recoger la complejidad de lo que es la educación y el estado toma muchas acciones que no se recogen aqui. Pero es un estudio simple del que se pueden aprender cosas interesantes. Una cuestión previa es si el SAT mide el conocimiento del alumno. Una manera de obtener alguna información sobre esto es mirar la correlación entre la nota de la parte de letras y de ciencias: si no hay ninguna, es que hay una componente de “suerte” muy fuerte en el examen. Noten que una falta de correlación da lugar a sospechar del examen como instrumento de medida, pero que una correlación alta no significa necesariamente que sea una buena medida del aprendizaje. Considere que la nota de la parte verbal es la variable independiente y calcule la recta de regresión. Mirando los resultados del summary() determine si la correlación puede considerarse fuerte. Vamos ahora a estudiar la correlación que hay entre el gasto, el número de alumnos por profesor y el salario del profesor con los resultados del SAT. Haga un estudio de regresión de cada uno de estas variables con la calificación total. No considere que la relación deba ser necesariamente lineal. En algunos casos usar los resultados del SAT para evaluar la “calidad” de la educación es claramente incorrecto: en muchos estados muy pocos alumnos toman este examen y estaríamos evaluando a todos con los resultados de unos pocos. Repita el estudio pero sólo considerando los estados en los que al menos un 60% de los alumnos ha tomado el SAT. Basándose en esta evidencia, ¿cree usted que los problemas educativos se resuelven simplemente dedicando más dinero a educación? Razone su respuesta. Prob RL.10 El conjunto de datos cats del paquete MASS contiene datos compilados por R.A. Fisher (uno de los grandes de la estadística) del peso del corporal y del corazón del conjunto de gatos que fueron usado en un experimento del compuesto digitalis para el tratamiento de enfermedades del corazón. Contiene tres columnas: Sex, con el sexo del gato; Bwt, con su peso corporal en kilos; y Hwt, con el peso del corazón, en gramos. Consideraremos que el peso corporal es la variable independiente y el peso del corazón la variable dependiente. Supondremos inicialmente que la relación entre pesos es lineal. Calcule las rectas de regresión para el total de los gatos, sólo los machos y sólo las hembras. Haga un diagnóstico de las tres regresiones. Si de este diagnóstico se deduce que no debe ser una recta, use otra curva que considere adecuada y que pase la prueba de diagnóstico. El enunciado hablará de rectas, pero si no lo es, adapte su trabajo a la curva que ha escogido. Interprete los coeficientes de la recta, los coeficientes de correlación \\(R^{2}\\) y el p-valor global para las tres regresiones. Dibuje en un gráfico los intervalos de confianza de las pendientes de las regresiones de machos, hembras y total. Calcule el intervalo de confianza de la diferencia de machos y hembras. ¿Se puede considerar que la pendiente para los machos es la misma que para las hembras? Use siempre un nivel de confianza del 90%. Considere los pesos corporales que son el primer, segundo y tercer cuartil de la muestra de machos y de la dehembras. Calcule el intervalo de rangos del peso del corazón y el intervalo del peso medio del corazónpara cada uno de estos tres pesos para cada sexo. Tenemos 1000 gatos, 500 machos y 500 hembras. Suponemos que siguen la distribución de pesos de la muestra. Escogemos todos aquellos gatos cuyos pesos están entre 2,5 y 2,75 Kg (ambos incluidos). ¿Cuántos gatos machos y cuántos hembras tenemos? Dé una estima del rango del peso total de todos los corazones de todos estos gatos. Prob RL.11 El conjunto de datos airquality de la distribución de base de R contiene datos de la calidad del aire en Nueva York. Queremos saber si hay correlación entre la concentración de ozono (columna “Ozone”) y la temperatura (columna “Temp”). Haga una regresión lineal suponiendo que la regresión es una recta. ¿Cuál sería la recta de regresión? ¿Cuál es el coeficiente de correlación? Prob RL.12 Haga una regresión lineal entre dos variables aleatorias. No debiera haber correlación entre ellas. ¿Qué valores resultantes, que aparecen en el summary del lm, nos indican este hecho? Prob RL.13 En el fichero Preciocoche.csv tiene los precios de 59 coches obtenidos de un periódico de Toulouse en 1985. La columna obs es el identificador de la observación, la columna year el año de compra del coche, la columna km, los kilómetros del coche (en miles) y la columna price, el precio (en miles de francos). Dibuje el precio en función de los kilómetros y haga la regresión suponiendo una relación lineal (recta). Diagnostique la regresión. Si no es buena intente hacerla como una lineal más cuadrática o como una exponencial. Elija la cuadrática o exponencial sólo si es claramente mejor que la lineal: si la diferencia es pequeña, es preferible la mayor simplicidad de la lineal que la mejor precisión de la cuadrática o exponencial. Cree la variable edad, con la edad del coche, y haga la regresión suponiendo una relación lineal. Diagnostique la regresión. Si no es buena intente hacerla como una lineal más cuadrática o como una exponencial. Elija la cuadrática o exponencial sólo si es claramente mejor que la recta. En función de los modelos que ha escogido prediga: El intervalo de precios de un coche de 80.000 Km. El intervalo del precio medio de un coche de 120.000 Km. El intervalo de precios de un coche de 4 años. El intervalo del precio medio de un coche de 6 años. Prob RL.14 El data frame kid.weights de la biblioteca UsingR nos da información de edad, pesos y alturas niños y niñas. La variable age es la edad en meses, weight es el peso en libras, height es la altura en pulgadas y gender indica si es niño o niña. Haga la regresión lineal del peso en función de la altura en niños y en niñas. Interprete los dos coeficientes en ambas regresiones indicando qué coeficientes no son de interés y por qué. ¿Qué porcentaje del peso de un niño es explicable por su altura?¿Y en una niña? Especule otras características del niño que pueden explicar su peso. ¿Qué influye más en el peso del niño, su altura o su edad?¿Y en una niña? Prob RL.15 Estudiamos en clase el peso de los niños (conjunto de datos kid.weights) en función de la altura considerando que la relación era lineal y también cuadrática. Vamos a estudiar ahora la relación de la altura con la edad. Coja sólo los niños. Estudie la relación de la altura en función de la edad. Determine si la relación lineal es suficientemente buena o si es necesario un término cuadrático. Repita para el caso de niñas. Prob RL.16 El dataframe term contiene datos de un centro de cálculo de los años 90. En quellos tiempos el centro de cálculo tenía uno o unos pocos grandes ordenadores (llamados mainframes) y muchos usuarios se conectaban a cada uno mediante terminales. Cuántos más terminales tuviera conectados, más lento es el sistema: tarda más tiempo en responder. La variable no indica el número de terminales conectados y la variable time indica el tiempo de respuesta de cada usuario en realizar una determinada tarea. Si hacemos una regresión lineal encontramos la mejor recta que correlaciona estas dos variables. Pero vemos que parece que crece más que linealmente. Hacemos una correlación lineal más cuadrática. Mire los valores de los coeficientes (no sólo la estima, sino todo) y responda ¿Es el crecimiento lineal, lineal más cuadrático o solamente cuadrático? En el tutorial dice que el último valor de cada fila de coeficientes es un p-valor, siendo la hipótesis nula que la estima del coeficiente es 0. La salida de R no lo llama p-valor sino Pr(\\(&gt;|\\)t\\(|\\)). Quizá haya notado que al final de todo del summary de R aparece un p-valor. Si no lo ha notado, mírelo y verá que su valor, hasta ahora, coincidía con el último valor de la fila del coeficiente de la respuesta (la pendiente de la recta, el que no es el Intercept). En este último caso, el p-valor es diferente de los de cualquiera de los dos coeficientes (tanto el lineal como el cuadrático). Además es menor que ambos. ¿Cuál cree usted que es la hipótesis nula de este p-valor del final? Prob RL.17 En clase mostramos un ejemplo en el que aplicamos voltajes a una resistencia y medimos las intensidades que circulan por ella. De la regresión resultante calculamos la resistencia: V = c(1, 3, 6, 10, 15, 20, 30) I = c(0.0016, 0.0460, 0.0500, 0.1045, 0.1763, 0.2067, 0.3359) plot(V,I) R = lm(I~V) 1/confint(R) Una manera alternativa de obtener la resistencia, sería calcular los 7 valores de V\\(_{i}\\)/I\\(_{i}\\) y hacer un t-test. Hágalo. Verá que obtenemos un IC mucho mayor. ¿Por qué? Elimine el “culpable obvio” y repita el t-test. ¿Son los resultados consistentes con los obtenidos con la recta de regresión?¿Qué método da mayor precisión?¿Por qué? (Pista: ¿cuáles son los requisitos para hacer un t-test?¿Y una regresión?¿Cuáles son más fáciles de cumplir?) Prob RL.18 En la regresión del problema anterior tenemos la variable controlada (V) en el eje X y la variable medida (I) en el eje Y. Esta es la manera correcta de hacerlo, pero hace que la pendiente sea 1/R. No es grave, pero es una lata. Podríamos poner la V en el eje Y y así la pendiente nos daría directamente la resistencia. Haga esta regresión “al revés”: lm(V~I). ¿Cree que tocaría dar lo mismo?¿Da lo mismo? Si no, ¿por qué? He dicho que poner la variable controlada en el eje X es la manera correcta. ¿Por qué? (Pista: los puntos no salen exactamente encima de la línea por errores de medida.) Prob RL.19 La web http://guessthecorrelation.com es un juego para adivinar la correlación entre dos variables. Créese un usuario llamado “EUIB\\(&lt;\\)nombre$&gt;$18” donde \\(&lt;\\)nombre\\(&gt;\\) son las 4 primeras letras de su primer apellido. Juegue cuántas partidas quiera y envíeme el pantallazo con su puntuación máxima. La calificación que obtendrá dependerá de esta puntuación. No aceptaré ninguna tarea con menos de 50 puntos de “high score”. Con 100 puntos tiene un 5; si obtiene 140 puntos tendrá un 7; con 200 o más tiene un 10. Prob RL.20 Uno de las frases fundamentales de la estadística es “correlación no es causalidad”. Si tiene suficientes datos, es relativamente fácil obtener dos variables muy correlacionadas pero que no tienen nada que ver entre ellas. En la web http://www.tylervigen.com/spurious-correlations puede encontrar muchos casos de correlaciones increíbles. Échele un vistazo. Puede descubrir nuevas correlaciones (enlace Discover a correlation, al final de la página): elige un tema, después elige una variable, después elige una segunda variable y le da la correlación (\\(R^2\\)). Busque correlaciones que sean altas (mayor que 0.75) y que sean divertidas. Muestre al menos 2. Debe entregar la descripción de las variables y la gráfica. La puntuación será sobre todo por lo divertido o sorprendente de la correlación. Prob RL.21 En el documento “Simple R: Using R for introductory statistics” (disponible en la pestaña de recursos) se explica la regresión en el capítulo 13. Muestra allí como el paquete UsingR tiene una función (simple.lm) que permite mostrar los intervalos de confianza de la regresión gráficamente. Estudie cómo se usa esta función y aplíquelo al ejemplo de peso de niños en función de su altura. Usando el IC de individuos (el exterior) responda a las siguientes preguntas: ¿Cuál es el intervalo de confianza del peso con nivel de confianza de 95% de los niños con una altura de 100 cm? ¿Cuál es el intervalo de confianza del peso con nivel de confianza de 90% de los niños con una altura de 130 cm? Prob RL.22 Esta es la gráfica de lo bien que un equipo de la NFL ha hecho en el draft de un año, contra lo bien que el mismo equipo lo ha hecho en el draft del año siguiente (el valor 0 es la media de la calidad del draft de ese año). ¿Parece que haya correlación? Si unos equipos fueran consistentemente mejores que otros, ¿qué pinta debería tener la gráfica? 15.9 Problemas con todo Prob CT.1 En Calificaciones.csv tiene 900 calificaciones de alumnos. Este dataframe tiene 5 columnas: Calif: La calificaciones (de 0 a 10) Sem: La semana (se 1 a 15) EnGrupo: Si se ha hecho la actividad en grupo o individual (G o I) Prof: el profesor (ProfA y ProfB) Queremos saber 3 cosas: ¿Son las calificaciones en grupo mejor que las individuales? ¿Son las notas con un profesor mejor que con otro? ¿Van mejorando las notas con el paso de las semanas? Haga todas las gráficas adecuadas para estudiar la problematicidad de los datos y obtener una idea intuitiva para estas tres preguntas. Haga después el estudio inferencial adecuado para responder a estas tres preguntas. Debe entregar el script de R, las gráficas y sus respuestas razonadas a las preguntas. Los razonamientos deben ser completos, no una o dos frases. Prob CT.2 Partimos del conocido conjunto de datos Cars93 (paquete MASS). Nos interesan los siguientes datos: Potencia (Horsepower) Tipo (Type) Consumo ciudad (MPG.city) Consumo carretera (MPG.highway) Longitud (Length) Anchura (width) Estos datos son de 1993. Añada los datos de al menos 50 coches actuales con una distribución de tipos similar a los del 93 (pueden reunirse varios para obtener los datos, pero deben decirme quiénes son). Convierta los datos de Cars93 a unidades europeas y añada una columna llamada Actual con dos niveles “2017” y “1993” [Este problema se propuso en 2017]. Queremos saber Si los coches actuales son más grandes (largos-anchos) que los del 93 Si hay correlación entre potencia y consumo en ciudad Si hay correlación entre potencia y consumo en carretera Si la hay, si es diferente en el 93 y ahora (es decir, si los coches consumen más o menos ahora) Si el consumo medio por tipo es diferente ahora de lo que era antes Para ello haga las gráficas adecuadas de estadística descriptiva. Haga un estudio de problematicidad de los datos. Obtenga de las gráficas una respuesta intuitiva a las preguntas. Confirme o no su intuición a partir de las pruebas correspondientes de estadística inferencial. Debe entregar: La lista de 50 coches añadidos con los datos El script de R Las gráficas Su respuesta razonada a las preguntas. Los razonamientos deben ser completos, no un par de frases. Prob CT.3 Partimos del conjunto de datos survey (paquete MASS). Vamos a buscar correlaciones y dependencias que pueden o no ser estadísticamente significativas. Busque con las gráficas y la prueba estadística adecuada si hay correlación entre El tamaño medio de la mano de escribir y el sexo El tamaño medio de la mano de escribir con la de no escribir El tamaño de la mano de escribir y lo que fuma Lo que fuma y el sexo La mano dominante al aplaudir y el brazo dominante al cruzar los brazos La mano dominante al aplaudir y el sexo La mano dominante al aplaudir y si hace ejercicio El ejercicio que hace y el ritmo cardíaco El ritmo cardíaco y la mano de no escribir El pulso y la altura La altura y el sexo Si fuma y en qué unidades da las medidas La altura y el tamaño de las manos (ambas) Si es zurdo o no y la mano dominante al aplaudir El ejercicio y la altura El ritmo cardíaco y el brazo dominante al cruzar los brazos El brazo dominante al cruzar los brazos y la altura Para cada una de estos pares de variables dibuje la gráfica (o gráficas adecuadas), estudie la problematicidad, haga las pruebas estadísticas adecuadas y decida si hay una correlación estadísticamente significativa. Si la hay, explique si es natural o pura casualidad del muestreo (no basta decir si una cosa u otra, debe dar una justificación a su afirmación). 15.10 Campos Elíseos Todas estas preguntas aparecieron en alguna edición del examen de Campos Elíseos. Prob CE.1 El motor de explosión se basa en pistones que se mueven dentro de cilindros. En una fábrica de motores los pistones tienen un diámetro medio de 76.32 mm con una desviación típica de 0.048 mm.Los cilindros tienen un diámetro medio de 76.50 mm con una desviación típica de 0.051 mm. En ambos casos los diámetros siguen una distribución normal. La suma o resta de distribuciones normales es una distribución normal. ¿Cuáles son los parámetros de la distribución normal de la distancia entre pistón y cilindro? La distancia entre pistón y cilindro debe estar entre 0.05 mm y 0.14 mm.¿Cuál es la probabilidad que cogiendo un pistón y un cilindro al azar, se cumpla la tolerancia?Basta que muestre las instrucciones de R necesarias. Prob CE.2 Los grandes jugadores rinden mejor cuando el partido está ajustado (lo que en inglés se dice un clutch player). Centrémonos en baloncesto y en el porcentaje de tiro. Indique qué datos debe coger, qué gráficas debe dibujar y qué pruebas estadísticas debe realizar para saber si un jugador es o no un clutch player. Prob CE.3 En su empresa tienen un circuito que se vende muy bien pero que se está quedando viejo y quieren crear la nueva versión mejorada y que espera que les sirva varios años. Ponen a dos equipos a rediseñar el circuito. El parámetro fundamental es el tiempo de respuesta, que en el circuito actual es de 15.4 ms. El equipo A crea un circuito cuya diferencia de tiempo de respuesta medio respecto al actual es de [-0.13, -0.17] (valores negativos indica que se reduce el tiempo de respuesta) con un p-valor de 0.00035. El equipo B crea otro circuito cuya diferencia de tiempo de respuesta medio respecto al actual es de [-3.26, 0.72] con un p-valor de 0.165. A partir de ahora sólo un equipo puede continuar y usted debe elegir cuál. Usando sólo la información suministrada, ¿cuál considera que debe continuar?¿Por qué? Prob CE.4 Pasamos una encuesta a tres ciudades sobre sus preferencias en deportes, cine, política… lo que usted quiera. El número de entrevistados en cada ciudad es proporcional al número de habitantes. Los resultados son: Ciudad Opción 1 Opción 2 Opción 3 Ciudad A 198 445 332 Ciudad B 130 288 229 Ciudad C 103 170 105 Si lo que queremos saber es si las 3 ciudades tienen gustos similares, ¿qué prueba debemos hacer? No olvide indicar con precisión las hipótesis nula y alternativa. Calcule los intervalos de confianza de las tres opciones para el conjunto de las tres ciudades. Sólo mirando los intervalos de confianza, ¿se puede decir que hay una opción preferida a las otras dos? (Suponemos nivel de confianza de 95%. Use 1.96 para el factor.) Ahora consideremos la Opción 1. Calcule los intervalos de confianza para las tres ciudades. Sólo mirando los intervalos de confianza, ¿se puede decir que hay una ciudad que prefiere esta opción a las otras dos? Prob CE.5 Estamos estudiando sistemas de climatización.Según un fabricante, bajo ciertas condiciones prefijadas, la temperatura debe disminuir a un ritmo de 0.75\\(^{\\mathrm{o}}\\)C por minuto. Reproducimos en un laboratorio las condiciones indicadas por el fabricante, tomamos medidas de temperatura cada minuto, calculamos la regresión lineal y obtenemos la siguiente salida de R: Call: lm(formula = temp ~ tiempo) Coefficients: Estimate Std.Error t value Pr(&gt;|t|) (Intercept) 24.92013 0.43547 57.23 9.65e-12 tiempo -0.73593 0.07018 -10.49 5.95e-06 --- Residual standard error: 0.6375 on 8 degrees of freedom Multiple R-squared:0.9322, Adjusted R-squared:0.9237 Aproxime el intervalo de confianza de la pendiente (use un factor de 2.3). Si la hipótesis nula es que la pendiente es \\(-0.75^{\\mathrm{o}}\\)C por minuto y la alternativa es que es mayor, explique cómo calcular el p-valor a partir de los datos mostrados arriba. Prob CE.6 Estamos estudiando la relación que puede haber entre el deporte favorito de una persona y el tipo de película a la que va. Introducimos en R la matriz con los siguientes datos: Accion Comedia Terror Futbol 24 15 8 Baloncesto 46 15 12 Volley 38 8 25 Cada celda es el número de personas que ha preferido una combinación deporte-película concreta. Queremos dibujar un diagrama de barras agrupados por tipos de película y donde el porcentaje para cada tipo de película sume Indique las acciones de R necesarias para hacerlo. Debe ser detallado. No es necesario que escriba instrucciones concretas, aunque puede serle más fácil hacerlo así. Calcule la probabilidad de que a uno que vaya a las películas de terror tenga como deporte favorito el volley; la probabilidad de que una persona vaya a las peliculas de acción y su deporte favorito sea el fútbol; P[Baloncesto \\(|\\) Comedia]. A primera vista, ¿le parece que las variables son independientes? Explique con suficiente detalle qué prueba(s) estadística(s) realizaría para asegurarse, junto con la interpretación de los resultados que vaya a obtener. Prob CE.7 Estamos diseñando el control de calidad de una fábrica y tenemos tres máquinas estampadoras de soportes. Queremos medir tres cosas: el porcentaje de soportes que no cumplen dos de las especificaciones (longitud y grosor) y el peso medio del soporte. Queremos comparar los resultados de las tres máquinas y si el peso cumple o no las especificaciones. Hemos decidido tomar cada día y de cada máquina una muestra de la producción y tomar las medidas. Indique las gráficas que hay que hacer y las pruebas estadísticas a realizar. Prob CE.8 Somos productores y comercializadores de vinos y tenemos un pedido de 50 barricas de 25 litros. Cada barrica vacía pesa de media 4,25 Kg con una desviación típica de 0,38 Kg. El vino contenido en la barrica pesa de media 24,38 Kg con una desviación típica de 0,56 Kg. ¿Cuál es el peso medio y la desviación típica de una barrica llena? Prob CE.9 Queremos estimar cuánto sube la tasa de alcohol en sangre (TAS). Según la DGT la tasa sube 0.02 por cerveza consumida. Medimos la tasa a varios estudiantes después de consumir cervezas.La tabla de partida es la siguiente: Estudiante Cervezas TAS 1 5 0.10 2 2 0.03 3 9 0.19 4 8 0.12 5 3 0.04 6 7 0.095 7 3 0.07 8 5 0.06 9 3 0.02 10 5 0.05 Para ver si la DGT tiene razón hacemos dos pruebas.En la primera calculamos la tasa media por cerveza de cada uno de los 10 estudantes y hacemos un t.test. La salida de R es la siguiente data: Med t = -3.0606, df = 9, p-value = 0.01356 alternative hypothesis: true mean is not equal to 0.02 95 percent confidence interval: 0.01130709 0.01869608 sample estimates: mean of x 0.01500159 La otra manera es hacer una regresión del aumento de la tasa en función de las cervezas consumidas. Calculamos en R lm(TAS~Cervezas). Los resultados del summary son: Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.018500 0.019230 -0.962 0.364200 Cervezas 0.019200 0.003511 5.469 0.000595 *** Multiple R-squared:0.789, Adjusted R-squared:0.7626 y el intervalo de confianza, calculado con confint() es 2.5 % 97.5 % (Intercept) -0.06284414 0.02584414 Cervezas 0.01110391 0.02729609 Obtenemos resultados diferentes, según el método usado. Explique por qué e indique si le parece que estos resultados dan o no la razón a la DGT. Prob CE.10 Queremos comprobar la temperatura de fusión del chocolate de las dos lineas de nuestra fábrica. Llamaremos a las lineas A y B. Por especificación, debería fundirse a 32.3\\(^\\mathrm{o}\\)C. Queremos saber si las lineas cumplen con la especificación y también las estamos comparando entre sí. Por cuestiones de coste, no podemos comprobar más que 16 tabletas por día. Una primera idea es tomar las muestras de las dos lineas proporcionalmente a su producción: la A produce 100 tabletas por hora y la B, 350. Una segunda es hacerlo de forma que los errores estándar de ambas muestras sea similar. Los datos tomados históricamente nos permiten considerar que las desviaciones estándar son 0.37\\(^\\mathrm{o}\\)C para la A y 0.25\\(^\\mathrm{o}\\)C para la B. Decida los tamaños de las muestras para ambos casos. Tomamos una muestra de cada linea lo suficientemente grandes para probar ambos tamaños de muestra (si sólo necesita \\(m\\), coja las \\(m\\) primeras): N. muestra A B 1 32.2 32.6 2 31.8 32.6 3 32.1 32.4 4 32.0 32.1 5 32.3 32.8 6 32.0 32.7 7 31.8 32.0 8 32.9 32.1 9 32.5 32.6 10 31.5 32.7 11 32.1 32.3 12 32.4 32.3 13 32.1 32.1 14 31.9 32.4 Calcule los intervalos de confianza (nivel de confianza de 95%) de la linea A y de la linea B con ambos tamaños de muestra. Para no tener que calcular las desviaciones típicas de las muestras, suponga que son las de las especificaciones. Los factores para los diferentes grados de libertad son: df \\(f\\) 2 4.30 3 3.18 4 2.78 5 2.57 6 2.45 7 2.36 8 2.31 9 2.26 10 2.23 11 2.20 12 2.18 13 2.16 ¿Cumplen las especificaciones?¿Podemos decir que las lineas son diferentes entre sí? ¿Cuál de las dos maneras de elegir el número de muestras le parece mejor?¿Por qué? Prob CE.11 En una empresa, cada mes se hace una encuesta de satisfacción a los clientes. Hace un mes encuestamos a 105 clientes y 82 dijeron estar “satisfechos” o “muy satisfechos”. Este mes encuestamos a 112 y 73 dijeron estar “satisfechos” o “muy satisfechos”. Esto nos hace sospechar que la satisfacción ha bajado. Un becario metió los datos en R y obtuvo &gt; prop.test(c(82,73),c(105,112)) X-squared = 3.8201, df = 1, p-value = 0.05064 alternative hypothesis: two.sided 95 percent confidence interval: 0.001437415 0.256895918 prop 1 prop 2 0.7809524 0.6517857 De esto concluyó que no se podía establecer que la satisfacción hubiera bajado. ¿Qué error cometió al hacer la prueba de prop-test. Antes de rehacer los cálculos del becario sin el error, estudió los resultados de R. A partir de su estudio, ¿coincide su opinión con la del becario? Prob CE.12 Se acaba de convertir en entrenador del Porreres F.C, que acaba de ascender a Primera. Como todo entrenador en estas circunstancias, empieza planteando el objetivo de permanencia. Los entrenadores normalmente dicen una frase del estilo: «Debemos conseguir \\(n\\) puntos para asegurarnos la permanencia». Habiendo estudiado estadística, mira los puntos del último equipo que se aseguró la permenencia desde la temporada 00/01 hasta la 2016/17. Los introduce en R: &gt; summary(Ult) Min. 1st Qu. Median Mean 3rd Qu. Max. 31.00 39.00 40.00 39.94 42.00 44.00 &gt; t.test(Ult, conf.level = 0.99) t = 49.803, df = 16, p-value &lt; 2.2e-16 alternative hypothesis: true mean is not equal to 0 99 percent confidence interval: 37.59878 42.28357 sample estimates: mean of x 39.94118 ¿En vista de los resultados de R qué frase estadísticamente correcta (pero que el aficionado entendiera) diría? Prob CE.13 En nuestra empresa queremos decidirnos por un distribuidor de material electrónico. Decidimos usar las resistencias para hacer una primera comparación. Tenemos 6 posibles proveedores y muchos valores de resistencia, desde 80\\(\\Omega\\) a 220K\\(\\Omega\\). Esto hace inviable comparar todos los proveedores para todos los valores y decidimos coger una muestra aleatoria de 60 resistencias de cada proveedor con una mezcla adecuada de valores y medir con alta precisión el valor de cada cada resistencia. La primera prueba es ver qué proporción de cada muestra está a menos de ±3%, entre ±3% y ±7% y entre ±7% y ±10% del valor nominal.Así tenemos 3 proporciones por proveedor (suponemos que ninguna resistencia estará fuera del margen de ±10 %). Explique por qué no podemos simplemente hacer prop-test con estas 18 proporciones. Proponga una prueba bien hecha sin coger más resistencias. Para una segunda prueba queremos hacer un ANOVA. No podemos simplemente hacer una media de los valores de las resistencias, pues una muy pequeña desviación de la resistencia de 220K\\(\\Omega\\) tendría muchísima más influencia que una enorme desviación en la de 80\\(\\Omega\\). Proponga una manera de hacer un solo ANOVA de los 6 fabricantes. ¿Cómo se deben combinar los resultados de las dos pruebas para tomar una decisión? Prob CE.14 Una fábrica de motores ha modificado ligeramente los parámetros de la electrónica de control de los inyectores para disminuir el consumo. Se han montado los sistemas originales en 10 motores y se ha medido el consumo y después se han montado los sistemas nuevos en los mismos motores y se ha vuelto a medir. Los resultados son los siguientes: Motor Original Nuevo 1 1.3 1.2 2 1.2 1.4 3 1.3 1.3 4 1.5 1.3 5 1.1 1.2 6 1.2 1.1 7 1.0 1.1 8 1.3 1.0 9 1.1 0.9 10 1.4 1.2 Explique cómo debe realizarse el contraste de hipótesis de medias para este caso en el que las variables son dependientes.¿Cómo debería realizar las medidas con los mismos materiales si quisiera que las variables fueran independientes? Prob CE.15 Se dice que uno de los puntos fuertes de Nadal es que falla poco en los puntos “importantes” (puntos de ruptura, de set, etc). Indique qué datos se necesitan y qué prueba estadística hay que hacer para demostrar si esto es cierto o no. Escriba las instrucciones de R necesarias para hacer la prueba. NOTA: se supone que los datos ya están introducidos y formateados. Describa sólo las variables que usará y la instrucción (o instrucciones) para hacer la prueba. Prob CE.16 Hemos recogido 91 datos y tenemos las siguientes gráficas. Indique de forma aproximada y haciendo los mínimos cálculos posibles los valores del mínimo, Q1, media, mediana, Q3, máximo y desviación típica. Explique cómo y de qué gráficas ha obtenido cada valor. Prob CE.17 En nuestra empresa queremos decidirnos por un distribuidor de material electrónico. Decidimos usar los condensadores para hacer una primera comparación. Tenemos 4 posibles proveedores y muchos valores de condensadores, desde 40 nF a 10 \\(\\mu\\)F. Esto hace inviable comparar todos los proveedores para todos los valores y decidimos coger una muestra aleatoria de 60 condensadores de cada proveedor con una mezcla adecuada de valores y medir con alta precisión el valor de cada cada uno. La primera prueba es hacer un ANOVA. No podemos simplemente hacer una media de los valores de los condensadores, pues una muy pequeña desviación de la capacidad de 10\\(\\mu\\)F tendría muchísima más influencia que una enorme desviación en la de 40 nF. Proponga una manera de hacer un solo ANOVA de los 4 fabricantes. Para una segunda prueba queremos ver qué proporción de cada muestra está a menos de ±1%, entre ±1% y ±3% y entre ±3% y ±5% del valor nominal. Así tenemos 3 proporciones por proveedor (suponemos que ningún condensador estará fuera del margen de ±5 %). Explique por qué no podemos simplemente hacer prop-test con todas estas proporciones. Proponga una prueba bien hecha sin coger más resistencias. ¿Cómo se deben combinar los resultados de las dos pruebas para tomar una decisión? Prob CE.18 Tenemos el siguiente diagrama de nube de puntos ¿Qué problemas hay si queremos hacer un estudio de regresión sobre estos datos?¿Qué deberíamos hacer? Prob CE.24 Usted está absolutamente convencido que los aviones de papel hechos con cartulina han de volar más que los hechos con papel normal. Explique qué experimento (o experimentos) harían para comprobar si su creencia es cierta. Explique tambien qué datos debe tomar y qué prueba (o pruebas) estadísticas debe realizar. Escriba las instrucciones de R apropiadas (no se preocupe por la sintaxis). Prob CE.25 Se han comparado los notas obtenidas por un curso en dos asignaturas, una del trimestre previo y otra del trimestre actual. Los datos se ven en la tabla siguiente: Actuales Previas Exc Not Apr Susp Total Exc 22 6 3 2 33 Not 7 15 5 4 31 Apr 3 2 9 16 30 Susp 3 3 8 19 33 Total 35 26 25 41 127 Simplemente mirando los números, explique si la nota actual parece o no independiente de la anterior, y por qué. ¿Cuál es la probabilidad de aprobar (con cualquier nota) la asignatura actual?¿Cuál es la probabilidad de tener la misma nota en la actual que en la anterior? Queremos hacer un test de Ji-Cuadrado de independencia para demostrar rigurosamente lo que nuestra intuición nos dice. ¿Qué problema tenemos?¿Cómo lo podría resolver si no puede obtener más datos? Prob CE.26 En una fábrica se están estudiando dos procesos para el control de calidad. Se ha hecho una medida de calidad con los dos procesos y se han obtenido los siguientes intervalos de confianza de las medias: Proceso A B Tam. muestra 75 16 Media 15.6 13.2 IC (NC = 95 %) [14.8, 16.4] [12.0, 14.4] Como ven, los intervalos de confianza no solapan. Un compañero dice que ya que en el proceso A se han utilizado 75 muestras contra sólo 16 del B es más probable que la media verdadera esté en el intervalo [14.8, 16.4]. Explique por qué se equivoca. Echa una ojeada al stripchart de las medidas: Dé su opinión de qué IC se fía más (puede no fiarse de ninguno) y por qué. Prob CE.27 Entre intereses, comisiones y letra pequeña es casi imposible saber qué banco da mejor rendimiento.Decidimos hacer una prueba empírica: creamos dos cuentas, Cuenta Verde y Cuenta Azul, y procuramos mantener en lo posible el mismo dinero en ambas y repartir las operaciones por igual entre las dos. Al final de cada mes calculamos coste = intereses recibidos - gastos de comisiones. Tras doce meses comparamos las medias y vemos que con la Cuenta Azul hemos pagado cada més una media de 2.68€, mientras que con la Cuenta Verde hemos pagado una media de 4.09€. Para estar seguros realizamos un t-test para comparar ambos costes y esto es lo que obtenemos: t.test(CosteA, CosteV) t = 0.8085, df = 21.993, p-value = 0.4275 95 percent confidence interval: -2.1964315.003098 Explique posibles características de los datos para que unas medias claramente diferentes den lugar a un p-valor de 0.4275 y un intervalo de confianza de [-2.20, 5.00]. Prob CE.28 Nos han encargado estudiar la fabricación de motores de automóvil. Nuestros datos muestran que los cilindros tienen un diámetro medio de 86,022 mm con una desviación típica de 0,05 mm. Los pistones que han de encajar en los cilindros tienen un diámetro de 85,897 mm con una desviación típica de 0,03 mm. ¿Cuál es la distancia media y la desviación típica media entre pistón y cilindro? Según especificaciones esta distancia debe estar entre 0,045 mm y 0,08 mm. ¿Cuál es la probabilidad de que un par pistón-cilindro no cumpla esta especificación? Puede suponer que la distribución es normal. No hace falta que calcule el número, basta que lo indique mediante la función de distribución o mediante instrucciones de R. Prob CE.29 Ha hecho un experimento de regresión lineal y han obtenido la siguiente gráfica: Un compañero le dice que claramente la gráfica no es lineal y por lo tanto debe calcular el logaritmo de \\(y\\) y hacer la regresión lineal entre \\(x\\) y el logaritmo de \\(y\\). Explique el error de este razonamiento. Prob CE.30 En un control del diseño de un nuevo circuito ha medido la relación de señal/ruido de 18 circuitos y determina qué proporción presenta una relación por encima del valor de un circuito de la competencia. El intervalo de confianza es [0.68, 0.79] con un nivel de confianza del 90%. A su jefe no le gusta que el margen entre la proporción mayor y menor sea de 0.11. Quiere que lo baje en la siguiente iteración a un máximo de 0.05. ¿Cuántos circuitos tendrá que medir la siguiente vez? Prob CE.31 En el conjunto de datos mtcars, con información de coches, hacemos un ANOVA entre la potencia (hp) y el número de cilindros (cyl). El resultado del ANOVA es &gt; oneway.test(hp~factor(cyl), data = mtcars) data:hp and factor(cyl) F = 35.3811, num df = 2.000, denom df = 16.514, p-value = 1.071e-06 Calculamos los intervalos de confianza entre los 3 niveles con TukeyHSD y obtenemos: Interprete estas salidas. En particular indique si de media los coches con un cierto número de cilindros son más potentes que con otro y por cuánto. Prob CE.32 Estamos estudiando la variabilidad de unas resistencias. Vamos a suponer que siguen una distribución normal. Medimos 100 resistencias y los valores máximos y mínimos de resistencia obtenida son de \\(107\\, \\Omega\\) y de \\(94\\, \\Omega\\). Estime la media y la desviación típica de la distribución. Si cogemos 2 resistencias al azar, indique la probabilidad de que haya \\(1\\, \\Omega\\) de diferencia entre las dos (basta que indique la instrucción de R necesaria para hacer el cálculo). Prob CE.33 Un compañero ha hecho un estudio de regresión de \\(y\\sim x\\): ![](imagenes/reglin2.jpg)&lt;!-- --&gt; Ha obtenido la siguiente salida de R Residuals: Min 1Q Median 3Q Max -10.6709 -4.1624 -0.5603 3.9355 14.3313 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -4.6386 1.1493 -4.036 0.000108 *** x 9.1386 0.1976 46.253 &lt; 2e-16 *** --- Residual standard error: 5.703 on 98 degrees of freedom Multiple R-squared:0.9562, Adjusted R-squared:0.9558 F-statistic:2139 on 1 and 98 DF,p-value: &lt; 2.2e-16 Nos dice que está claro que \\(y = 9,14\\) y \\(x = - 4,64\\). Indique cuál es el error cometido y cómo se debe corregir. Prob CE.33 Estamos decidiéndonos entre 4 fabricantes de bombillas halógenas para un proyecto. No tenemos datos de fiabilidad de ellos y por lo tanto cogemos 10 de cada fabricante y vamos subiendo la tensión hasta que se rompen. Tomamos nota de la tensión de ruptura en cada caso. Explique que gráficas debemos realizar y qué prueba(s) estadística(s) hay que realizar para decidirnos por uno (o más de uno si son equivalentes). Prob CE.34 Se ha hecho una encuesta en 4 municipios para saber si creen que España debe seguir enviando un cantante a Eurovisión. El municipio A tiene 50.000 habitantes, el B 37,500, el C 89.000 y el D 120.000. Queremos que el intervalo de confianza sea de ± 4% con un nivel de confianza del 95%. Suponemos que la proporción es 0.50 (es el caso más desfavorable) ¿Cuánta gente debemos encuestar en cada municipio? (aproxime el intervalo de confianza a partir del error estándar). Después de hacer la encuesta vemos que en el municipio B el 27% quiere que continuemos enviando cantantes, mientras que en el C el 36% quiere que se haga. ¿Es esta diferencia estadísticamente significativa? Prob CE.35 Tiene dos caminos (camino A y camino B) para ir de su casa a la UIB en coche y quiere saber cuál es el más rápido. Se le ocurren dos estrategias. La primera consiste en ir los días pares por un camino y los impares por el otro. La segunda consiste en quedar con un vecino que también va a la universidad los martes y jueves (que son los días en que sus horarios coinciden) e ir uno por el camino A y el otro por el camino B. Describa las ventajas e inconvenientes de cada método. Indique mejoras posibles para los dos métodos. Describa qué prueba (o pruebas) estadísticas debe realizar y las instrucciones que debe usar en R para hacerlas. Prob CE.36 Se ha hecho una encuesta para saber si se opina que España ganará o no el Mundial. Se ha hecho en 4 ciudades: Madrid (3.200.000 habitantes), Barcelona (1.600.000 habitantes), Valencia (792.000 habitantes) y Palma (398.000 habitantes). Se ha encuestado a un total de 2000 personas. Si la encuesta se ha hecho bien, ¿cuántas personas se han encuestado de cada ciudad? En Madrid el 38.7% ha dicho que España ganará el Mundial, en Barcelona el 31.6%, en Valencia el 42.9% y en Palma el 27.5%. Aproxime el intervalo de confianza para un nivel de confianza del 95% de la proporción real del total de la población. Aproxime también los intervalos de confianza de cada ciudad. ¿Se puede asegurar que hay diferencias estadísticamente significativas entre algún par? Prob CE.37 En un periódico hay una noticia de una encuesta sobre las expectativas goleadoras de las selecciones. Cada encuestado indicaba cuántos goles creía que iban a hacer de promedio cada una de 5 selecciones favoritas. Sale la siguiente gráfica: En la noticia se dice que España ha salido “ganadora” de la encuesta y menciona que el resutado es estadísticamente significativo porque se ha hecho un ANOVA y sale que la probabilidad de que las diferencias sean por azar es menor que el 0,1%. Explique el error del periodista. Prob CE.39 Se quiere ver la relación que hay entre los resultados del Mundial y los exámenes.Los días después de un partido de España se entrevista a los alumnos que han hecho un examen y se les pregunta si lo han hecho mejor o peor de lo esperado. Los resultados son: Mejor Igual Peor Victoria 28 21 18 Empate 31 35 29 Derrota 26 29 30 Tenemos los datos metidos en R en una matriz llamada EM. Indique qué prueba (o pruebas) deben hacerse y cómo se deben interpretar los resultados. Escriba las instrucciones de R apropiadas (no se preocupe por la sintaxis). Prob CE.40 Recibe dos conjuntos de medidas de tiempos de respuesta de un circuito y le piden que los analice. Estas son las gráficas del Conjunto A: Y estos son los del Conjunto B: ¿Cuál de los dos conjuntos es más problemático?¿Por qué? Quieren calcular la media del tiempo de respuesta. ¿En cuál de los dos necesitaría tomar más muestras? Prob CE.41 Tenemos un evento que suponemos sigue una distribución de Poisson. La media de ocurrencias del evento es de 5,3. Para asegurarse que es una distribución de Poisson estudia las ocurrencias del evento en 1400 periodos de tiempo. En 458 de estos 1400 periodos el evento ha sucedido 4 ó 5 veces. Esto nos da una proporción \\(p = 0.327\\). ¿Cuál es el error estándar? ¿Considera que es razonable pensar que el proceso realmente es de Poisson? #Preguntas conceptuales 15.11 Tipos de datos TD 1 ¿De qué tipo de datos es la presión arterial sistólica? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 2 ¿De qué tipo de datos es el mes del año? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 3 ¿De qué tipo de datos es el número de hijos? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 4 ¿De qué tipo de datos es el número medio de hijos por madre de un país? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 5 ¿De qué tipo de datos es el grupo sanguíneo (A, B, AB, 0)? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 6 ¿De qué tipo de datos son las notas que se pueden tocar en una guitarra? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 7 ¿De qué tipo de datos son las notas que se pueden tocar en un violín? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo TD 8 ¿De qué tipo de datos es libros vendidos en una librería? (a)Cualitativo Ordinal Cuantitativo discreto Cuantitativo continuo 15.12 Estadística descriptiva ED 1 Con un summary() de R obtenemos la siguiente salida Min Q1 Median Mean Q3 Max 0.2 3.3 6.2 6.6 9.1 14.6 La distribución parece ser Simétrica Asimétrica a la derecha Asimétrica a la izquierda Con los datos numéricos no se puede saber ED 2 Conviene usar la mediana como medida de centralidad Cuando hay valores atípicos Cuando es fuertemente asimétrica Cuando es fuertemente asimétrica o hay valores atípicos Cuando es fuertemente asimétrica y hay valores atípicos ED 3 Tenemos una muestra de más de 400 elementos. La media es 6.9 y la desviación típica es 1.5. El valor máximo es 13.5. Este valor máximo Parece un valor atípico: está a más de 3 desviaciones típicas de la media Con sólo estos datos no podemos saber si es un valor atípico o no. No parece un valor atípico. No llega ni al doble de la media. No parece un valor atípico. Está a más de 3 desviaciones típicas, pero son más de 400 datos. ED 4 La modalidad de una muestra se ve en Todos los diagramas Todos los diagramas menos el de caja Sólo en el histograma y el de tallo y hojas Depende de la distribución. ED 5 Tengo una muestra de 120 datos con las siguientes características: Min Q1 Median Mean Q3 Max 15,3 21,0 28,3 27,4 36,5 44,4 Una estima razonable de la desviación típica es 13,7: la mitad de la media 9: algo más de la mitad de Q3 - Q1 3,5: la cuarta parte de Q3 - Q1 5: la sexta parte de Max - Min ED 6 En la distribución de la figura La media es claramente mayor que la mediana La media es claramente menor que la mediana La media es aproximadamente igual a la mediana No se puede saber a partir de la gráfica ED 7 Los datos represetados en la figura son Nada problemáticos Algo problemáticos Bastante problemáticos Muy problemáticos ED 8 Los datos represetados en la figura son Nada problemáticos Algo problemáticos Bastante problemáticos Muy problemáticos ED 9 Los datos representados en este diagrama de tallo y hojas -0 | 744 0 | 22344668999 1 | 122233344444677789 2 | 00122233455677 3 | 00001111223445667778 4 | 12223455567889 5 | 0001334899 6 | 233345666788999 7 | 000111223333445667888 8 | 0000011134556667778 9 | 01112244456777789 10 | 001245566778889 11 | 0033467 12 | 0125689 13 | 9 14 | 03 Son unimodales Son bimodales Son trimodales Son tetramodales ED 10 A partir de esta diagrama de barras vemos que la variable es Unimodal Bimodal Trimodal No tiene sentido hablar de modalidad de esta variable "]
]
